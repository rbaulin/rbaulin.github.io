<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="generator" content="pandoc">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <!--[if lt IE 9]>
    <script src="http://html5shim.googlecode.com/svn/trunk/html5.js"></script>
  <![endif]-->
  <link rel="stylesheet" href="style.css">

</head>
<body>

<div class="container preview-contents">

<p>graphicx = cmr10 scaled 2 = cmr10 scaled 0 = cmr10 scaled 0 \<span><span class="math">\(\backslash\)</span></span></p>
<p><span class="math">\[1\]</span></p>
<p>1. Теорема Поста о полноте систем функций в алгебре логики. 22. Графы, деревья, планарные графы; их свойства. Оценка числа деревьев. 43. Логика 1-го порядка. Выполнимость и общезначимость. Общая схема метода резолюций. 54. Логическое программирование. Декларативная семантика и операционная семантика: соотношение между ними. Стандартная стратегия выполнения логических программ. 85. Транзакционное управление в СУБД. Методы сериализации транзакций. 96. Аппаратно-программные средства поддержки мультипрограммного режима - система прерываний, защита памяти, привилегированный режим. 107. Организация взаимодействия процессов и средства их синхронизации. Классические задачи синхронизации. 118. Виртуальная память. Модели организации оперативной памяти. 189. Алгоритм Сети-Ульмана оптимального распределения регистров и его обоснование. 2210. Основные принципы объектно-ориентированного программирования. 2311. Основные этапы компиляции (лексический анализ, синтаксический анализ, семантический анализ, генерация кода и т.д.). 2412. Построение детерминированного конечного автомата по регулярному выражению. Error! Bookmark not defined.13. Построение канонического множества LR(1) ситуаций и таблиц действии и переходов для LR(1) грамматик. 2614. Архитектура параллельных вычислительных систем. 2815. Технологии параллельного программирования. 3116. Методы представления знаний в системах искусственного интеллекта (язык предикатов, семантические сети, фреймы, продукции). 4117. Методы поиска решения задач в системах искусственного интеллекта (эвристический поиск в пространстве состояний и на И/ИЛИ деревьях). 4318. Организация сетевого взаимодействия. Эталонная модель OSI ISO. Основные элементы и архитектура OSI ISO. Уровни протоколов и их основные функции. 4519. Организация сетевого взаимодействия. Семейство протоколов TCP/IP. Сравнение с эталонной моделью OSI ISO. Основные функции протоколов IP и TCP. Основные прикладные протоколы архитектуры TCP/IP. 5020. Средства межсетевого взаимодействия (мосты, маршрутизаторы, шлюзы). 5421. Методы защиты от несанкционированного доступа в компьютерных сетях. 5622. Унифицированный язык моделировании UML. Основные средства языка. 7523. Основы программной инженерии. Каскадная и итерационная модели жизненного цикла программного обеспечения. 7624. Глобальные и локальные модели освещения в компьютерной графике. Модель Фонга. 781.<span><strong>Теорема Поста о полноте систем функций в алгебре логики.</strong></span> <span><strong>Определение 1</strong></span>. Пусть A <span class="math">\(\subset \)</span> P<span class="math">\({}^{2}\)</span>. Тогда замыканием A называется множество всех функций алгебры логики, которые можно выразить формулами над A. Замыкание обозначается как [A]. Свойства замыкания:</p>
<p>[A] <span class="math">\(\supseteq \)</span> A;</p>
<p>A <span class="math">\(\supseteq \)</span> B ==<span class="math">\(&gt;\)</span> [A] <span class="math">\(\supseteq \)</span> [B], причём, если в левой части импликации строгое вложение, то из него вовсе не следует строгое вложение в правой части — верно лишь A<span class="math">\(\supset \)</span>B ==<span class="math">\(&gt;\)</span> [A] <span class="math">\(\supseteq \)</span> [B];</p>
<p>[[A]] = [A].</p>
<p><span><strong>Определение 2</strong></span>. Система функций алгебры логики A называется полной, если [A] = P<span class="math">\({}^{2}\)</span>. <span>****</span> <span><strong>Определение 3</strong></span>. Пусть A <span class="math">\(\subset \)</span> P<span class="math">\({}^{2}\)</span>. Тогда система A называется замкнутым классом, если замыкание A совпадает с самим A: [A] = A. <span>****</span> <span><strong>Утверждение</strong></span>. Пусть A — замкнутый класс, A <span class="math">\(\ne \)</span> P<span class="math">\({}^{2}\)</span> и B <span class="math">\(\subset \)</span> A. Тогда B — неполная система (подмножество неполной системы будет также неполной системой). <span><strong>Доказательство</strong></span>. B <span class="math">\(\subset \)</span> A ==<span class="math">\(&gt;\)</span> [B] <span class="math">\(\subset \)</span> [A] = A <span class="math">\(\ne \)</span> P2 ==<span class="math">\(&gt;\)</span> [B] <span class="math">\(\ne \)</span> P2. Следовательно, B — неполная система. Утверждение доказано.</p>
<p><span><strong>Теорема</strong></span>. Класс T<span class="math">\({}_{0}\)</span> = <span class="math">\(\{\)</span>f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) f (0, …, 0) = 0<span class="math">\(\}\)</span> —замкнутый. <span><strong>Доказательство</strong></span>. Пусть <span class="math">\(\{\)</span>f(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,..,<span><em>x<span class="math">\({}_{n}\)</span></em></span>),g<span class="math">\({}_{1}\)</span>(y<span class="math">\({}_{11}\)</span>,...y<span class="math">\({}_{1,}\)</span><span class="math">\({}_{m}\)</span><span class="math">\({}_{1}\)</span>),…,g<span><em><span class="math">\({}_{n}\)</span></em></span>(y<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}_{1}\)</span>,…,y<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}_{,}\)</span><span class="math">\({}_{m}\)</span><span><em><span class="math">\({}_{n}\)</span></em></span>)<span class="math">\(\}\)</span> <span class="math">\(\subset \)</span> T<span class="math">\({}_{0}\)</span>. Рассмотрим функцию h(y<span class="math">\({}_{1}\)</span>,…,y<span class="math">\({}_{r}\)</span> ) = f(g<span class="math">\({}_{1}\)</span>(y<span class="math">\({}_{11}\)</span>,…,y<span class="math">\({}_{1,}\)</span><span class="math">\({}_{m}\)</span><span class="math">\({}_{1}\)</span>),…,g<span><em><span class="math">\({}_{n}\)</span></em></span>(y<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}_{1}\)</span>,…,y<span class="math">\({}_{m}\)</span><span class="math">\({}_{,}\)</span><span><em><span class="math">\({}_{nn}\)</span></em></span>)). Среди переменных функций g<span><em><span class="math">\({}_{i}\)</span></em></span> могут встречаться и одинаковые, поэтому в качестве переменных функции h возьмём все различные из них. Тогда h (0, …, 0) = f (g<span class="math">\({}_{1}\)</span>(0, …, 0), …, g<span><em><span class="math">\({}_{n}\)</span></em></span>(0, …, 0)) = f(0, …, 0) = 0 , следовательно, функция h также сохраняет ноль. Рассмотрен только частный случай (без переменных в качестве аргументов). Однако, поскольку тождественная функция сохраняет ноль, подстановка простых переменных эквивалентна подстановке тождественной функции, теорема доказана.</p>
<p><span><strong>Теорема</strong></span>. Класс T<span class="math">\({}_{1}\)</span> = <span class="math">\(\{\)</span>f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) f (1, 1, …, 1) = 1<span class="math">\(\}\)</span> замкнут. Доказательство повторяет доказательство аналогичной теоремы для класса T<span class="math">\({}_{0}\)</span>.</p>
<p><span><strong>Определение</strong></span>. Функция алгебры логики f(<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) называется линейной, если f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) = a<span class="math">\({}_{0}\)</span> <span class="math">\(\oplus \)</span> a<span class="math">\({}_{1}\)</span><span><em>x</em></span><span class="math">\({}_{1}\)</span> <span class="math">\(\oplus \)</span> …<span class="math">\(\oplus \)</span> a<span><em><span class="math">\({}_{n}\)</span>x<span class="math">\({}_{n}\)</span></em></span>, где a<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\(\in \)</span>${<span class="math">\(0, 1\)</span>}$. Иными словами, в полиноме линейной функции нет слагаемых, содержащих конъюнкцию.</p>
<p><span><strong>Теорема</strong></span>. Класс L замкнут. <span><strong>Доказательство</strong></span>. Поскольку тождественная функция — линейная, достаточно рассмотреть только случай подстановки в формулы функций: пусть f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\in \)</span>L и g<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\(\in \)</span>L. Достаточно доказать, что f (g<span class="math">\({}_{1}\)</span>, …, g<span><em><span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\in \)</span>L. Действительно, если не учитывать слагаемых с коэффициентами a<span><em><span class="math">\({}_{i}\)</span></em></span> = 0, то всякую линейную функцию можно представить в виде <span><em>x<span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{1 }\)</span><span class="math">\(\oplus \)</span> <span><em>x<span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{2}\)</span> <span class="math">\(\oplus \)</span> <span><em>x<span class="math">\({}_{ik}\)</span></em></span><span class="math">\({}_{ }\)</span><span class="math">\(\oplus \)</span> a<span class="math">\({}_{0}\)</span>. Если теперь вместо каждого <span><em>x<span class="math">\({}_{ij}\)</span></em></span> подставить линейное выражение, то получится снова линейное выражение (или константа единица или нуль).</p>
<p><span><strong>Определение</strong></span>. Функцией, двойственной к функции алгебры логики f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>), называется функция f<span class="math">\({}^{*}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,…,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) = <span class="math">\(\overline{f}(\overline{x_{1} },...,\overline{x_{n} })\)</span> <span><strong>Теорема (принцип двойственности)</strong></span>. Пусть Ф(y<span class="math">\({}_{1}\)</span>,…,y<span class="math">\({}_{m}\)</span>) = f(g<span class="math">\({}_{1}\)</span>(y<span class="math">\({}_{11}\)</span>,…,y<span class="math">\({}_{1}\)</span><span><em><span class="math">\({}_{k}\)</span></em></span><span class="math">\({}_{1}\)</span>),…,(y<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}_{1}\)</span>,…,y<span><em><span class="math">\({}_{nkn}\)</span></em></span>)). Тогда Ф<span class="math">\({}^{*}\)</span>(y<span class="math">\({}_{1}\)</span>,…,y<span class="math">\({}_{m}\)</span>) = f<span class="math">\({}^{*}\)</span>(g<span class="math">\({}_{1}\)</span><span class="math">\({}^{*}\)</span>(y<span class="math">\({}_{11}\)</span>,…,y<span class="math">\({}_{1}\)</span><span><em><span class="math">\({}_{k}\)</span></em></span><span class="math">\({}_{1}\)</span>),…,g<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}^{*}\)</span>(y<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}_{1}\)</span>,…,y<span><em><span class="math">\({}_{nkn}\)</span></em></span>)). <span><strong>Доказательство</strong></span>. Рассмотрим Ф<span class="math">\({}^{*}\)</span>(y<span class="math">\({}_{1}\)</span>,…,y<span class="math">\({}_{m}\)</span>) = <span class="math">\(\overline{f}(g_{1} (\overline{y_{11} },...,\overline{y_{1k1} })\)</span>,…,<span class="math">\(g_{n} (\overline{y_{n1} },...,\overline{y_{nkn} }))\)</span> = <span class="math">\(\overline{f}(\overline{\overline{g_{11} }} ,...,\overline{y_{1k1} })\)</span>,…,<span class="math">\(\overline{\overline{g_{n} }} (\overline{y_{n1} },...,\overline{y_{nkn} })\)</span> = <span class="math">\(\overline{f}(\overline{g_{1}^{*} }(y_{11} ,...,y_{1k1} )\)</span>,…, <span class="math">\(\overline{g_{n}^{*} }(y_{n1} ,...,y_{nkn} )\)</span>= f<span class="math">\({}^{*}\)</span>(g<span class="math">\({}_{1}\)</span><span class="math">\({}^{*}\)</span>(y<span class="math">\({}_{11}\)</span>,…,y<span class="math">\({}_{1}\)</span><span><em><span class="math">\({}_{k}\)</span></em></span><span class="math">\({}_{1}\)</span>),…,g<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}^{*}\)</span>(y<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}_{1}\)</span>,…,y<span><em><span class="math">\({}_{nkn}\)</span></em></span>)). <span><strong>Следствие</strong></span>. Пусть функция Ф(y<span class="math">\({}_{1}\)</span>, …, y<span class="math">\({}_{m}\)</span>) реализуется формулой над A = <span class="math">\(\{\)</span>f1, f2, …<span class="math">\(\}\)</span>. Тогда если в этой формуле всюду заменить вхождения f<span><em><span class="math">\({}_{i}\)</span></em></span> на f<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\({}^{*}\)</span>, то получится формула, реализующая Ф<span class="math">\({}^{*}\)</span> (y<span class="math">\({}_{1}\)</span>, …, y<span class="math">\({}_{m}\)</span>). <span><strong>Утверждение</strong></span>. Для любой функции алгебры логики f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) справедливо равенство f(<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>)=f<span class="math">\({}^{**}\)</span> (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>).</p>
<p><span><strong>Определение</strong></span>. Функция алгебры логики f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) называется самодвойственной, если f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) = f<span class="math">\({}^{*}\)</span> (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>). Иначе говоря, S = <span class="math">\(\{\)</span>f f = f<span class="math">\({}^{*}\)</span><span class="math">\(\}\)</span>. <span><strong>Теорема</strong></span>. Класс S замкнут. <span><strong>Доказательство</strong></span>. Пусть f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\in \)</span>S, для любого <span><em>i</em></span> g<span><em><span class="math">\({}_{i}\)</span></em></span>(y<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{1}\)</span>,…,y<span><em><span class="math">\({}_{iki}\)</span></em></span>) <span class="math">\(\in \)</span>S, <span><em>i</em></span> = 1, 2, …, n и Ф = f(g<span class="math">\({}_{1}\)</span>(y<span class="math">\({}_{11}\)</span>,…,y<span class="math">\({}_{1}\)</span><span><em><span class="math">\({}_{k}\)</span></em></span><span class="math">\({}_{1}\)</span>),…,g<span><em><span class="math">\({}_{n}\)</span></em></span>(y<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}_{1}\)</span>,…,y<span><em><span class="math">\({}_{nkn}\)</span></em></span>)). Тогда из принципа двойственности следует, что Ф<span class="math">\({}^{*}\)</span> = f<span class="math">\({}^{*}\)</span>(g<span class="math">\({}_{1}\)</span><span class="math">\({}^{*}\)</span>(y<span class="math">\({}_{11}\)</span>,…,y<span class="math">\({}_{1}\)</span><span><em><span class="math">\({}_{k}\)</span></em></span><span class="math">\({}_{1}\)</span>),…,g<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}^{*}\)</span>(y<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}_{1}\)</span>,…,y<span><em><span class="math">\({}_{nk}\)</span></em></span>)). Таким образом, мы получили, что Ф = Ф<span class="math">\({}^{*}\)</span> и Ф<span class="math">\(\in \)</span>S.</p>
<p><span><strong>Определение</strong></span>. Функция алгебры логики f(<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) называется монотонной, если для любых двух сравнимых наборов <span class="math">\(\alpha \)</span> и <span class="math">\(\beta \)</span> выполняется импликация <span class="math">\(\alpha \)</span> <span class="math">\(&lt;\)</span>= <span class="math">\(\beta \)</span> ==<span class="math">\(&gt;\)</span> f(<span class="math">\(\alpha \)</span>) <span class="math">\(&lt;\)</span>= f(<span class="math">\(\beta \)</span>) . <span><strong>Теорема</strong></span>. Класс M монотонных функций замкнут. <span><strong>Доказательство</strong></span>. Поскольку тождественная функция монотонна, достаточно проверить лишь случай суперпозиции функций. Пусть f(<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\in \)</span>M, для любого <span><em>j</em></span> g<span><em><span class="math">\({}_{j}\)</span></em></span>(y<span class="math">\({}_{1}\)</span>, …, y<span class="math">\({}_{m}\)</span>) <span class="math">\(\in \)</span>M и Ф(y<span class="math">\({}_{1}\)</span>, …, y<span class="math">\({}_{m}\)</span>) = f(g<span class="math">\({}_{1}\)</span>(y<span class="math">\({}_{1}\)</span>, …,y<span class="math">\({}_{m}\)</span>), …,g<span><em><span class="math">\({}_{n}\)</span></em></span>(y<span class="math">\({}_{1}\)</span>, …,y<span class="math">\({}_{m}\)</span>)). Рассмотрим произвольные наборы <span class="math">\(\alpha \)</span> = (<span class="math">\(\alpha \)</span><span class="math">\({}_{1}\)</span>,…,<span class="math">\(\alpha \)</span><span class="math">\({}_{m}\)</span>) <span class="math">\(\beta \)</span> = (<span class="math">\(\beta \)</span><span class="math">\({}_{1}\)</span>,…<span class="math">\(\beta \)</span><span class="math">\({}_{m}\)</span>) такие, что <span class="math">\(\alpha \)</span> <span class="math">\(&lt;\)</span>= <span class="math">\(\beta \)</span>. Обозначим g<span><em><span class="math">\({}_{i}\)</span></em></span>(<span class="math">\(\alpha \)</span>) = <span class="math">\(\gamma \)</span><span><em><span class="math">\({}_{i}\)</span></em></span>, g<span><em><span class="math">\({}_{i}\)</span></em></span>(<span class="math">\(\beta \)</span>) = <span class="math">\(\delta \)</span><span><em><span class="math">\({}_{i}\)</span></em></span>. Тогда для любого <span><em>i</em></span> имеем <span class="math">\(\gamma \)</span><span><em><span class="math">\({}_{i}\)</span></em></span> <span class="math">\(&lt;\)</span>= <span class="math">\(\delta \)</span><span><em><span class="math">\({}_{i}\)</span></em></span>. Тогда по определению <span class="math">\(\gamma \)</span> = (<span class="math">\(\gamma \)</span><span class="math">\({}_{1}\)</span>,…, <span class="math">\(\gamma \)</span><span class="math">\({}_{m}\)</span>) <span class="math">\(&lt;\)</span>= <span class="math">\(\delta \)</span> = (<span class="math">\(\delta \)</span><span class="math">\({}_{1}\)</span>,…, <span class="math">\(\delta \)</span><span class="math">\({}_{m}\)</span>) и, в силу монотонности функции f, f(<span class="math">\(\gamma \)</span>) <span class="math">\(&lt;\)</span>= f(<span class="math">\(\delta \)</span>). Но Ф(<span class="math">\(\alpha \)</span>) = f(<span class="math">\(\gamma \)</span><span class="math">\({}_{1}\)</span>,…, <span class="math">\(\gamma \)</span><span class="math">\({}_{m}\)</span>) = f(<span class="math">\(\gamma \)</span>), Ф(<span class="math">\(\beta \)</span>) = f(<span class="math">\(\delta \)</span><span class="math">\({}_{1}\)</span>,…, <span class="math">\(\delta \)</span><span class="math">\({}_{m}\)</span>) = f(<span class="math">\(\delta \)</span>) и неравенство f(<span class="math">\(\gamma \)</span>) <span class="math">\(&lt;\)</span>= f(<span class="math">\(\delta \)</span>) <span class="math">\(&lt;\)</span>==<span class="math">\(&gt;\)</span> Ф(<span class="math">\(\alpha \)</span> ) <span class="math">\(&lt;\)</span>= Ф(<span class="math">\(\beta \)</span>), следовательно, Ф<span class="math">\(\in \)</span>M.</p>
<p><span><strong>Лемма (о несамодвойственной функции)</strong></span>. Из любой несамодвойственной функции алгебры логики f(<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …,<span><em>x<span class="math">\({}_{n}\)</span></em></span>), подставляя вместо всех переменных функции <span class="math">\(\overline{x}\)</span>и <span><em>x</em></span>, можно получить <span class="math">\(\varphi \)</span>(<span><em>x</em></span>) ≡ const. <span><strong>Доказательство</strong></span>. Пусть f <span class="math">\(\notin \)</span> S. Тогда <span class="math">\(\overline{f}(\overline{x_{1} },...,\overline{x_{n} })\)</span> <span class="math">\(\ne \)</span> f(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,…<span><em>x<span class="math">\({}_{n}\)</span></em></span>) ==<span class="math">\(&gt;\)</span> <span class="math">\(\exists\)</span> <span class="math">\(\sigma \)</span> = (<span class="math">\(\sigma \)</span><span class="math">\({}_{1}\)</span>,…,<span class="math">\(\sigma \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>): <span class="math">\(\overline{f}(\overline{\sigma _{1} },...,\overline{\sigma _{n} })\)</span> <span class="math">\(\ne \)</span> f(<span class="math">\(\sigma \)</span><span class="math">\({}_{1}\)</span>,…<span class="math">\(\sigma \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(&lt;\)</span>==<span class="math">\(&gt;\)</span> <span class="math">\(f(\overline{\sigma _{1} },...,\overline{\sigma _{n} })\)</span>= f(<span class="math">\(\sigma \)</span><span class="math">\({}_{1}\)</span>,…,<span class="math">\(\sigma \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>). Построим функцию <span class="math">\(\varphi \)</span>(<span><em>x</em></span>) так: <span class="math">\(\varphi \)</span>(<span><em>x</em></span>) = f(<span><em>x</em></span> <span class="math">\(\oplus \)</span> <span class="math">\(\sigma \)</span><span class="math">\({}_{1}\)</span>, …, <span><em>x</em></span> <span class="math">\(\oplus \)</span> <span class="math">\(\sigma \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>). Действительно, <span class="math">\(\varphi \)</span>(0) = f (<span class="math">\(\sigma \)</span><span class="math">\({}_{1}\)</span>,…,<span class="math">\(\sigma \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>), <span class="math">\(\varphi \)</span>(1) = <span class="math">\(f(\overline{\sigma _{1} },...,\overline{\sigma _{n} })\)</span> и <span class="math">\(\varphi \)</span>(0) = <span class="math">\(\varphi \)</span>(1) ==<span class="math">\(&gt;\)</span> <span class="math">\(\varphi \)</span>(<span><em>x</em></span>) = const. Заметим, что подстановка удовлетворяет условию теоремы, так как <span class="math">\[x\oplus \sigma =\left\{{x,\sigma =0\over \overline{x},\sigma =1} \right.\]</span></p>
<p><span><strong>Лемма (о немонотонной функции)</strong></span>. Из любой немонотонной функции алгебры логики f(<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>), подставляя вместо всех переменных функции <span><em>x</em></span>, 0, 1, можно получить функцию <span class="math">\(\varphi \)</span> (<span><em>x</em></span>) ≡ <span class="math">\(\overline{x}\)</span>. <span><strong>Доказательство</strong></span>. Пусть f <span class="math">\(\notin \)</span> M. Тогда существуют такие наборы <span class="math">\(\alpha \)</span> = (<span class="math">\(\alpha \)</span><span class="math">\({}_{1}\)</span>,…,<span class="math">\(\alpha \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>) и <span class="math">\(\beta \)</span> = (<span class="math">\(\beta \)</span><span class="math">\({}_{1}\)</span>,…,<span class="math">\(\beta \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>), что <span class="math">\(\alpha \)</span> <span class="math">\(&lt;\)</span> <span class="math">\(\beta \)</span> и f(<span class="math">\(\alpha \)</span>) <span class="math">\(&gt;\)</span> f(<span class="math">\(\beta \)</span>). Выделим те разряды i<span class="math">\({}_{1}\)</span>, …,i<span><em><span class="math">\({}_{k}\)</span></em></span> наборов <span class="math">\(\alpha \)</span> и <span class="math">\(\beta \)</span>, в которых они различаются. Очевидно, в наборе <span class="math">\(\alpha \)</span> эти разряды равны 0, а в наборе <span class="math">\(\beta \)</span> — 1. Рассмотрим последовательность наборов <span class="math">\(\alpha \)</span><span class="math">\({}^{0}\)</span>, <span class="math">\(\alpha \)</span><span class="math">\({}^{1}\)</span>,…, <span class="math">\(\alpha \)</span><span class="math">\({}^{k}\)</span>, таких, что <span class="math">\(\alpha \)</span> = <span class="math">\(\alpha \)</span><span class="math">\({}^{0}\)</span> <span class="math">\(&lt;\)</span> <span class="math">\(\alpha \)</span><span class="math">\({}^{1}\)</span> <span class="math">\(&lt;\)</span> <span class="math">\(\alpha \)</span><span class="math">\({}^{2}\)</span> <span class="math">\(&lt;\)</span> …<span class="math">\(&lt;\)</span> <span class="math">\(\alpha \)</span><span class="math">\({}^{k}\)</span> = <span class="math">\(\beta \)</span>, где <span class="math">\(\alpha \)</span><span class="math">\({}^{i}\)</span><span class="math">\({}^{+1}\)</span> получается из <span class="math">\(\alpha \)</span><span class="math">\({}^{i}\)</span> заменой одного из нулей на 1. Поскольку f(<span class="math">\(\alpha \)</span>) = 1, а f(<span class="math">\(\beta \)</span>) = 0, то найдутся соседние <span class="math">\(\alpha \)</span><span class="math">\({}^{i}\)</span> и <span class="math">\(\alpha \)</span><span class="math">\({}^{i}\)</span><span class="math">\({}^{+1}\)</span>, что f(<span class="math">\(\alpha \)</span><span class="math">\({}^{i}\)</span>) = 1 и f(<span class="math">\(\alpha \)</span><span class="math">\({}^{i}\)</span><span class="math">\({}^{+1}\)</span>) = 0. Пусть они различаются в r-ом разряде: <span class="math">\(\alpha \)</span><span class="math">\({}^{i}\)</span> = (<span class="math">\(\alpha \)</span><span class="math">\({}_{1}\)</span>, <span class="math">\(\alpha \)</span><span class="math">\({}_{2}\)</span>,…, <span class="math">\(\alpha \)</span><span class="math">\({}_{r}\)</span><span class="math">\({}_{-1}\)</span>, 0, <span class="math">\(\alpha \)</span><span class="math">\({}_{r}\)</span><span class="math">\({}_{+1}\)</span>,…, <span class="math">\(\alpha \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>), <span class="math">\(\alpha \)</span><span class="math">\({}^{i}\)</span><span class="math">\({}^{+1}\)</span> = (<span class="math">\(\alpha \)</span><span class="math">\({}_{1}\)</span>, <span class="math">\(\alpha \)</span><span class="math">\({}_{2}\)</span>,…, <span class="math">\(\alpha \)</span><span class="math">\({}_{r}\)</span><span class="math">\({}_{-1}\)</span>, 1, <span class="math">\(\alpha \)</span><span class="math">\({}_{r}\)</span><span class="math">\({}_{+1}\)</span>, …, <span class="math">\(\alpha \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>). Тогда определим функцию <span class="math">\(\varphi \)</span>(<span><em>x</em></span>) так: <span class="math">\(\varphi \)</span>(<span><em>x</em></span>) = f (<span class="math">\(\alpha \)</span><span class="math">\({}_{1}\)</span>, <span class="math">\(\alpha \)</span><span class="math">\({}_{2}\)</span>, …, <span class="math">\(\alpha \)</span><span class="math">\({}_{r}\)</span><span class="math">\({}_{--1}\)</span>, <span><em>x</em></span>, <span class="math">\(\alpha \)</span><span class="math">\({}_{r}\)</span><span class="math">\({}_{+1}\)</span>, …, <span class="math">\(\alpha \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>). Действительно, тогда <span class="math">\(\varphi \)</span>(0) = f(<span class="math">\(\alpha \)</span><span class="math">\({}^{i}\)</span>) = 1, <span class="math">\(\varphi \)</span>(1) = f(<span class="math">\(\alpha \)</span><span class="math">\({}^{i}\)</span><span class="math">\({}^{+1}\)</span>) = 0, <span class="math">\(\varphi \)</span> (<span><em>x</em></span>) ≡ <span class="math">\(\overline{x}\)</span>.</p>
<p><span><strong>Определение</strong></span>. Полиномом Жегалкина над <span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span> называется выражение вида K<span class="math">\({}_{1}\)</span> <span class="math">\(\oplus \)</span> K<span class="math">\({}_{2}\)</span> <span class="math">\(\oplus \)</span> K<span class="math">\({}_{3}\)</span> <span class="math">\(\oplus \)</span> …<span class="math">\(\oplus \)</span> K<span class="math">\({}_{l}\)</span>, либо 0, где <span><em>l</em></span> <span class="math">\(&gt;\)</span>= 1 и все K<span><em><span class="math">\({}_{j}\)</span></em></span> есть выражения вида <span><em>x<span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{1}\)</span><span><em>x<span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{2}\)</span>…<span><em>x<span class="math">\({}_{ik}\)</span></em></span>, где все переменные различны, либо 1.</p>
<p><span><strong>Теорема(теорема Жегалкина)</strong></span>. Любую функцию алгебры логики f(<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) можно единственным образом выразить полиномом Жегалкина над <span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>.</p>
<p><span><strong>Лемма (о нелинейной функции)</strong></span>. Из любой нелинейной функции алгебры логики f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>), подставляя вместо всех переменных <span><em>x</em></span>, <span class="math">\(\overline{x}\)</span> , <span><em>y</em></span>, <span class="math">\(\overline{y}\)</span> , 0, 1, можно получить <span class="math">\(\varphi \)</span>(<span><em>x</em></span>, <span><em>y</em></span>) = <span><em>x</em></span>y или <span class="math">\(\varphi \)</span>(<span><em>x</em></span>, <span><em>y</em></span>) = <span class="math">\(\overline{xy}\)</span>. <span><strong>Доказательство</strong></span>. Пусть f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\notin \)</span> L. Рассмотрим полином Жегалкина этой функции. Из её нелинейности следует, что в нём присутствуют слагаемые вида <span><em>x<span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{1}\)</span><span><em>x<span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{2}\)</span> . Не ограни- чивая общности рассуждений, будем считать, что присутствует произведение <span><em>x</em></span><span class="math">\({}_{1}\)</span><span><em>x</em></span><span class="math">\({}_{2}\)</span> · …. Та- ким образом, полином Жегалкина этой функции выглядит так: f(<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) = <span><em>x</em></span><span class="math">\({}_{1}\)</span> · <span><em>x</em></span><span class="math">\({}_{2}\)</span> · P<span class="math">\({}_{1}\)</span> (<span><em>x</em></span><span class="math">\({}_{3}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\oplus \)</span> <span><em>x</em></span><span class="math">\({}_{1}\)</span> · P<span class="math">\({}_{2}\)</span> (<span><em>x</em></span><span class="math">\({}_{3}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\oplus \)</span> <span><em>x</em></span><span class="math">\({}_{2}\)</span> · P<span class="math">\({}_{3}\)</span> (<span><em>x</em></span><span class="math">\({}_{3}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\oplus \)</span> P<span class="math">\({}_{4}\)</span> (<span><em>x</em></span><span class="math">\({}_{3}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>), причем P<span class="math">\({}_{1}\)</span> (<span><em>x</em></span><span class="math">\({}_{3}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\ne \)</span> 0. Иначе говоря, <span class="math">\(\exists\)</span> a<span class="math">\({}_{3}\)</span>, a<span class="math">\({}_{4}\)</span>, …, a<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\(\in \)</span>E2 = ${<span class="math">\(0, 1\)</span>}$ такие, что P<span class="math">\({}_{1}\)</span>(a<span class="math">\({}_{3}\)</span>, a<span class="math">\({}_{4}\)</span>, …, a<span><em><span class="math">\({}_{n}\)</span></em></span>) = 1. Рассмотрим вспомогательную функцию f (<span><em>x</em></span><span class="math">\({}_{1}\)</span>, <span><em>x</em></span><span class="math">\({}_{2}\)</span>, a<span class="math">\({}_{3}\)</span>, a<span class="math">\({}_{4}\)</span>, …, a<span><em><span class="math">\({}_{n}\)</span></em></span>) = <span><em>x</em></span><span class="math">\({}_{1}\)</span><span><em>x</em></span><span class="math">\({}_{2}\)</span> · <span class="math">\({}_{1}\)</span> <span class="math">\(\oplus \)</span> <span><em>x</em></span><span class="math">\({}_{1}\)</span> · b <span class="math">\(\oplus \)</span> <span><em>x</em></span>2 · c <span class="math">\(\oplus \)</span> d. Тогда функция f(<span><em>x</em></span> <span class="math">\(\oplus \)</span> с, <span><em>y</em></span> <span class="math">\(\oplus \)</span> b, a<span class="math">\({}_{3}\)</span>, a<span class="math">\({}_{4}\)</span>, …, a<span><em><span class="math">\({}_{n}\)</span></em></span>) = (<span><em>x</em></span> <span class="math">\(\oplus \)</span> c)(<span><em>y</em></span> <span class="math">\(\oplus \)</span> b) <span class="math">\(\oplus \)</span> (<span><em>x</em></span> <span class="math">\(\oplus \)</span> c)b <span class="math">\(\oplus \)</span> (<span><em>y</em></span> <span class="math">\(\oplus \)</span> b)c <span class="math">\(\oplus \)</span> d = <span><em>x</em></span>y <span class="math">\(\oplus \)</span> <span><em>x</em></span> · b <span class="math">\(\oplus \)</span> <span><em>y</em></span> · c <span class="math">\(\oplus \)</span> b · c <span class="math">\(\oplus \)</span> <span><em>x</em></span> · b <span class="math">\(\oplus \)</span> b · c <span class="math">\(\oplus \)</span> <span><em>y</em></span> · c <span class="math">\(\oplus \)</span> b · c <span class="math">\(\oplus \)</span> d = <span><em>x</em></span>y <span class="math">\(\oplus \)</span> (bc <span class="math">\(\oplus \)</span> d) = <span class="math">\(\left\{{xy,bc\oplus d=0\over \overline{xy},bc\oplus d=1} \right. \)</span></p>
<p><span><strong>Теорема 12 (теорема Поста)</strong></span>. Система функций алгебры логики A = <span class="math">\(\{\)</span>f<span class="math">\({}_{1}\)</span>, f<span class="math">\({}_{2}\)</span>, …<span class="math">\(\}\)</span> является полной в P<span class="math">\({}^{2}\)</span> тогда и только тогда, когда она не содержится целиком ни в одном из следующих классов: T<span class="math">\({}_{0}\)</span>, T<span class="math">\({}_{1}\)</span>, S, L, M. <span><strong>Доказательство</strong></span>. Необходимость. Пусть A — полная система, N — любой из классов T0, T1, S, L, M и пусть A <span class="math">\(\subset \)</span> N. Тогда [A] <span class="math">\(\subset \)</span> [N] = placeN <span class="math">\(\ne \)</span> P2 и [A] <span class="math">\(\ne \)</span> P2. Достаточность. Пусть A<span class="math">\(\not\subset \)</span>T0, A<span class="math">\(\not\subset \)</span>T1, A<span class="math">\(\not\subset \)</span>M, A<span class="math">\(\not\subset \)</span>L, A<span class="math">\(\not\subset \)</span>S. Тогда в A существуют функции f<span class="math">\({}_{0}\)</span> <span class="math">\(\notin \)</span> T<span class="math">\({}_{0}\)</span>, f<span class="math">\({}_{1}\)</span> <span class="math">\(\notin \)</span> T<span class="math">\({}_{1}\)</span>, f<span class="math">\({}_{M}\)</span> <span class="math">\(\notin \)</span> M, f<span class="math">\({}_{L}\)</span> <span class="math">\(\notin \)</span> L, f<span class="math">\({}_{S}\)</span> <span class="math">\(\notin \)</span> S. Достаточно показать, что [A] <span class="math">\(\supseteq \)</span> [f<span class="math">\({}_{0}\)</span>, f<span class="math">\({}_{1}\)</span>, f<span class="math">\({}_{M}\)</span>, f<span class="math">\({}_{L}\)</span>, f<span class="math">\({}_{S}\)</span>] = P<span class="math">\({}^{2}\)</span>. Разобьём доказательство на три части: получение отрицания, констант и конъюнкции. a) Получение <span class="math">\(\overline{x}\)</span>. Рассмотрим функцию f<span class="math">\({}_{0}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\notin \)</span> T<span class="math">\({}_{0}\)</span> и введём функцию <span class="math">\(\varphi \)</span><span class="math">\({}_{0}\)</span>(<span><em>x</em></span>) = f<span class="math">\({}_{0}\)</span>(<span><em>x</em></span>, <span><em>x</em></span>, …, <span><em>x</em></span>). Так как функция f<span class="math">\({}_{0}\)</span> не сохраняет нуль, <span class="math">\(\varphi \)</span><span class="math">\({}_{0}\)</span>(0) = 1. Возможны два случая: либо <span class="math">\(\varphi \)</span><span class="math">\({}_{0}\)</span>(<span><em>x</em></span>) = <span class="math">\(\overline{x}\)</span>, либо <span class="math">\(\varphi \)</span><span class="math">\({}_{0}\)</span>(<span><em>x</em></span>) ≡ 1. Рассмотрим функцию f<span class="math">\({}_{1}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>, …, <span><em>x<span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\notin \)</span> T<span class="math">\({}_{1}\)</span> и аналогичным образом введём функцию <span class="math">\(\varphi \)</span><span class="math">\({}_{1}\)</span>(<span><em>x</em></span>) = f<span class="math">\({}_{1}\)</span> (<span><em>x</em></span>, <span><em>x</em></span>, …, <span><em>x</em></span>). Так как функция f<span class="math">\({}_{1}\)</span> не сохраняет единицу, <span class="math">\(\varphi \)</span><span class="math">\({}_{1}\)</span>(1) = 0. Возможны также два случая: либо <span class="math">\(\varphi \)</span><span class="math">\({}_{1}\)</span>(<span><em>x</em></span>) = <span class="math">\(\overline{x}\)</span>, либо <span class="math">\(\varphi \)</span><span class="math">\({}_{1}\)</span> (<span><em>x</em></span>) ≡ 0. Если хотя бы в одном случае получилось искомое отрицание, пункт завершён. Если же в обоих случаях получились константы, то согласно лемме о немонотонной функции, подставляя в функцию f<span class="math">\({}_{M}\)</span> <span class="math">\(\notin \)</span> M вместо всех переменных константы и тождественные функции, можно получить отрицание. b) Получение констант 0 и 1. Имеем f<span class="math">\({}_{S}\)</span> <span class="math">\(\notin \)</span> S. Согласно лемме о несамодвойственной функции, подставляя вместо всех переменных функции fS отрицание (которое полу- чено в пункте a) и тождественную функцию, можно получить константы: [f<span class="math">\({}_{S}\)</span>,<span class="math">\(\overline{x}\)</span>] <span class="math">\(\supseteq \)</span> [0, 1]. c) Получение конъюнкции <span><em>x</em></span> · <span><em>y</em></span>. Имеем функцию f<span class="math">\({}_{L}\)</span> <span class="math">\(\notin \)</span> L. Согласно лемме о нелинейной функции, подставляя в функцию f<span class="math">\({}_{L}\)</span> вместо всех переменных константы и отрицания (которые были получены на предыдущих шагах доказательства), можно получить либо конъюнкцию, либо отрицание конъюнкции. Однако на первом этапе отрицание уже получено, следовательно, всегда можно получить конъюнкцию: В результате получено, что [f<span class="math">\({}_{0}\)</span>, f<span class="math">\({}_{1}\)</span>, f<span class="math">\({}_{M}\)</span>, f<span class="math">\({}_{L}\)</span>, f<span class="math">\({}_{S}\)</span>] <span class="math">\(\supseteq \)</span> [<span class="math">\(\overline{x}\)</span>, <span><em>x</em></span>y] = P<span class="math">\({}^{2}\)</span>.</p>
<p><span>****</span></p>
<p><span>****</span></p>
<p><span><strong>2. Графы, деревья, планарные графы; их свойства. Оценка числа деревьев. </strong></span> <span><strong>Определение</strong></span>. Графом называется произвольное множество элементов V и произвольное семейство E пар из V. Обозначение: G = (V, E). В дальнейшем будем рассматривать конечные графы, то есть графы с конечным множеством элементов и конечным семейством пар. <span><strong>Определение</strong></span>. Если элементы из E рассматривать как неупорядоченные пары, то граф называется неориентированным, а пары называются рёбрами. Если же элементы из E рас- сматривать как упорядоченные, то граф ориентированный, а пары — дуги. <span><strong>Определение</strong></span>. Пара вида (a, a) называется петлёй, если пара (a, b) встречается в семействе E несколько раз, то она называется кратным ребром (кратной дугой). <span><strong>Определение</strong></span>. В дальнейшем условимся граф без петель и кратных рёбер называть неориентированным графом (или просто графом), граф без петель — мультиграфом, а мультиграф, в котором разрешены петли — псевдографом. <span><strong>Определение</strong></span>. Две вершины графа называются смежными, если они соединены ребром. <span><strong>Определение</strong></span>. Говорят, что вершина и ребро инцидентны, если ребро содержит вершину. <span><strong>Определение</strong></span>. Степенью вершины (deg v) называется количество рёбер, инцидентных данной вершине. Для псевдографа полагают учитывать петлю дважды. <span>****</span> <span><strong>Утверждение</strong></span>. В любом графе (псевдографе) справедливо следующее соотношение: <span class="math">\(\sum _{i=1}^{p}\deg v_{i}  =2q\)</span>, где p – число вершин, а q – число ребер.</p>
<p><span><strong>Определение</strong></span>. Пусть множество вершин графа V = <span class="math">\(\{\)</span>v<span class="math">\({}_{1}\)</span>, v<span class="math">\({}_{2}\)</span>, …, v<span class="math">\({}_{p}\)</span><span class="math">\(\}\)</span>. Тогда матрицей смежности этого графа назовём матрицу A = a<span><em><span class="math">\({}_{ij}\)</span></em></span>, где a<span><em><span class="math">\({}_{ij}\)</span></em></span> = 1, если вершины v<span><em><span class="math">\({}_{i}\)</span></em></span> и v<span><em><span class="math">\({}_{j}\)</span></em></span> смежны (2, 3, …для мультиграфа или псевдографа) и 0 в противном случае, a<span><em><span class="math">\({}_{ii}\)</span></em></span> при этом равно числу петель в вершине v<span><em><span class="math">\({}_{i}\)</span></em></span>. <span><strong>Определение</strong></span>. Два графа (или псевдографа) G<span class="math">\({}_{1}\)</span> = (V<span class="math">\({}_{1}\)</span>, E<span class="math">\({}_{1}\)</span>) и G<span class="math">\({}_{2}\)</span> = (V<span class="math">\({}_{2}\)</span>, E<span class="math">\({}_{2}\)</span>) называются изоморфными, если существуют два взаимно однозначных отображения <span class="math">\(\varphi \)</span><span class="math">\({}_{1}\)</span>: V<span class="math">\({}_{1}\)</span> -<span class="math">\(&gt;\)</span> V<span class="math">\({}_{2}\)</span> и <span class="math">\(\varphi \)</span><span class="math">\({}_{2}\)</span>: E<span class="math">\({}_{1}\)</span> -<span class="math">\(&gt;\)</span> E<span class="math">\({}_{2}\)</span> такие, что для любых двух вершин u и v графа G<span class="math">\({}_{1}\)</span> справедливо <span class="math">\(\varphi \)</span><span class="math">\({}_{2}\)</span>(u, v) = (<span class="math">\(\varphi \)</span><span class="math">\({}_{1}\)</span>(u), <span class="math">\(\varphi \)</span><span class="math">\({}_{1}\)</span>(v)). <span><strong>Определение </strong></span>(изоморфизм графов без петель и кратных рёбер). Два графа G<span class="math">\({}_{1}\)</span> = (V<span class="math">\({}_{1}\)</span>, E<span class="math">\({}_{1}\)</span>) и G<span class="math">\({}_{2}\)</span> = (V<span class="math">\({}_{2}\)</span>, E<span class="math">\({}_{2}\)</span>) называются изоморфными, если существует взаимно однозначное отображение <span class="math">\(\varphi \)</span><span class="math">\({}_{1}\)</span>: V<span class="math">\({}_{1}\)</span> -<span class="math">\(&gt;\)</span> V<span class="math">\({}_{2}\)</span> такое, что (u, v) <span class="math">\(\in \)</span>E<span class="math">\({}_{1}\)</span> <span class="math">\(&lt;\)</span>==<span class="math">\(&gt;\)</span> (<span class="math">\(\varphi \)</span>(u), <span class="math">\(\varphi \)</span>(v)) <span class="math">\(\in \)</span>E<span class="math">\({}_{2}\)</span>. <span><strong>Определение</strong></span>. Граф G<span class="math">\({}_{1}\)</span> = (V<span class="math">\({}_{1}\)</span>, E<span class="math">\({}_{1}\)</span>) называется подграфом графа G = (V, E), если V<span class="math">\({}_{1}\)</span> <span class="math">\(\subset \)</span> V, E<span class="math">\({}_{1}\)</span> <span class="math">\(\subset \)</span> E. <span><strong>Определение</strong></span>. Путём в графе G = (V, E) называется любая последовательность вида v<span class="math">\({}_{0}\)</span>, (v<span class="math">\({}_{0}\)</span>, v<span class="math">\({}_{1}\)</span>), v<span class="math">\({}_{1}\)</span>, (v<span class="math">\({}_{1}\)</span>, v<span class="math">\({}_{2}\)</span>), …, v<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}_{-1}\)</span>, (v<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\({}_{--1}\)</span>, v<span><em><span class="math">\({}_{n}\)</span></em></span>), v<span><em><span class="math">\({}_{n}\)</span></em></span>. <span class="math">\(\times\)</span>исло n в данных обозначениях называется длиной пути. <span><strong>Определение</strong></span>. Цепью называется путь, в котором нет повторяющихся рёбер. Простой цепью называется путь без повторения вершин. <span><strong>Утверждение</strong></span>. Пусть в G = (V, E) v<span class="math">\({}_{1}\)</span> <span class="math">\(\ne \)</span> v<span class="math">\({}_{2}\)</span> и пусть P — путь из v<span class="math">\({}_{1}\)</span> в v<span class="math">\({}_{2}\)</span>. Тогда в P можно выделить подпуть из v<span class="math">\({}_{1}\)</span> в v<span class="math">\({}_{2}\)</span>, являющийся простой цепью. <span><strong>Доказательство</strong></span>. Пусть данный путь — не простая цепь. Тогда в нём повторяется некоторая вершина v, то есть он имеет вид: P<span class="math">\({}_{1}\)</span> = v<span class="math">\({}_{0}\)</span>C<span class="math">\({}_{1}\)</span>vC<span class="math">\({}_{2}\)</span>vC<span class="math">\({}_{3}\)</span>v<span class="math">\({}_{2}\)</span>. Тогда он содержит подпуть P<span class="math">\({}_{2}\)</span> = v<span class="math">\({}_{0}\)</span>C<span class="math">\({}_{1}\)</span>vC<span class="math">\({}_{3}\)</span>v<span class="math">\({}_{2}\)</span>. Если в P<span class="math">\({}_{2}\)</span> повторяется некоторая вершина, то аналогично удалим ещё кусок и так далее. Процесс должен закончиться, так как P<span class="math">\({}_{1}\)</span> — конечный путь. <span><strong>Определение</strong></span>. Путь называется замкнутым, если v<span class="math">\({}_{0}\)</span> = v<span><em><span class="math">\({}_{n}\)</span></em></span>. Путь называется циклом, если он замкнут, и рёбра в нём не повторяются. Путь называется простым циклом, если v<span class="math">\({}_{0}\)</span> = v<span><em><span class="math">\({}_{n}\)</span></em></span> и вершины не повторяются. <span><strong>Определение</strong></span>. Граф G = (V, E) называется связным, если для любых вершин v<span><em><span class="math">\({}_{i}\)</span></em></span>, v<span><em><span class="math">\({}_{j}\)</span></em></span><span class="math">\(\in \)</span>V (v<span><em><span class="math">\({}_{i}\)</span></em></span> <span class="math">\(\ne \)</span> v<span><em><span class="math">\({}_{j}\)</span></em></span>) существует путь из v<span><em><span class="math">\({}_{i}\)</span></em></span> в v<span><em><span class="math">\({}_{j}\)</span></em></span>.</p>
<p>Рассмотрим отношение v<span><em><span class="math">\({}_{i}\)</span></em></span> -<span class="math">\(&gt;\)</span> v<span><em><span class="math">\({}_{j}\)</span></em></span> существования пути из v<span><em><span class="math">\({}_{i}\)</span></em></span> в v<span><em><span class="math">\({}_{j}\)</span></em></span> для неориентированных графов. Оно 1) симметрично, так как (v<span><em><span class="math">\({}_{i}\)</span></em></span> -<span class="math">\(&gt;\)</span> v<span><em><span class="math">\({}_{j}\)</span></em></span>) ==<span class="math">\(&gt;\)</span> (v<span><em><span class="math">\({}_{j}\)</span></em></span> -<span class="math">\(&gt;\)</span> v<span><em><span class="math">\({}_{i}\)</span></em></span>), 2) транзитивно, так как (v<span><em><span class="math">\({}_{i}\)</span></em></span> -<span class="math">\(&gt;\)</span> v<span><em><span class="math">\({}_{j}\)</span></em></span>) &amp; (v<span><em><span class="math">\({}_{j}\)</span></em></span> -<span class="math">\(&gt;\)</span> v<span><em><span class="math">\({}_{k}\)</span></em></span>) ==<span class="math">\(&gt;\)</span> (v<span><em><span class="math">\({}_{i}\)</span></em></span> -<span class="math">\(&gt;\)</span> v<span><em><span class="math">\({}_{k}\)</span></em></span>), 3) рефлексивно, так как для любого <span><em>i</em></span> (v<span><em><span class="math">\({}_{i}\)</span></em></span> -<span class="math">\(&gt;\)</span> v<span><em><span class="math">\({}_{i}\)</span></em></span>). Таким образом, получено, что v<span><em><span class="math">\({}_{i}\)</span></em></span> -<span class="math">\(&gt;\)</span> v<span><em><span class="math">\({}_{j}\)</span></em></span> — отношение эквивалентности на множестве неориентированных графов и множество вершин разбивается на конечное число классов эквивалентности: V -<span class="math">\(&gt;\)</span> V<span class="math">\({}_{1}\)</span> <span class="math">\(\bigcup \)</span> V<span class="math">\({}_{2}\)</span> <span class="math">\(\bigcup \)</span> …<span class="math">\(\bigcup \)</span> V<span><em><span class="math">\({}_{k}\)</span></em></span>, Vi <span class="math">\(\cap\)</span> Vj = <span class="math">\(\emptyset \)</span> если <span><em>i</em></span> <span class="math">\(\ne \)</span> <span><em>j</em></span>. При этом граф G разбивается на связные подграфы, которые называются компонентами связности.</p>
<p><span><strong>Определение</strong></span>. Деревом называется связный граф без циклов. <span><strong>Определение</strong></span>. Подграф G<span class="math">\({}_{1}\)</span> = (V<span class="math">\({}_{1}\)</span>, E<span class="math">\({}_{1}\)</span>) графа G = (V, E), называется остовным деревом в графе G = (V, E), если G<span class="math">\({}_{1}\)</span> = (V<span class="math">\({}_{1}\)</span>, E<span class="math">\({}_{1}\)</span>) — дерево и V<span class="math">\({}_{1}\)</span> = V. <span><strong>Определение 2. </strong></span>1) Граф, состоящий из одной вершины, которая выделена, называется корневым деревом. 2) Пусть имеются корневые деревья D<span class="math">\({}_{1}\)</span>, D<span class="math">\({}_{2}\)</span>, …, D<span class="math">\({}_{m}\)</span> с корнями v<span class="math">\({}_{1}\)</span>, v<span class="math">\({}_{2}\)</span>, …, v<span class="math">\({}_{m}\)</span>, D<span><em><span class="math">\({}_{i}\)</span></em></span> = (V<span><em><span class="math">\({}_{i}\)</span></em></span>, E<span><em><span class="math">\({}_{i}\)</span></em></span>), V<span><em><span class="math">\({}_{i}\)</span></em></span> <span class="math">\(\cap\)</span> V<span><em><span class="math">\({}_{j}\)</span></em></span> = $ <span class="math">\($\emptyset \)</span> (<span><em>i</em></span> <span class="math">\(\ne \)</span> <span><em>j</em></span>). Тогда граф D = (V, E), полученный следующим образом: V = V<span class="math">\({}_{1}\)</span> <span class="math">\(\bigcup \)</span> V<span class="math">\({}_{2}\)</span> <span class="math">\(\bigcup \)</span> …<span class="math">\(\bigcup \)</span> V<span class="math">\({}_{m}\)</span> <span class="math">\(\bigcup \)</span> <span class="math">\(\{\)</span>v<span class="math">\(\}\)</span> (v<span class="math">\(\in \)</span>V<span><em><span class="math">\({}_{i}\)</span></em></span>, для любого <span><em>i</em></span> ), E = E<span class="math">\({}_{1}\)</span> <span class="math">\(\bigcup \)</span> E<span class="math">\({}_{2}\)</span> <span class="math">\(\bigcup \)</span> …<span class="math">\(\bigcup \)</span> E<span class="math">\({}_{m}\)</span> <span class="math">\(\bigcup \)</span> <span class="math">\(\{\)</span>(v, v<span class="math">\({}_{1}\)</span>), (v, v<span class="math">\({}_{2}\)</span>), …,(v, v<span class="math">\({}_{m}\)</span>)<span class="math">\(\}\)</span> и в котором выделена вершина v, называется корневым деревом. 3) Только те объекты являются корневыми деревьями, которые можно построить согласно пунктам 1) и 2). <span><strong>Определение</strong></span>. Упорядоченным корневым деревом называется корневое дерево, в котором 1) задан порядок поддеревьев и 2) каждое поддерево D<span><em><span class="math">\({}_{i}\)</span></em></span> является упорядоченным поддеревом.</p>
<p><span><strong>Теорема</strong></span>. <span class="math">\(\times\)</span>исло упорядоченных корневых деревьев с q рёбрами не превосходит 4<span class="math">\({}^{q}\)</span>. <span><strong>Доказательство</strong></span>. Рассмотрим алгоритм обхода упорядоченного дерева, называемого «поиском в глубину». Этот обход описывается рекурсивно следующим образом: 1) Начать с корня. Пока есть поддеревья выполнять: 2) перейти в корень очередного поддерева, обойти это поддерево «в глубину». 3) Вернуться в корень исходного поддерева. В результате обход «в глубину» проходит по каждому ребру дерева ровно 2 раза: один раз при переходе в очередное поддерево, второй раз при возвращении из этого поддерева. В соответствии с обходом «в глубину» будем строить последовательность из нулей и единиц, записывая на каждом шаге нуль или единицу, причём нуль будем записывать, если происходит переход в очередное поддерево, а единицу, если мы возвращаемся из поддерева. Получим последовательность из 0 и 1 длины 2q, которую назовём кодом дерева. По этому коду однозначно восстанавливается дерево, поскольку каждый очередной разряд однозначно указывает, начинать ли строить новое очередное поддерево или возвращаться на ярус ближе к корню. Таким образом, упорядоченных корневых деревьев с q рёбрами не больше, чем последовательностей из 0 и 1 длины 2q, а их число равно 2<span class="math">\({}^{2}\)</span><span class="math">\({}^{q}\)</span> = 4<span class="math">\({}^{q}\)</span>.</p>
<p>Изоморфизм корневых деревьев определяется так же, как и изоморфизм графов, но с дополнительным требованием: корень должен отображаться в корень. Для упорядоченных корневых деревьев также требуется сохранение порядка поддеревьев.</p>
<p><span><strong>Определение</strong></span>. Граф называется планарным, если существует его геометрическая реализация на плоскости. <span><strong>Определение</strong></span>. Если имеется планарная реализация графа и мы «разрежем» плоскость по всем линиям этой планарной реализации, то плоскость распадётся на части, которые называются гранями этой планарной реализации (одна из граней бесконечна, она называется внешней гранью).</p>
<p><span><strong>Теорема (формула Эйлера)</strong></span>. Для любой планарной реализации связного планарного графа G = (V, E) с p вершинами, q рёбрами и r гранями выполняется равенство: p – q + r = 2. <span><strong>Доказательство</strong></span>. Докажем теорему при фиксированном p индукцией по q. Так как G — связный граф, то q <span class="math">\(&gt;\)</span>= p – 1. a) Базис индукции: q = p – 1. Так как G — связный и q = p – 1, то G — дерево, то есть, в G нет циклов. Тогда r = 1. Отсюда p – q + r = 2. b) Пусть для q: p – 1 <span class="math">\(&lt;\)</span>= q <span class="math">\(&lt;\)</span> q<span class="math">\({}_{0}\)</span> теорема справедлива. Докажем, что для q = q<span class="math">\({}_{0}\)</span> она также справедлива. Пусть G — связный граф с p вершинами и q<span class="math">\({}_{0}\)</span> рёбрами и пусть в его планарной реализации r граней. Так как q<span class="math">\({}_{0}\)</span> <span class="math">\(&gt;\)</span> p – 1, то в G есть цикл (т.к. добавление любого ребра к связному графу порождает цикл). Пусть ребро e входит в цикл. Тогда к нему с двух сторон примыкают разные грани. Удалим ребро e из G. Тогда две грани сольются в одну, а полученный граф G<span class="math">\({}_{1}\)</span> останется связным. При этом получится планарная реализация графа G<span class="math">\({}_{1}\)</span> с p вершинами и q<span class="math">\({}_{0}\)</span> – 1 рёбрами и r – 1 гранями. Так как q<span class="math">\({}_{0 }\)</span>– 1 <span class="math">\(&lt;\)</span> q<span class="math">\({}_{0}\)</span>, то, по предположению индукции, для G<span class="math">\({}_{1}\)</span> справедлива формула Эйлера, то есть p – (q<span class="math">\({}_{0}\)</span> – 1) + (r – 1) = 2, откуда p – q<span class="math">\({}_{0}\)</span> + r = 2.</p>
<p><span><strong>3. Логика 1-го порядка. Выполнимость и общезначимость. Общая схема метода резолюций. </strong></span> <span><strong>Определение</strong></span>. Алфавитом называется множество V<span class="math">\(\bigcup \)</span>C<span class="math">\(\bigcup \)</span>F<span class="math">\(\bigcup \)</span>P<span class="math">\(\bigcup \)</span>L<span class="math">\(\bigcup \)</span>Q<span class="math">\(\bigcup \)</span>S, где</p>
<p>V = <span class="math">\(\{\)</span><span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span><span class="math">\(\}\)</span> – предметные переменные</p>
<p>C = <span class="math">\(\{\)</span>c<span class="math">\({}_{1}\)</span>,...,c<span class="math">\({}_{m}\)</span><span class="math">\(\}\)</span> – предметные константы</p>
<p>F = <span class="math">\(\{\)</span>f<span class="math">\({}_{1}\)</span>,...,f<span><em><span class="math">\({}_{k}\)</span></em></span><span class="math">\(\}\)</span> – функциональные символы. Каждый функциональный символ снабжен арностью этого символа.</p>
<p>P = <span class="math">\(\{\)</span>P<span class="math">\({}_{1}\)</span>,...,P<span class="math">\({}_{l}\)</span><span class="math">\(\}\)</span> – предикатные символы (также с арностями)</p>
<p>L = <span class="math">\(\{\)</span><span class="math">\(\neg \)</span>, &amp;, <span class="math">\(\vee \)</span>, <span class="math">\(\to \)</span><span class="math">\(\}\)</span> – логические связки</p>
<p>Q = <span class="math">\(\{\)</span><span class="math">\(\exists \)</span>, <span class="math">\(\forall \)</span><span class="math">\(\}\)</span> – кванторы</p>
<p>S – скобки и знаки препинания. <span><strong>Определение</strong></span>. Термом называется конструкция, построенная по следующим правилам:</p>
<p><span><em>x</em></span><span class="math">\(\in \)</span>V<span class="math">\(\bigcup \)</span>C – терм</p>
<p>f<span class="math">\(\in \)</span>F и имеет арность n, t<span class="math">\({}_{1}\)</span>,...t<span><em><span class="math">\({}_{n}\)</span></em></span> – термы. Тогда f(t<span class="math">\({}_{1}\)</span>,...,t<span><em><span class="math">\({}_{n}\)</span></em></span>) – терм.</p>
<p>Других термов нет. <span><strong>Определение</strong></span>. Формулой называется конструкция, построенная по следующим правилам:</p>
<p>P<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\(\in \)</span>P и имеет арность n, t<span class="math">\({}_{1}\)</span>,..., t<span><em><span class="math">\({}_{n}\)</span></em></span> – термы, тогда P<span><em><span class="math">\({}_{i}\)</span></em></span>(t<span class="math">\({}_{1}\)</span>,..., t<span><em><span class="math">\({}_{n}\)</span></em></span>) – атомарная формула (атом).</p>
<p><span class="math">\(\phi \)</span>, <span class="math">\(\varphi \)</span> - формулы, тогда (<span class="math">\(\phi \)</span><span class="math">\(\vee \)</span><span class="math">\(\varphi \)</span>), (<span class="math">\(\phi \)</span>&amp;<span class="math">\(\varphi \)</span>), (<span class="math">\(\neg \phi \)</span>), (<span class="math">\(\phi \)</span><span class="math">\(\to \)</span><span class="math">\(\varphi \)</span>) – формулы</p>
<p><span class="math">\(\phi \)</span> - формула, <span><em>x</em></span><span class="math">\(\in \)</span>V, тогда (<span class="math">\(\exists \)</span><span><em>x</em></span> <span class="math">\(\phi \)</span>), (<span class="math">\(\forall \)</span><span><em>x</em></span> <span class="math">\(\phi \)</span>) – формулы</p>
<p>Других формул нет. <span><strong>Определение</strong></span>. Пусть Q квантор; подформула <span class="math">\(\phi \)</span> формулы (Q<span><em>x</em></span> <span class="math">\(\phi \)</span>) называется областью действия квантора Q по переменной <span><em>x</em></span>. Переменная <span><em>x</em></span> называется свободной в формуле <span class="math">\(\varphi \)</span>, если не входит в область действия никакого квантора по <span><em>x</em></span>. В формуле (Q<span><em>x</em></span> <span class="math">\(\phi \)</span>) квантор Q связывает все свободные вхождения переменной <span><em>x</em></span> в формулу <span class="math">\(\phi \)</span>. Формула называется замкнутой, если содержит только связанные вхождения переменных. <span><strong>Определение</strong></span>. Интерпретацией I = (D<span class="math">\({}_{I}\)</span>, <span class="math">\(\overline{C}\)</span>, <span class="math">\(\overline{F}\)</span>, <span class="math">\(\overline{P}\)</span>), где</p>
<p>D<span class="math">\({}_{I}\)</span> –непустое множество, область интерпретации</p>
<p><span class="math">\(\overline{C}\)</span>:C <span class="math">\(\to \)</span>D<span class="math">\({}_{I}\)</span></p>
<p><span class="math">\(\overline{F}\)</span>:F<span class="math">\(\to \)</span> (D*<span class="math">\(\to \)</span>D<span class="math">\({}_{I}\)</span><span class="math">\({}_{)}\)</span>, где D* - множество подмножеств предметов из D<span class="math">\({}_{I}\)</span>, причем отображение <span class="math">\(\overline{F}\)</span>сохраняет арность.</p>
<p><span class="math">\(\overline{P}\)</span>:P<span class="math">\(\to \)</span> (D*<span class="math">\(\to \)</span><span class="math">\(\{\)</span><span><em>истина</em></span>, <span><em>ложь</em></span><span class="math">\(\}\)</span>), сохраняющее арность <span><strong>Определение</strong></span>. Пусть t(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) – терм, I – интерпретация, b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span> <span class="math">\(\in \)</span>D<span class="math">\({}_{I}\)</span>. Тогда значением терма на в I на наборе b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span> называется конструкция t(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]<span class="math">\({}_{I}\)</span>, построенная по следующим правилам:</p>
<p>Если t = c<span class="math">\(\in \)</span>C, то t(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]<span class="math">\({}_{I}\)</span> = <span class="math">\(\overline{C}\)</span>(с) <span class="math">\(\in \)</span>D<span class="math">\({}_{I}\)</span></p>
<p>Если t = <span><em>x<span class="math">\({}_{i}\)</span></em></span><span class="math">\(\in \)</span>V, то t(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]<span class="math">\({}_{I}\)</span> = b<span><em><span class="math">\({}_{i}\)</span></em></span></p>
<p>Если t = f(t<span class="math">\({}_{1}\)</span>,...,t<span class="math">\({}_{m}\)</span>)<span class="math">\(\in \)</span>F, то t(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[ b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]<span class="math">\({}_{I}\)</span> = <span class="math">\(\overline{F}\)</span>(f)( t<span class="math">\({}_{1}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]<span class="math">\({}_{I}\)</span>,..., t<span class="math">\({}_{m}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]<span class="math">\({}_{I}\)</span>) Далее будем использовать краткую запись: t(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[ b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]<span class="math">\({}_{I}\)</span> ~ t[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]</p>
<p><span><strong>Определение</strong></span>. Пусть<span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) - формула, I – интерпретация, b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\(\in \)</span>D<span class="math">\({}_{I}\)</span>. Будем говорить, что <span class="math">\(\phi \)</span> выполнима в I на наборе b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>, (I =<span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]) если выполнены следующие условия:</p>
<p>Если <span class="math">\(\phi \)</span> = P<span><em><span class="math">\({}_{i}\)</span></em></span>(t<span class="math">\({}_{1}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>),...,t<span class="math">\({}_{m}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)), то I =<span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>] <span class="math">\(\Leftrightarrow \)</span> P<span><em><span class="math">\({}_{i}\)</span></em></span>(t<span class="math">\({}_{1}\)</span>(b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>),...,t<span class="math">\({}_{m}\)</span>(b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>)) = <span><em>истина</em></span>.</p>
<p>Если</p>
<p><span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) = <span class="math">\(\neg \)</span><span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)</p>
<p><span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) = <span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)&amp;<span class="math">\(\phi \)</span><span class="math">\({}_{2}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)</p>
<p><span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) = <span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)<span class="math">\(\vee \)</span><span class="math">\(\phi \)</span><span class="math">\({}_{2}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)</p>
<p><span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) = <span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>(<span><em>x</em></span>1,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)<span class="math">\(\to \)</span>&amp;<span class="math">\(\phi \)</span><span class="math">\({}_{2}\)</span>(<span><em>x</em></span>1,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) то I =<span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>] <span class="math">\(\Leftrightarrow \)</span></p>
<p>не верно, что I =<span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]</p>
<p>одновременно I =<span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>] и I =<span class="math">\(\phi \)</span><span class="math">\({}_{2}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]</p>
<p>I =<span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>] или I =<span class="math">\(\phi \)</span><span class="math">\({}_{2}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]</p>
<p>I =<span class="math">\(\phi \)</span><span class="math">\({}_{2}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>] или не верно, что I =<span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]</p>
<p>Если <span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) = (<span class="math">\(\exists \)</span>[<span class="math">\(\forall \)</span>]<span><em>x</em></span><span class="math">\({}_{0}\)</span> <span class="math">\(\varphi \)</span>(<span><em>x</em></span><span class="math">\({}_{0}\)</span>, <span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)), то I =<span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>] <span class="math">\(\Leftrightarrow \)</span><span class="math">\(\exists \)</span>[<span class="math">\(\forall \)</span>] b<span class="math">\({}_{0}\)</span><span class="math">\(\in \)</span>D<span class="math">\({}_{I}\)</span>, I =<span class="math">\(\varphi \)</span> (<span><em>x</em></span><span class="math">\({}_{0}\)</span>, <span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{0}\)</span>, b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>] Далее будем использовать краткую запись: I =<span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>)[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>] ~ I =<span class="math">\(\phi \)</span>[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]</p>
<p><span><strong>Определение</strong></span>.</p>
<p><span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) выполнима в I (I = <span class="math">\(\phi \)</span>) если <span class="math">\(\exists \)</span> b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>, что I =<span class="math">\(\phi \)</span>[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]</p>
<p><span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) истинна в I (I = <span class="math">\(\phi \)</span>) если <span class="math">\(\forall \)</span> b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>, I =<span class="math">\(\phi \)</span>[b<span class="math">\({}_{1}\)</span>,...,b<span><em><span class="math">\({}_{n}\)</span></em></span>]</p>
<p><span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) выполнима <span class="math">\(\Leftrightarrow \)</span> <span class="math">\(\exists \)</span> I, что I = <span class="math">\(\phi \)</span></p>
<p><span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) противоречива <span class="math">\(\Leftrightarrow \)</span><span class="math">\(\forall \)</span> I, <span class="math">\(\phi \)</span> не выполнима в I</p>
<p><span class="math">\(\phi \)</span>(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) общезначима ( =<span class="math">\(\phi \)</span>) <span class="math">\(\Leftrightarrow \)</span> <span class="math">\(\forall \)</span> I, I = <span class="math">\(\phi \)</span></p>
<p><span><strong>Определение</strong></span>. Пусть Г=<span class="math">\(\{\)</span><span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>, <span class="math">\(\phi \)</span><span class="math">\({}_{2}\)</span>, ...<span class="math">\(\}\)</span> – конечное или бесконечное множество замкнутых формул. I – модель для Г, если <span class="math">\(\forall \)</span><span class="math">\(\phi \)</span><span><em><span class="math">\({}_{i}\)</span></em></span> I = <span class="math">\(\phi \)</span><span><em><span class="math">\({}_{i}\)</span></em></span>. Определение. Пусть <span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span> – замкнута. <span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span> называется логическим следованием Г=<span class="math">\(\{\)</span><span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>, <span class="math">\(\phi \)</span><span class="math">\({}_{2}\)</span>, ...<span class="math">\(\}\)</span>, если для любой модели I для Г, I = <span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span> (обозначается Г =<span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span>).</p>
<p><span><strong>Теорема</strong></span> <span><strong>(о логическом следовании)</strong></span>. Пусть Г = <span class="math">\(\{\)</span><span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>,..., <span class="math">\(\phi \)</span><span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\(\}\)</span> – конечное множество формул, <span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span> – замкнутая формула. Г =<span class="math">\(\phi \)</span><span class="math">\({}_{0 }\)</span>т. и т.т., когда = (<span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>&amp;...&amp;<span class="math">\(\phi \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>)<span class="math">\(\to \)</span> <span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span>. <span><strong>Доказательство</strong></span>. Необходимость. Г =<span class="math">\(\phi \)</span><span class="math">\({}_{0. }\)</span>Рассмотрим произвольную интерпретацию I. Если I – модель для Г, то I = <span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span>, и I = (<span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>&amp;...&amp;<span class="math">\(\phi \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>)<span class="math">\(\to \)</span> <span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span>. Если же I – не модель для Г, до <span class="math">\(\exists \)</span><span class="math">\(\phi \)</span><span><em><span class="math">\({}_{i}\)</span></em></span>, что <span class="math">\(\phi \)</span><span><em><span class="math">\({}_{i}\)</span></em></span> не выполнима на I, следовательно, <span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>&amp;...&amp;<span class="math">\(\phi \)</span><span><em><span class="math">\({}_{n}\)</span></em></span> не выполнима на I и I = (<span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>&amp;...&amp;<span class="math">\(\phi \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>)<span class="math">\(\to \)</span> <span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span>. Достаточность. = (<span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>&amp;...&amp;<span class="math">\(\phi \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>)<span class="math">\(\to \)</span> <span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span>. Пусть I – произвольная модель для Г, тогда <span class="math">\(\forall \)</span><span class="math">\(\phi \)</span><span><em><span class="math">\({}_{i}\)</span></em></span>, I = <span class="math">\(\phi \)</span><span><em><span class="math">\({}_{i}\)</span></em></span>. Значит, I = <span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>&amp;...&amp;<span class="math">\(\phi \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>. Т.к. I = (<span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>&amp;...&amp;<span class="math">\(\phi \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>)<span class="math">\(\to \)</span> <span class="math">\(\phi \)</span><span class="math">\({}_{0 }\)</span>(следует из общезначимости (<span class="math">\(\phi \)</span><span class="math">\({}_{1}\)</span>&amp;...&amp;<span class="math">\(\phi \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>)<span class="math">\(\to \)</span> <span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span>), то необходимо I =<span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span>, а значит и Г = <span class="math">\(\phi \)</span><span class="math">\({}_{0}\)</span>.</p>
<p><span><strong>Определение</strong></span>. Пусть <span class="math">\(\phi \)</span> и <span class="math">\(\varphi \)</span> - формулы. <span class="math">\(\phi \)</span> и <span class="math">\(\varphi \)</span> равносильны (<span class="math">\(\phi \)</span><span class="math">\(\equiv \)</span><span class="math">\(\varphi \)</span>), если (<span class="math">\(\phi \)</span><span class="math">\(\to \)</span><span class="math">\(\varphi \)</span>)&amp;(<span class="math">\(\varphi \)</span><span class="math">\(\to \)</span><span class="math">\(\phi \)</span>). <span><strong>Утверждение</strong></span>. Если =<span class="math">\(\phi \)</span> и =<span class="math">\(\phi \)</span><span class="math">\(\equiv \)</span><span class="math">\(\varphi \)</span>, то =<span class="math">\(\varphi \)</span>. Если <span class="math">\(\phi \)</span> - невыполнима, и =<span class="math">\(\phi \)</span><span class="math">\(\equiv \)</span><span class="math">\(\varphi \)</span>, то и <span class="math">\(\varphi \)</span> - невыполнима.</p>
<p><span><strong>Теорема</strong></span>. Следующие пары формул эквивалентны:</p>
<p>(<span class="math">\(\phi \)</span>&amp;<span class="math">\(\varphi \)</span>) и (<span class="math">\(\varphi \)</span>&amp;<span class="math">\(\phi \)</span>)</p>
<p>(<span class="math">\(\phi \)</span>&amp;<span class="math">\(\varphi \)</span>)&amp;<span class="math">\(\chi \)</span> и <span class="math">\(\varphi \)</span>&amp;(<span class="math">\(\phi \)</span>&amp;<span class="math">\(\chi \)</span>)</p>
<p>(<span class="math">\(\phi \)</span><span class="math">\(\vee \)</span><span class="math">\(\varphi \)</span>) и (<span class="math">\(\varphi \)</span><span class="math">\(\vee \)</span><span class="math">\(\phi \)</span>)</p>
<p>(<span class="math">\(\phi \)</span><span class="math">\(\vee \)</span><span class="math">\(\varphi \)</span>)<span class="math">\(\vee \)</span><span class="math">\(\chi \)</span>и <span class="math">\(\varphi \)</span><span class="math">\(\vee \)</span>(<span class="math">\(\phi \)</span><span class="math">\(\vee \)</span><span class="math">\(\chi \)</span>)</p>
<p>(<span class="math">\(\phi \)</span><span class="math">\(\to \)</span><span class="math">\(\varphi \)</span>) и (<span class="math">\(\neg \)</span><span class="math">\(\phi \)</span><span class="math">\(\vee \)</span><span class="math">\(\varphi \)</span>)</p>
<p><span class="math">\(\neg \)</span>(<span class="math">\(\phi \)</span>&amp;<span class="math">\(\varphi \)</span>) и (<span class="math">\(\neg \)</span><span class="math">\(\varphi \)</span>)<span class="math">\(\vee \)</span>(<span class="math">\(\neg \)</span><span class="math">\(\phi \)</span>)</p>
<p><span class="math">\(\neg \)</span>(<span class="math">\(\phi \)</span><span class="math">\(\vee \)</span><span class="math">\(\varphi \)</span>) и (<span class="math">\(\neg \)</span><span class="math">\(\varphi \)</span>)&amp;(<span class="math">\(\neg \)</span><span class="math">\(\phi \)</span>)</p>
<p><span class="math">\(\neg \)</span> (<span class="math">\(\neg \)</span><span class="math">\(\phi \)</span>) и <span class="math">\(\phi \)</span></p>
<p><span class="math">\(\neg \)</span>(<span class="math">\(\forall \)</span><span><em>x</em></span> <span class="math">\(\phi \)</span>) и <span class="math">\(\exists \)</span><span><em>x</em></span> <span class="math">\(\neg \)</span><span class="math">\(\phi \)</span></p>
<p><span class="math">\(\neg \)</span>(<span class="math">\(\exists \)</span><span><em>x</em></span> <span class="math">\(\phi \)</span>) и <span class="math">\(\forall \)</span><span><em>x</em></span> <span class="math">\(\neg \)</span><span class="math">\(\phi \)</span></p>
<p>Q<span><em>x</em></span> <span class="math">\(\phi \)</span> и Q<span><em>y</em></span> <span class="math">\(\phi \)</span><span class="math">\(\{\)</span><span><em>x</em></span>/<span><em>y</em></span><span class="math">\(\}\)</span>, где Q – квантор и <span><em>y</em></span> не содержится в Q<span><em>x</em></span> <span class="math">\(\phi \)</span></p>
<p>(Q<span><em>x</em></span> <span class="math">\(\phi \)</span>) &amp;[<span class="math">\(\vee \)</span>] <span class="math">\(\varphi \)</span> и Q<span><em>x</em></span> (<span class="math">\(\phi \)</span>&amp;[<span class="math">\(\vee \)</span>]<span class="math">\(\varphi \)</span>), <span><em>x</em></span> не содержится в <span class="math">\(\varphi \)</span> свободно</p>
<p>(<span class="math">\(\phi \)</span><span class="math">\(\vee \)</span><span class="math">\(\varphi \)</span>)&amp;<span class="math">\(\chi \)</span>и (<span class="math">\(\varphi \)</span>&amp;<span class="math">\(\chi \)</span>)<span class="math">\(\vee \)</span>(<span class="math">\(\phi \)</span>&amp;<span class="math">\(\chi \)</span>)</p>
<p><span class="math">\(\phi \)</span>&amp;<span class="math">\(\phi \)</span> и <span class="math">\(\phi \)</span></p>
<p><span class="math">\(\phi \)</span><span class="math">\(\vee \)</span><span class="math">\(\phi \)</span> и <span class="math">\(\phi \)</span> и т.д.</p>
<p><span><strong>Теорема (о замене эквивалентных подформул)</strong></span>. Если формулы <span class="math">\(\phi \)</span>’ и <span class="math">\(\varphi \)</span>’ равносильны, и формула <span class="math">\(\varphi \)</span> получается из <span class="math">\(\phi \)</span> заменой подформулы <span class="math">\(\phi \)</span>’ на подформулу <span class="math">\(\varphi \)</span>’, то формулы <span class="math">\(\phi \)</span> и <span class="math">\(\varphi \)</span> равносильны.</p>
<p><span><strong>Определение</strong></span>. Замкнутая формула <span class="math">\(\phi \)</span> имеет предваренную нормальную форму, если <span class="math">\(\phi \)</span> = Q<span class="math">\({}_{1}\)</span><span><em>x</em></span><span class="math">\({}_{1}\)</span>...Q<span><em><span class="math">\({}_{n}\)</span>x<span class="math">\({}_{n}\)</span></em></span>M(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>), где Qi – кванторы и M не содержит кванторов и представлена в КНФ, т.е. M = K<span class="math">\({}_{1}\)</span>&amp; ...&amp;K<span class="math">\({}_{m}\)</span>, K<span><em><span class="math">\({}_{i}\)</span></em></span> = L<span class="math">\({}_{1}\)</span><span class="math">\(\vee \)</span>...<span class="math">\(\vee \)</span>L<span><em><span class="math">\({}_{k}\)</span></em></span>, L<span><em><span class="math">\({}_{i}\)</span></em></span> – либо атом, либо отрицание атома.</p>
<p><span><strong>Теорема</strong></span>. Для любой замкнутой формулы <span class="math">\(\phi \)</span> существует предваренная нормальная форма.</p>
<p><span><strong>Определение</strong></span>. Пусть <span class="math">\(\phi \)</span> = Q<span class="math">\({}_{1}\)</span><span><em>x</em></span><span class="math">\({}_{1}\)</span>...Q<span><em><span class="math">\({}_{n}\)</span>x<span class="math">\({}_{n}\)</span></em></span>M(<span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>) - формула в п.н.ф. Тогда формула <span class="math">\(\phi \)</span>’ называется скулемовской нормальной формой (с.н.ф.) формулы <span class="math">\(\phi \)</span>, если она получена из <span class="math">\(\phi \)</span> следующими преобразованиями: если Q<span><em><span class="math">\({}_{i}\)</span></em></span> - квантор <span class="math">\(\exists \)</span>, а Q<span class="math">\({}_{1}\)</span>...Q<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{-1}\)</span> - все кванторы <span class="math">\(\forall \)</span>, предшествующие Q<span><em><span class="math">\({}_{i}\)</span></em></span> в <span class="math">\(\phi \)</span>, то Q<span><em><span class="math">\({}_{i}\)</span>x<span class="math">\({}_{i}\)</span></em></span> удаляется из кванторной приставки, а в формуле M каждое вхождение переменной <span><em>x<span class="math">\({}_{i}\)</span></em></span> заменяется на терм f(<span><em>x</em></span><span class="math">\({}_{1}\)</span>...<span><em>x<span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{-1}\)</span>) , где f - новый m-арный функциональный символ; и т.д. для всех кванторов <span class="math">\(\exists \)</span>.</p>
<p><span><strong>Теорема</strong></span>. Если <span class="math">\(\phi \)</span> - формула в п.н.ф., а <span class="math">\(\phi \)</span>’ - соответствующая ей формула в с.н.ф., то формулы <span class="math">\(\phi \)</span> и <span class="math">\(\phi \)</span>’ одновременно невыполнимы. <span><strong>Теорема</strong></span>. Замкнутая формула общезначима тогда и только тогда, когда ее отрицание невыполнимо.</p>
<p><span><strong>Определение</strong></span>. Система дизъюнктов S = <span class="math">\(\{\)</span>D<span class="math">\({}_{1}\)</span>,...,D<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\(\}\)</span> называется противоречивой, если <span class="math">\(\forall \)</span>I, <span class="math">\(\exists \)</span> (a<span class="math">\({}_{1}\)</span>,...,a<span><em><span class="math">\({}_{n}\)</span></em></span>)<span class="math">\(\in \)</span>D<span class="math">\({}_{I}\)</span><span class="math">\({}^{n}\)</span> и <span class="math">\(\exists \)</span> D<span><em><span class="math">\({}_{j}\)</span></em></span> <span class="math">\(\in \)</span> S, что D<span><em><span class="math">\({}_{j}\)</span></em></span> невыполнима на I.</p>
<p>Процесс доказательства общезначимости формулы <span class="math">\(\phi \)</span>:</p>
<p>Построение п.н.ф. для <span class="math">\(\neg \)</span><span class="math">\(\phi \)</span></p>
<p>Построение с.н.ф.</p>
<p>Построение набора дизъюнктов S = <span class="math">\(\{\)</span>D<span class="math">\({}_{1}\)</span>,...,D<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\(\}\)</span> по с.н.ф.</p>
<p>Резолютивный вывод для S. Если вывод завершается успешно, то это означает, что S – противоречив, и, следовательно, <span class="math">\(\neg \)</span><span class="math">\(\phi \)</span> - невыполнима, а значит <span class="math">\(\phi \)</span> - общезначима. Резолютивный вывод для набора дизъюнктов S состоит в построении конечной последовательности дизъюнктов <span class="math">\(\{\)</span>D<span class="math">\({}_{1}\)</span>’, ..., D<span><em><span class="math">\({}_{k}\)</span></em></span>’<span class="math">\(\}\)</span>, такой что каждый D<span><em><span class="math">\({}_{i}\)</span></em></span>’ получается из <span class="math">\(\{\)</span>D<span class="math">\({}_{1}\)</span>,...,D<span><em><span class="math">\({}_{n}\)</span></em></span>, D<span class="math">\({}_{1}\)</span>’,...D<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{-1}\)</span>’<span class="math">\(\}\)</span> по правилам резолютивного вывода. Вывод считается успешным, если вывод заканчивается получением D<span><em><span class="math">\({}_{k}\)</span></em></span>’ = □ – пустого дизъюнкта.</p>
<p><span><strong>Теорема (корректность резолютивного вывода)</strong></span>. Если из S резолютивно выводим D, то S = D. <span><strong>Теорема (полнота резолютивного вывода)</strong></span>. Если S – противоречив, то <span class="math">\(\exists \)</span> успешный резолютивный вывод для S.</p>
<p><span><strong>4. Логическое программирование. Декларативная семантика и операционная семантика: соотношение между ними. Стандартная стратегия выполнения логических программ. </strong></span></p>
<p><span><em>Синтаксис логической программы</em></span> <span class="math">\(&lt;\)</span>программа<span class="math">\(&gt;\)</span>::=<span class="math">\(&lt;\)</span>программные утверждения<span class="math">\(&gt;\)</span><span class="math">\(&lt;\)</span>запрос<span class="math">\(&gt;\)</span> <span class="math">\(&lt;\)</span>программное утверждение<span class="math">\(&gt;\)</span>::=<span class="math">\(&lt;\)</span>процедура<span class="math">\(&gt;\)</span><span class="math">\(&lt;\)</span>факт<span class="math">\(&gt;\)</span> <span class="math">\(&lt;\)</span> процедура<span class="math">\(&gt;\)</span>::=<span class="math">\(&lt;\)</span>заголовок процедуры<span class="math">\(&gt;\)</span> :- <span class="math">\(&lt;\)</span>тело процедуры<span class="math">\(&gt;\)</span> <span class="math">\(&lt;\)</span>заголовок процедуры<span class="math">\(&gt;\)</span> :- <span class="math">\(&lt;\)</span>атом<span class="math">\(&gt;\)</span> <span class="math">\(&lt;\)</span>тело процедуры<span class="math">\(&gt;\)</span> :- <span class="math">\(&lt;\)</span>атом<span class="math">\(&gt;\)</span><span class="math">\(&lt;\)</span>атом<span class="math">\(&gt;\)</span>, <span class="math">\(&lt;\)</span>тело процедуры<span class="math">\(&gt;\)</span> <span class="math">\(&lt;\)</span>факт<span class="math">\(&gt;\)</span> :- <span class="math">\(&lt;\)</span>атом<span class="math">\(&gt;\)</span> <span class="math">\(&lt;\)</span>запрос<span class="math">\(&gt;\)</span>::= ?<span class="math">\(&lt;\)</span>тело процедуры<span class="math">\(&gt;\)</span></p>
<p>Основная структура данных – список:</p>
<p>nil – константа, пустой список</p>
<p><span><em>x</em></span>.nil – список, состоящий из единственного элемента <span><em>x</em></span></p>
<p><span><em>x</em></span>.<span><em>y</em></span> – список, состоящий из головного элемента <span><em>x</em></span> и хвоста <span><em>y</em></span></p>
<p><span><em>Декларативная семантика</em></span></p>
<p><span>**<span><strong></span></strong></span>Процедура A<span class="math">\({}_{0}\)</span> :- A<span class="math">\({}_{1}\)</span>,...,A<span><em><span class="math">\({}_{n}\)</span></em></span> интерпретируется как <span class="math">\(\forall \)</span><span><em>x</em></span><span class="math">\({}_{1}\)</span>, ..., <span class="math">\(\forall \)</span><span><em>x<span class="math">\({}_{n}\)</span></em></span> (A<span class="math">\({}_{1}\)</span>&amp;...&amp;A<span><em><span class="math">\({}_{n}\)</span></em></span> <span class="math">\(\to \)</span> A<span class="math">\({}_{0}\)</span>), или, что то же самое, <span class="math">\(\forall \)</span><span><em>x</em></span><span class="math">\({}_{1}\)</span>, ..., <span class="math">\(\forall \)</span><span><em>x<span class="math">\({}_{n}\)</span></em></span> (<span class="math">\(\neg \)</span>A<span class="math">\({}_{1}\)</span><span class="math">\(\vee \)</span> ... <span class="math">\(\vee \)</span><span class="math">\(\neg \)</span>A<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\(\vee \)</span>A<span class="math">\({}_{0}\)</span>)</p>
<p>Факт B<span class="math">\({}_{0}\)</span> :- интерпретируется как <span class="math">\(\forall \)</span><span><em>x</em></span><span class="math">\({}_{1}\)</span>, ..., <span class="math">\(\forall \)</span><span><em>x<span class="math">\({}_{n}\)</span></em></span> B<span class="math">\({}_{0}\)</span></p>
<p>Запрос ?C<span class="math">\({}_{1}\)</span>,...,C<span><em><span class="math">\({}_{n}\)</span></em></span> интерпретируется как <span class="math">\(\exists \)</span><span><em>x</em></span><span class="math">\({}_{1}\)</span>,..., <span class="math">\(\exists \)</span><span><em>x<span class="math">\({}_{n}\)</span></em></span> (C<span class="math">\({}_{1}\)</span>,...,C<span><em><span class="math">\({}_{n}\)</span></em></span>), где кванторы существования связывают все переменные Ответ <span class="math">\(\theta \)</span> называется правильным, если P = G<span class="math">\(\theta \)</span>.</p>
<p><span><strong>Определение</strong></span>. Ответом на запрос G к программе P называется подстановка <span class="math">\(\theta \)</span> = <span class="math">\(\{\)</span><span><em>x</em></span><span class="math">\({}_{1}\)</span>/t<span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span>/t<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\(\}\)</span>, где <span><em>x</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>x<span class="math">\({}_{n}\)</span></em></span> – переменные, входящие в запрос, а t<span class="math">\({}_{1}\)</span>,...,t<span><em><span class="math">\({}_{n}\)</span></em></span> – основные термы.</p>
<p><span><strong>Определение</strong></span>. Множество H = H<span class="math">\({}_{0}\)</span><span class="math">\(\bigcup \)</span>H<span class="math">\({}_{1}\)</span><span class="math">\(\bigcup \)</span>…<span class="math">\(\bigcup \)</span>H<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\(\bigcup \)</span>…называется эрбрановским универсумом множества формул Г, если:</p>
<p>Н<span class="math">\({}_{0}\)</span> – множество всех констант из Г</p>
<p>H<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{+1}\)</span> = H<span class="math">\(\bigcup \)</span><span class="math">\(\{\)</span>f(t<span class="math">\({}_{1}\)</span>,...,t<span><em><span class="math">\({}_{n}\)</span></em></span>f – функции из Г, t<span class="math">\({}_{1}\)</span>,...,t<span><em><span class="math">\({}_{n}\)</span></em></span> <span class="math">\(\in \)</span>H<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\(\}\)</span> Терм P<span><em><span class="math">\({}_{i}\)</span></em></span>(t<span class="math">\({}_{1}\)</span>,...,t<span><em><span class="math">\({}_{n}\)</span></em></span>), где P<span><em><span class="math">\({}_{i}\)</span></em></span> – предикат из Г, а t<span class="math">\({}_{1}\)</span>,...,t<span><em><span class="math">\({}_{n}\)</span></em></span><span class="math">\(\in \)</span>H, называется основным термом. Эрбрановским базисом называется множество всех основных термов. <span><strong>Определение</strong></span>. Эрбрановской интерпретацией для множества формул Г называется интерпретация I с областью Н(Г), если:</p>
<p>для любой константы c из Г, c<span class="math">\({}_{I}\)</span> = c</p>
<p>для любой функции f из Г и для любых t<span class="math">\({}_{1}\)</span>,...,t<span><em><span class="math">\({}_{n}\)</span></em></span> <span class="math">\(\in \)</span>H, f(t<span class="math">\({}_{1}\)</span>,...,t<span><em><span class="math">\({}_{n}\)</span></em></span>)<span class="math">\({}_{I}\)</span> = f(t<span class="math">\({}_{1}\)</span>,..,t<span><em><span class="math">\({}_{n}\)</span></em></span>)</p>
<p><span><strong>Определение</strong></span>. Эрбрановская интерпретация I называется моделью для программы P, если I = P.</p>
<p><span><strong>Теорема (об основном правильном ответе)</strong></span>. Пусть P – программа, A – атом c переменными <span class="math">\(\{\)</span><span><em>y</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>y<span class="math">\({}_{n}\)</span></em></span><span class="math">\(\}\)</span>, <span class="math">\(\theta \)</span> = <span class="math">\(\{\)</span><span><em>y</em></span><span class="math">\({}_{1}\)</span>/t<span class="math">\({}_{1}\)</span>,...,<span><em>y<span class="math">\({}_{n}\)</span></em></span>/t<span><em><span class="math">\({}_{n}\)</span></em></span>, где t<span class="math">\({}_{1}\)</span>,...,t<span><em><span class="math">\({}_{n}\)</span></em></span> – основные термы. <span class="math">\(\theta \)</span> является правильным ответом на запрос ?A тогда и только тогда, когда A<span class="math">\(\theta \)</span> = M<span class="math">\({}_{P}\)</span>, где M<span class="math">\({}_{P}\)</span> – наименьшая эрбрановская интерпретация, являющаяся моделью для P.</p>
<p><span><em>Операционная семантика</em></span> <span><strong>Определение</strong></span>. Подстановка <span class="math">\(\theta \)</span> называется унификатором выражений E<span class="math">\({}_{1}\)</span> и E<span class="math">\({}_{2}\)</span>, если E<span class="math">\({}_{1}\)</span><span class="math">\(\theta \)</span> = E<span class="math">\({}_{2}\)</span><span class="math">\(\theta \)</span>. Унификатор <span class="math">\(\eta \)</span> выражений E<span class="math">\({}_{1}\)</span> и E<span class="math">\({}_{2}\)</span> называется наиболее общим унификатором (НОУ), если для любого унификатора <span class="math">\(\theta \)</span> <span class="math">\(\exists \)</span>подстановка <span class="math">\(\rho \)</span>, что <span class="math">\(\theta \)</span> = <span class="math">\(\eta \)</span><span class="math">\(\rho \)</span>, т.е. <span class="math">\(\theta \)</span> является суперпозицией подстановок <span class="math">\(\eta \)</span> и <span class="math">\(\rho \)</span>. <span><strong>Определение</strong></span>. Пусть G = ?C<span class="math">\({}_{1}\)</span>,...,C<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{-1}\)</span>, C<span><em><span class="math">\({}_{i}\)</span></em></span>, C<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{+1}\)</span>,...,C<span><em><span class="math">\({}_{n}\)</span></em></span> – запрос к программе P, D = A<span class="math">\({}_{0}\)</span> :- A<span class="math">\({}_{1}\)</span>,...,A<span><em><span class="math">\({}_{n}\)</span></em></span> – программное утверждение из P, причем множества переменных G и D не пересекаются, <span class="math">\(\theta \)</span> - НОУ для C<span><em><span class="math">\({}_{i}\)</span></em></span> и A<span class="math">\({}_{0}\)</span>. Тогда G’ = ?(C<span class="math">\({}_{1}\)</span>,...,C<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{-1}\)</span>,A<span class="math">\({}_{1}\)</span>,...,A<span><em><span class="math">\({}_{n}\)</span></em></span>,C<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{+1}\)</span>,...,C<span><em><span class="math">\({}_{n}\)</span></em></span>) <span class="math">\(\theta \)</span> называется SLD-резольвентой запроса G к программе P с выделенной подцелью C<span><em><span class="math">\({}_{i}\)</span></em></span> и активизированными программным утверждением D и наиболее общим унификатором <span class="math">\(\theta \)</span>. <span><strong>Определение</strong></span>. Пусть G<span class="math">\({}_{0}\)</span> – запрос к программе P. Тогда последовательность (G<span class="math">\({}_{0}\)</span>, <span class="math">\(\theta \)</span><span class="math">\({}_{0}\)</span>), (G<span class="math">\({}_{1}\)</span>, <span class="math">\(\theta \)</span><span class="math">\({}_{1}\)</span>),...., (G<span><em><span class="math">\({}_{n}\)</span></em></span>, <span class="math">\(\theta \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>), где G<span><em><span class="math">\({}_{i}\)</span></em></span><span class="math">\({}_{+1}\)</span> – SLD-резольвента G<span><em><span class="math">\({}_{i}\)</span></em></span>, называется частичным SLD-вычислением ответа на запрос G<span class="math">\({}_{0}\)</span> к программе P. <span><strong>Определение</strong></span>. <span class="math">\(\times\)</span>астичное SLD-вычисление ответа на запрос G к программе P называется SLD-вычислением, если:</p>
<p><span class="math">\(\times\)</span>астичное SLD-вычисление имеет вид (G<span class="math">\({}_{0}\)</span>, <span class="math">\(\theta \)</span><span class="math">\({}_{0}\)</span>),...,(G<span><em><span class="math">\({}_{n}\)</span></em></span>, <span class="math">\(\theta \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>), □ и результатом выполнения запроса (G<span><em><span class="math">\({}_{n}\)</span></em></span>, <span class="math">\(\theta \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>) является пустой запрос. Это успешное SLD-вычисление</p>
<p><span class="math">\(\times\)</span>астичное SLD-вычисление имеет вид (G<span class="math">\({}_{0}\)</span>, <span class="math">\(\theta \)</span><span class="math">\({}_{0}\)</span>),...,(G<span><em><span class="math">\({}_{n}\)</span></em></span>, <span class="math">\(\theta \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>), ■ и ни одно выделение подцели G<span><em><span class="math">\({}_{n}\)</span></em></span> и ни одна активизация программного утверждение неприменимы для получения SLD-резольвенты. Такое вычисление называется тупиковым.</p>
<p>(G<span class="math">\({}_{0}\)</span>, <span class="math">\(\theta \)</span><span class="math">\({}_{0}\)</span>),...,(G<span><em><span class="math">\({}_{n}\)</span></em></span>, <span class="math">\(\theta \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>),... – бесконечное вычисление Определение. Пусть (G<span class="math">\({}_{0}\)</span>, <span class="math">\(\theta \)</span><span class="math">\({}_{0}\)</span>),...,(G<span><em><span class="math">\({}_{n}\)</span></em></span>, <span class="math">\(\theta \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>), □ – успешное SLD-вычисление ответа на запрос G<span class="math">\({}_{0}\)</span> к программе P, <span class="math">\(\{\)</span><span><em>y</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>y<span class="math">\({}_{n}\)</span></em></span><span class="math">\(\}\)</span> – множество переменных G<span class="math">\({}_{0}\)</span>. Тогда подстановка <span class="math">\(\eta \)</span>= <span class="math">\(\theta \)</span><span class="math">\({}_{0}\)</span>... <span class="math">\(\theta \)</span><span><em><span class="math">\({}_{n}\)</span></em></span> <span class="math">\({}_{1}\)</span>,...<span><em>y<span class="math">\({}_{n}\)</span></em></span> – проекция композиции подстановок <span class="math">\(\theta \)</span><span class="math">\({}_{0}\)</span>... <span class="math">\(\theta \)</span><span><em><span class="math">\({}_{n}\)</span></em></span> на переменные <span><em>y</em></span><span class="math">\({}_{1}\)</span>,...,<span><em>y<span class="math">\({}_{n}\)</span></em></span> называется вычисленным ответом на G<span class="math">\({}_{0}\)</span> к P.</p>
<p><span><strong>Теорема (о корректности вычисленных ответов)</strong></span>. Пусть <span class="math">\(\theta \)</span> - вычисленный ответ на запрос G к P. Тогда <span class="math">\(\theta \)</span> - правильный ответ.</p>
<p><span><strong>Теорема (о полноте относительно вычисленных ответов)</strong></span>. Пусть <span class="math">\(\theta \)</span> - правильный ответ на запрос G к P. Тогда <span class="math">\(\exists \)</span> вычисленный ответ <span class="math">\(\lambda \)</span>, такой что <span class="math">\(\exists \)</span> подстановка <span class="math">\(\rho \)</span>, что <span class="math">\(\theta \)</span> = <span class="math">\(\lambda \)</span><span class="math">\(\rho \)</span>.</p>
<p><span><strong>Определение</strong></span>. Правилом вычисления R называется правило, по которому выбирается подцель C<span><em><span class="math">\({}_{i}\)</span></em></span> на каждом шаге SLD-вычисления запроса G к программе P.</p>
<p>Стандартное правило вычислений – выбирать всегда самую левую подцель.</p>
<p><span><strong>Определение</strong></span>. Пусть G – запрос к программе P, R – правило вычислений. Деревом вычислений запроса G к программе P по правилу R называется корневое дерево, построенное по следующим правилам:</p>
<p>Корень дерева помечен исходным запросом.</p>
<p>Если вершина V помечена запросом G’, а G<span class="math">\({}_{1}\)</span>”,...,G<span><em><span class="math">\({}_{n}\)</span></em></span>” – всевозможные SLD-резольвенты, полученные из G’ по правилу R c НОУ <span class="math">\(\theta \)</span><span class="math">\({}_{1}\)</span>,..., <span class="math">\(\theta \)</span><span><em><span class="math">\({}_{n}\)</span></em></span> соответственно, то из V выходит n дуг к вершинам U<span class="math">\({}_{1}\)</span>,...,U<span><em><span class="math">\({}_{n}\)</span></em></span>, помеченным G<span class="math">\({}_{1}\)</span>”,...,G<span><em><span class="math">\({}_{n}\)</span></em></span>”, а дуги помечены <span class="math">\(\theta \)</span><span class="math">\({}_{1}\)</span>,..., <span class="math">\(\theta \)</span><span><em><span class="math">\({}_{n}\)</span></em></span>. <span><strong>Определение</strong></span>. Стратегией вычисления запроса G к программе P называется порядок обхода дерева SLD-вычислений.</p>
<p>Возможные стратегии обхода - в ширину и в глубину.</p>
<p><span><strong>5. Транзакционное управление в СУБД. Методы сериализации транзакций. </strong></span> <span><strong>Определение</strong></span>. Транзакция - это последовательность операций над БД, рассматриваемых СУБД как единое целое. Либо транзакция успешно выполняется, и СУБД фиксирует изменения БД, произведенные этой транзакцией, во внешней памяти, либо ни одно из этих изменений никак не отражается на состоянии БД. Понятие транзакции необходимо для поддержания логической целостности БД.</p>
<p>К транзакциям обычно предъявляются следующие требования:</p>
<p>atomicy – атомарность транзакции. Транзакция понимается как единица пользовательской активности по отношению к базе данных.</p>
<p>consistency – база данных находится в согласованном состоянии до начала транзакции и должна остаться в согласованном состоянии после успешного завершения транзакции, либо после ее отката.</p>
<p>isolation – отсутствие влияния различных транзакций друг на друга. Пользователь, работающий с СУБД, не должен ощущать на себе влияние работы других пользователей с той же базой данных.</p>
<p>durability – устойчивость внесенных изменений. Если транзакция была успешно выполнена и пользователь получил соответствующее подтверждение, то никакие дальнейшие события не могут отменить или исказить результаты этой транзакции.</p>
<p><span><strong>Определение</strong></span>. Под сериализацией параллельно выполняющихся транзакций понимается такой порядок их работы, что суммарный эффект их смешанного выполнения эквивалентен эффекту некоторого последовательного их выполнения.</p>
<p><span><em>Метод сериализации, основанный на синхронизационных захватах</em></span> Наиболее распространенным в централизованных СУБД (включающих системы, основанные на архитектуре “клиент-сервер”) является подход, основанный на соблюдении двухфазного протокола синхронизационных захватов объектов БД. В общих чертах протокол состоит в том, что перед выполнением любой операции в транзакции T над объектом базы данных r от имени транзакции T запрашивается синхронизационный захват объекта r в соответствующем режиме (в зависимости от вида операции).</p>
<p>Основными режимами синхронизационных захватов являются:</p>
<p>совместный режим - S (Shared), означающий разделяемый захват объекта и требуемый для выполнения операции чтения объекта;</p>
<p>монопольный режим - X (eXclusive), означающий монопольный захват объекта и требуемый для выполнения операций занесения, удаления и модификации. Захваты объектов несколькими транзакциями по чтению совместимы, т.е. нескольким транзакциям допускается читать один и тот же объект, захват объекта одной транзакцией по чтению не совместим с захватом другой транзакцией того же объекта по записи, и захваты одного объекта разными транзакциями по записи не совместимы.</p>
<p>Для обеспечения сериализации транзакций синхронизационные захваты объектов, произведенные по инициативе транзакции, можно снимать только при ее завершении. Это требование порождает двухфазный протокол синхронизационных захватов. В соответствии с этим протоколом выполнение транзакции разбивается на две фазы:</p>
<p>первая фаза транзакции - накопление захватов;</p>
<p>вторая фаза (фиксация или откат) - освобождение захватов.</p>
<p>Объектами захвата могут служить:</p>
<p>файл - физический (с точки зрения базы данных) объект, область хранения нескольких отношений и, возможно, индексов;</p>
<p>отношение - логический объект, соответствующий множеству кортежей данного отношения;</p>
<p>страница данных - физический объект, хранящий кортежи одного или нескольких отношений, индексную или служебную информацию;</p>
<p>кортеж - элементарный физический объект базы данных.</p>
<p>Одним из наиболее чувствительных недостатков метода сериализации транзакций на основе синхронизационных захватов является возможность возникновение тупиков (deadlocks) между транзакциями. Поскольку тупики возможны, и никакого естественного выхода из тупиковой ситуации не существует, то эти ситуации необходимо обнаруживать и искусственно устранять.</p>
<p>Основой обнаружения тупиковых ситуаций является построение (или постоянное поддержание) графа ожидания транзакций. Граф ожидания транзакций - это ориентированный двудольный граф, в котором существует два типа вершин - вершины, соответствующие транзакциям, и вершины, соответствующие объектам захвата. В этом графе существует дуга, ведущая из вершины-транзакции к вершине-объекту, если для этой транзакции существует удовлетворенный захват объекта. В графе существует дуга из вершины-объекта к вершине-транзакции, если транзакция ожидает удовлетворения захвата объекта. Легко показать, что в системе существует ситуация тупика, если в графе ожидания транзакций имеется хотя бы один цикл. Для разрешения тупика откатывается одна или несколько транзакций, так, чтобы остальные могли продолжить свою работу.</p>
<p><span><em>Метод сериализации, основанный на временных метках</em></span> Альтернативный метод сериализации транзакций, хорошо работающий в условиях редких конфликтов транзакций и не требующий построения графа ожидания транзакций, основан на использовании временных меток.</p>
<p>Основная идея метода (у которого существует множество разновидностей) состоит в следующем: если транзакция T<span class="math">\({}_{1}\)</span> началась раньше транзакции T<span class="math">\({}_{2}\)</span>, то система обеспечивает такой режим выполнения, как если бы T1 была целиком выполнена до начала T<span class="math">\({}_{2}\)</span>. Для этого каждой транзакции T предписывается временная метка t, соответствующая времени начала T. При выполнении операции над объектом r транзакция T помечает его своей временной меткой и типом операции (чтение или изменение).</p>
<p>Перед выполнением операции над объектом r транзакция T<span class="math">\({}_{1}\)</span> выполняет следующие действия:</p>
<p>Проверяет, не закончилась ли транзакция T, пометившая этот объект. Если T закончилась, T<span class="math">\({}_{1}\)</span> помечает объект r и выполняет свою операцию.</p>
<p>Если транзакция T не завершилась, то T<span class="math">\({}_{1}\)</span> проверяет конфликтность операций. Если операции неконфликтны, при объекте r остается или проставляется временная метка с меньшим значением, и транзакция T1 выполняет свою операцию.</p>
<p>Если операции T<span class="math">\({}_{1}\)</span> и T конфликтуют, то если t(T) <span class="math">\(&gt;\)</span> t(T<span class="math">\({}_{1}\)</span>) (т.е. транзакция T является более “молодой”, чем T<span class="math">\({}_{1}\)</span>), производится откат T и T<span class="math">\({}_{1}\)</span> продолжает работу.</p>
<p>Если же t(T) <span class="math">\(&lt;\)</span> t(T<span class="math">\({}_{1}\)</span>) (T “старше” T<span class="math">\({}_{1}\)</span>), то T<span class="math">\({}_{1}\)</span> получает новую временную метку и начинается заново.</p>
<p>К недостаткам метода временных меток относятся потенциально более частые откаты транзакций, чем в случае использования синхронизационных захватов. Это связано с тем, что конфликтность транзакций определяется более грубо. Кроме того, в распределенных системах не очень просто вырабатывать глобальные временные метки с отношением полного порядка.</p>
<p><span><strong>6.</strong></span> <span><strong>Аппаратно-программные средства поддержки мультипрограммного режима - система</strong></span> <span><strong>прерываний, защита памяти, привилегированный режим.</strong></span> Если система обрабатывает единственную программу, то в это время ЦП не производит никакой полезной работы, то есть простаивает (на самом деле термин простой достаточно условный, так как при этом работает операционная система).</p>
<div class="figure">
<img src="image1" alt="image" /><p class="caption">image</p>
</div>
<p>Решением проблемы простоя ЦП в этом случае является использование ВС в <span><strong><span><em>мультипрограммном режиме</em></span></strong></span>, в режиме при котором возможна организация переключения выполнения с одной программы на другую</p>
<div class="figure">
<img src="image2" alt="image" /><p class="caption">image</p>
</div>
<p>На рисунке изображена подобная мультипрограммная система, обрабатывающая одновременно 4 программы (процесса). t<span class="math">\({}_{1}\)</span> – момент времени в который программа<span class="math">\({}_{1}\)</span> будет остановлена для ожидания завершения обмена (до момента времени t<span class="math">\({}_{4}\)</span>). В момент времени t<span class="math">\({}_{1}\)</span> система запускает выполнение программы<span class="math">\({}_{2}\)</span>, которая выполняется до момента времени t<span class="math">\({}_{2}\)</span>. С t<span class="math">\({}_{2}\)</span> программа<span class="math">\({}_{2}\)</span> также начинает ждать завершения своего обмена и т.д. Для корректной организации мультипрограммной обработки необходима аппаратная поддержка ЭВМ. Как минимум аппаратура ЭВМ должна поддерживать следующие функции.</p>
<p><span><strong><span><em>Аппарат защиты памяти</em></span></strong></span>. Аппаратная возможность ассоциирования некоторых областей ОЗУ с одним из выполняющихся процессов/программ. Настройка аппарата защиты памяти происходит аппаратно, то есть назначение программе/процессу области памяти происходит программно (т.е., в общем случае операционная система устанавливает соответствующую информацию в специальных регистрах), а контроль за доступом – автоматически. При этом при попытке другим процессом/программой обратиться к этим областям ОЗУ происходит прерывание “Защита памяти”</p>
<p>Наличие специального режима <span><strong><span><em>операционной системы (привилегированный режимом или режим супервизора)</em></span></strong></span> ЦП. Суть заключается в следующем: все множество машинных команд разбивается на 2 группы. Первая группа – команды, которые могут исполняться всегда (пользовательские команды). Вторая группа – команды, которые могут исполняться только в том случае, если ЦП работает в режиме ОС. Если ЦП работает в режиме пользователя, то попытка выполнения специализированной команды вызовет прерывание – &quot;Запрещенная команда”. Какова необходимость наличия такого режима выполнения команд? Простой пример – управление аппаратом защиты памяти. Для корректного функционирования этого аппарата необходимо обеспечить централизованный доступ к командам настройки аппарата защиты памяти. То есть эта возможность должна быть доступна не всем программам.</p>
<p>Необходимо наличие аппарата прерываний. Как минимум в машине должно быть прерывание по таймеру, что позволит избежать ``зависания`` всей системы при зацикливании одной из программ.</p>
<p><span>****</span></p>
<p><span>****</span></p>
<p><span><strong>7. Организация взаимодействия процессов и средства их синхронизации. Классические задачи синхронизации.</strong></span> В различных системах используются различные трактовки определения термина <span><strong><span><em>процесс</em></span></strong></span>. Рассмотрим уточнение понятия процесса.</p>
<p><span><strong><span><em>Полновесные процессы</em></span></strong></span> - это процессы, выполняющиеся внутри защищенных участков памяти операционной системы, то есть имеющие собственные виртуальные адресные пространства для статических и динамических данных. В мультипрограммной среде управление такими процессами тесно связано с управлением и защитой памяти, поэтому переключение процессора с выполнения одного процесса на выполнение другого является достаточно дорогой операцией. В дальнейшем, используя термин <span><strong><span><em>процесс</em></span></strong></span> будем подразумевать <span><strong><span><em>полновесный процесс</em></span></strong></span>.</p>
<p><span><strong><span><em>Легковесные процессы</em></span></strong></span>, называемые еще как <span><strong><span><em>нити</em></span></strong></span> или <span><strong><span><em>сопрограммы</em></span></strong></span>, не имеют собственных защищенных областей памяти. Они работают в мультипрограммном режиме одновременно с активировавшей их задачей и используют ее виртуальное адресное пространство, в котором им при создании выделяется участок памяти под динамические данные (стек), то есть они могут обладать собственными локальными данными. Нить описывается как обычная функция, которая может использовать статические данные программы. Для одних операционных систем можно сказать, что нити являются некоторым аналогом процесса, а в других нити представляют собой части процессов. Таким образом, обобщая можно сказать – в любой операционной системе понятие «процесс» включает в себя следующее:</p>
<p>исполняемый код;</p>
<p>собственное адресное пространство, которое представляет собой совокупность виртуальных адресов, которые может использовать процесс;</p>
<p>ресурсы системы, которые назначены процессу ОС;</p>
<p>хотя бы одну выполняемую нить.</p>
<p>При этом подчеркнем – понятие процесса может включать в себя понятие исполняемой нити, т. е. однонитевую организацию – «один процесс – одна нить». В данном случае понятие процесса жестко связано с понятием отдельной и недоступной для других процессов виртуальной памяти. С другой стороны, в процессе может несколько нитей, т. е. процесс может представлять собой многонитевую организацию.</p>
<p>Нить также имеет понятие контекста – это информация, которая необходима ОС для того, чтобы продолжить выполнение прерванной нити. Контекст нити содержит текущее состояние регистров, стеков и индивидуальной области памяти, которая используется подсистемами и библиотеками. Как видно, в данном случае характеристики нити во многом аналогичны характеристикам процесса. С точки зрения процесса, нить можно определить как независимый поток управления, выполняемый в контексте процесса. При этом каждая нить, в свою очередь, имеет свой собственный контекст.</p>
<p><span><strong>Взаимодействие процессов. Методы синхронизации</strong></span></p>
<p>Процессы, выполнение которых хотя бы частично перекрывается по времени, называются параллельными. Они могут быть независимыми и взаимодействующими. <span><strong><span><em>Независимые процессы</em></span></strong></span> – процессы, использующие независимое множество ресурсов и на результат работы такого процесса не влияет работа независимого от него процесса. Наоборот – взаимодействующие процессы совместно используют ресурсы и выполнение одного может оказывать влияние на результат другого.</p>
<p>Совместное использование несколькими процессами ресурса ВС, когда каждый из процессов одновременно владеет ресурсом называют <span><strong>разделением ресурса</strong></span>. Разделению подлежат как аппаратные, так программные ресурсы. Разделяемые ресурсы, которые должны быть доступны в текущий момент времени только одному процессу – это так называемые <span><strong>критические ресурсы</strong></span>. Таковыми ресурсами могут быть, как внешнее устройство, так и некая переменная, значение которой может изменяться разными процессами.</p>
<p>Необходимо уметь решать две важнейшие задачи:</p>
<p>Распределение ресурсов между процессами.</p>
<p>Организация защиты адресного пространства и других ресурсов, выделенных определенному процессу, от неконтролируемого доступа со стороны других процессов. Важнейшим требованием мультипрограммирования с точки зрения распределения ресурсов является следующее: результат выполнения процесса не должен зависеть от порядка переключения выполнения между процессами, т.е. от соотношения скорости выполнения процесса со скоростями выполнения других процессов.</p>
<p>Рассмотрим ситуацию, изображенную на Рис. 1:</p>
<p><span><strong>Рис. 1 Конкуренция процессов за ресурс.</strong></span> В этом случае символ, считанный процессом <span><strong>А</strong></span>, был потерян, а символ, считанный процессом В, был выведен дважды. Результат выполнения процессов здесь зависит от того, в какой момент осуществляется переключение процессов, и от того, какой конкретно процесс будет выбран для выполнения следующим. Такие ситуации называются <span><strong>гонками</strong></span> (race conditions) между процессами, а процессы – конкурирующими. Единственный способ избежать гонок при использовании разделяемых ресурсов – контролировать доступ к любым разделяемым ресурсам в системе. При этом необходимо организовать <span><strong>взаимное исключение</strong></span> – т.е. такой способ работы с разделяемым ресурсом, при котором постулируется, что в тот момент, когда один из процессов работает с разделяемым ресурсом, все остальные процессы не могут иметь к нему доступ.</p>
<p>Проблему организации взаимного исключения можно сформулировать в более общем виде. <span class="math">\(\times\)</span>асть программы (фактически набор операций), в которой осуществляется работа с критическим ресурсом, называется <span><strong>критической секцией</strong></span>, или <span><strong>критическим интервалом</strong></span>. Задача взаимного исключения в этом случае сводится к тому, чтобы не допускать ситуации, когда два процесса одновременно находятся в критических секциях, связанных с одним и тем же ресурсом. Заметим, что вопрос организации взаимного исключения актуален не только для взаимосвязанных процессов, совместно использующих определенные ресурсы для обмена информацией. Выше отмечалось, что возможна ситуация, когда процессы, не подозревающие о существовании друг друга, используют глобальные ресурсы системы, такие как устройства ввода/вывода, принтеры и т.п. В с этом случае имеет место конкуренция за ресурсы, доступ к которым также должен быть организован по принципу взаимного исключения.</p>
<p>При организации взаимного исключения могут возникнуть <span><strong>тупики</strong></span> <span><strong>(deadlocks</strong></span>), ситуации в которой конкурирующие за критический ресурс процессы вступают в клинч – безвозвратно блокируются. Есть два процесса <span><strong>А</strong></span> и <span><strong>В</strong></span>, каждому из которых в некоторый момент требуется иметь доступ к двум ресурсам <span><strong>R<span class="math">\({}_{1}\)</span></strong></span><span class="math">\({}_{ }\)</span>и <span><strong>R<span class="math">\({}_{2}\)</span>.</strong></span> Процесс <span><strong>А</strong></span> получил доступ к ресурсу <span><strong>R<span class="math">\({}_{1}\)</span></strong></span><span class="math">\({}_{, }\)</span>и следовательно, никакой другой процесс не может иметь к нему доступ, пока процесс <span><strong>А </strong></span>не закончит с ним работать. Одновременно процесс <span><strong>В</strong></span> завладел ресурсом <span><strong>R<span class="math">\({}_{2}\)</span>.</strong></span> В этой ситуации каждый из процессов ожидает освобождения недостающего ресурса, но оба ресурса никогда не будут освобождены, и процессы никогда не смогут выполнить необходимые действия.</p>
<p>Далее мы рассмотрим различные механизмы организации взаимного исключения для синхронизации доступа к разделяемым ресурсам и обсудим достоинства, недостатки и области применения этих подходов.</p>
<p>Рассмотри классические методы (средства) синхронизации.</p>
<p><span><em>Семафоры Дейкстры</em></span></p>
<p>Тип данных, именуемый . Семафор представляет собой переменную целого типа <span><strong>S</strong></span>, над которой определены две операции: <span><strong>down(s)</strong></span> (или <span><strong>P(S)</strong></span>) и <span><strong>up(S)</strong></span> (или <span><strong>V(S)</strong></span>). Оригинальные обозначения <span><strong>P</strong></span> и <span><strong>V</strong></span>, данные Дейкстрой и получившие широкое распространение в литературе, являются сокращениями голландских слов <span><em>proberen</em></span> – проверить и <span><em>verhogen</em></span> – увеличить.</p>
<p>Операция <span><strong>down(S)</strong></span> проверяет значение семафора, и если оно больше нуля, то уменьшает его на <span><strong>1</strong></span>. Если же это не так, процесс блокируется, причем операция <span><strong>down</strong></span> считается незавершенной. Важно отметить, что вся операция является неделимой, т. е. Проверка значения, его уменьшение и, возможно, блокирование процесса производится как одно атомарное действие, которое не может быть прервано. Операция <span><strong>up(S)</strong></span> увеличивает значение семафора на <span><strong>1</strong></span>. При этом, если в системе присутствуют процессы, блокированные ранее при выполнении down на этом семафоре, ОС разблокирует один из них с тем, чтобы он завершил выполнение операции <span><strong>down</strong></span>, т. е. Вновь уменьшил значение семафора. При этом также постулируется, что увеличение значения семафора и, возможно, разблокирование одного из процессов и уменьшение значения являются атомарной неделимой операцией.</p>
<p><span class="math">\(\times\)</span>тобы прокомментировать работу семафора рассмотрим пример. Представим себе супермаркет, посетители которого прежде чем войти в торговый зал должны обязательно взять себе инвентарную тележку. В момент открытия магазина на входе имеется N свободных тележек – это начальное значение семафора. Каждый посетитель забирает одну из тележек (уменьшая тем самым количество оставшихся на 1) и проходит в торговый зал – это аналог операции down. При выходе посетитель возвращает тележку на место, увеличивая количество тележек на 1 – это аналог операции up. Теперь представим себе, что очередной посетитель обнаруживает, что свободных тележек нет – он вынужден <span><strong>блокироваться</strong></span> на входе в ожидании появления тележки. Когда один из посетителей, находящихся в торговом зале, покидает его, посетитель, ожидающий тележку, <span><strong>разблокируется</strong></span>, забирает тележку и проходит в зал. Таким образом, наш семафор в виде тележек позволяет находиться в торговом зале (аналоге критической секции) не более чем N посетителям одновременно. Положив N=1, получим реализацию взаимного исключения. Семафор, начальное (и максимальное) значение которого равно 1, называется двоичным семафором (т. к. имеет только 2 состояния: 0 и 1).</p>
<p>Семафоры – это низкоуровневые средства синхронизации, для корректной практической реализации которых необходимо наличие специальных, атомарных семафорных машинных команд.</p>
<p><span><em>Мониторы Хоара</em></span></p>
<p>Идея <span><strong>монитора</strong></span> была впервые сформулирована в metricconverterProductID1974 ?1974 г1974 г. Хоаром. В отличие от других средств, монитор представляет собой <span><em>языковую</em></span> конструкцию, т. е. Некоторое средство, предоставляемое языком программирования и поддерживаемое компилятором. Монитор представляет собой совокупность процедур и структур данных, объединенных в программный модуль специального типа. Постулируются три основных свойства монитора:</p>
<p>структуры данных, входящие в монитор, могут быть доступны только для процедур, входящих в этот монитор (таким образом, монитор представляет собой некоторый аналог объекта в объектно-ориентированных языках и реализует инкапсуляцию данных);</p>
<p>процесс «входит» в монитор путем вызова одной из его процедур;</p>
<p>в любой момент времени внутри монитора может находиться не более одного процесса. Если процесс пытается попасть в монитор, в котором уже находится другой процесс, он блокируется. Таким образом, чтобы защитить разделяемые структуры данных, иx достаточно поместить внутрь монитора вместе с процедурами, представляющими критические секции для их обработки.</p>
<p>Монитор представляет собой конструкцию языка программирования и компилятору известно о том, что входящие в него процедуры и данные имеют особую семантику, поэтому первое условие может проверяться еще на этапе компиляции, кроме того, код для процедур монитора тоже может генерироваться особым образом, чтобы удовлетворялось третье условие. Поскольку организация взаимного исключения в данном случае возлагается на компилятор, количество программных ошибок, связанных с организацией взаимного исключения, сводится к минимуму.</p>
<p><span><strong>Классические задачи синхронизации процессов</strong></span></p>
<p><span><em>«Обедающие философы»</em></span></p>
<p>Пять философов собираются за круглым столом, перед каждым из них стоит блюдо со спагетти, и между каждыми двумя соседями лежит вилка. Каждый из философов некоторое время размышляет, затем берет две вилки (одну в правую руку, другую в левую) и ест спагетти, затем опять размышляет и так далее. Каждый из них ведет себя независимо от других, однако вилок запасено ровно столько, сколько философов, хотя для еды каждому из них нужно две. Таким образом, философы должны совместно использовать имеющиеся у них вилки (ресурсы). Задача состоит в том, чтобы найти алгоритм, который позволит философам организовать доступ к вилкам таким образом, чтобы каждый имел возможность насытиться, и никто не умер с голоду.</p>
<p>Рассмотрим простейшее решение, использующее семафоры. Когда один из философов хочет есть, он берет вилку слева от себя, если она в наличии, а затем - вилку справа от себя. Закончив есть, он возвращает обе вилки на свои места. Данный алгоритм может быть представлен следующим способом:</p>
<p>#define N 5 /* число философов*/ void philosopher (int i) /* i – номер философа от 0 до 4*/ <span class="math">\(\{\)</span> while (TRUE)</p>
<p><span class="math">\(\{\)</span> think(); /*философ думает*/ take_fork(i); /*берет левую вилку*/ take_fork((i+1)%N); /*берет правую вилку*/ eat(); /*ест*/ put_fork(i); /*кладет обратно левую вилку*/ put_fork((i+1)%N); /* кладет обратно правую вилку */ <span class="math">\(\}\)</span> <span class="math">\(\}\)</span> Функция <span><strong>take_fork(i)</strong></span> описывает поведение философа по захвату вилки: он ждет, пока указанная вилка не освободится, и забирает ее. Данное решение может привести к тупиковой ситуации. <span class="math">\(\times\)</span>то произойдет, если все философы захотят есть в одно и то же время? Каждый из них получит доступ к своей левой вилке и будет находиться в состоянии ожидания второй вилки до бесконечности. Другим решением может быть алгоритм, который обеспечивает доступ к вилкам только четырем из пяти философов. Тогда всегда среди четырех философов по крайней мере один будет иметь доступ к двум вилкам. Данное решение не имеет тупиковой ситуации. Алгоритм решения может быть представлен следующим образом:</p>
<p># define N 5 /* количество философов */</p>
<p># define LEFT (i-1)%N /* номер легого соседа для i-ого философа */</p>
<p># define RIGHT (i+1)%N /* номер правого соседа для i-ого философа*/</p>
<p># define THINKING 0 /* философ думает */</p>
<p># define HUNGRY 1 /* философ голоден */</p>
<p># define EATING 2 /* философ ест */</p>
<p>typedef int semaphore; /* определяем семафор */</p>
<p>int state[N]; /* массив состояний каждого из философов */</p>
<p>semaphore mutex=1; /* семафор для критической секции */</p>
<p>semaphore s[N]; /* по одному семафору на философа */</p>
<p>void philosopher (int i) /* i : номер философа от 0 до N-1 */</p>
<p><span class="math">\(\{\)</span></p>
<p>while (TRUE) /* бесконечный цикл */</p>
<p><span class="math">\(\{\)</span></p>
<p>think(); /* философ думает */ take_forks(i); /*философ берет обе вилки или блокируется */ eat(); /* философ ест */ put_forks(i); /* философ кладет обе вилки на стол */</p>
<p><span class="math">\(\}\)</span> <span class="math">\(\}\)</span></p>
<p>void take_forks(int i) /* i : номер философа от 0 до N-1 */ <span class="math">\(\{\)</span></p>
<p>down(&amp;mutex); /* вход в критическую секцию */</p>
<p>state[i] = HUNGRY; /*записываем, что i-ый философ голоден */</p>
<p>test(i); /* попытка взять обе вилки */</p>
<p>up(&amp;mutex); /* выход из критической секции */</p>
<p>down(&amp;s[i]); /* блокируемся, если вилок нет */ <span class="math">\(\}\)</span></p>
<p>void put_forks(i) /* i : номер философа от 0 до N-1 */ <span class="math">\(\{\)</span></p>
<p>down(&amp;mutex); /* вход в критическую секцию */</p>
<p>state[i] = THINKING; /* философ закончил есть */ test(LEFT); /* проверить может ли левый сосед сейчас есть */ test(RIGHT); /* проверить может ли правый сосед сейчас есть*/</p>
<p>up(&amp;mutex); /* выход из критической секции */ <span class="math">\(\}\)</span></p>
<p>void test(i) /* i : номер философа от 0 до N-1 */ <span class="math">\(\{\)</span></p>
<p>if (state[i] == HUNGRY &amp;&amp; state[LEFT] != EATING &amp;&amp; state[RIGHT] != EATING)</p>
<p><span class="math">\(\{\)</span></p>
<p>state[i] = EATING; up (&amp;s[i]);</p>
<p><span class="math">\(\}\)</span> <span class="math">\(\}\)</span></p>
<p><span><em>Задача «читателей и писателей»</em></span> Другой классической задачей синхронизации доступа к ресурсам является проблема «читателей и писателей», иллюстрирующая широко распространенную модель совместного доступа к данным. Представьте себе ситуацию, например, в системе резервирования билетов, когда множество конкурирующих процессов хотят читать и обновлять одни и те же данные. Несколько процессов могут читать данные одновременно, но когда один процесс начинает записывать данные (обновлять базу данных проданных билетов), ни один другой процесс не должен иметь доступ к данным, даже для чтения. Вопрос, как спланировать работу такой системы? Одно из решений представлено ниже:</p>
<p>typedef int semaphore; /* некий семафор */ semaphore mutex = 1; /* контроль за доступом к «rc» (разделямый ресурс) */ semaphore db = 1; /* контроль за доступом к базе данных*/ int rc = 0; /* кол-во процессов читающих или пишущих */</p>
<p>void reader (void) <span class="math">\(\{\)</span> while (TRUE) /* бесконечный цикл */ <span class="math">\(\{\)</span> down (&amp;mutex); /* получить эксклюзивный доступ к «rc»*/ rc = rc+1; /* еще одним читателем больше */ if (rc==1) down (&amp;db); /* если это первый читатель, нужно заблокировать эксклюзивный доступ к базе */ up(&amp;mutex); /*освободить ресурс rc */ read_data_base(); /* доступ к данным */ down(&amp;mutex); /*получить эксклюзивный доступ к «rc»*/ rc = rc-1: /* теперь одним читателем меньше */ if (rc==0) up(&amp;db); /*если это был последний читатель, разблокировать эксклюзивный доступ к базе данных */ up(&amp;mutex); /*освободить разделяемый ресурс rc*/ use_data_read(); /* некритическая секция */ <span class="math">\(\}\)</span> <span class="math">\(\}\)</span></p>
<p>void writer (void) <span class="math">\(\{\)</span></p>
<p>while(TRUE) /* бесконечный цикл */</p>
<p><span class="math">\(\{\)</span></p>
<p>think_up_data(); /* некритическая секция */ down(&amp;db); /* получить эксклюзивный доступ к данным*/</p>
<p>write_data_base(); /* записать данные */</p>
<p>up(&amp;db); /* отдать эксклюзивный доступ */</p>
<p><span class="math">\(\}\)</span> <span class="math">\(\}\)</span></p>
<p>В этом примере, первый процесс, обратившийся к базе данных по чтению, осуществляет операцию DOWN над семафором <span><strong>db</strong></span>, тем самым блокируя эксклюзивный доступ к базе, который нужен для записи. <span class="math">\(\times\)</span>исло процессов, осуществляющих чтение в данный момент, определяется переменной <span><strong>rc</strong></span> (обратите внимание! Т.к. переменная <span><strong>rc</strong></span> является разделяемым ресурсом – ее изменяют все процессы, обращающиеся к базе данных по чтению – то доступ к ней охраняется семафором <span><strong>mutex</strong></span>). Когда читающий процесс заканчивает свою работу, он уменьшает <span><strong>rc</strong></span> на единицу. Если он является последним читателем, он также совершает операцию UP над семафором <span><strong>db</strong></span>, тем самым разрешая заблокированному писателю, если такой имелся, получить эксклюзивный доступ к базе для записи. Надо заметить, что приведенный алгоритм дает преимущество при доступе к базе данных процессам-читателям, т.к. процесс, ожидающий доступа по записи, будет ждать до тех пор, пока все читающие процессы не окончат работу, и если в это время появляется новый читающий процесс, он тоже беспрепятственно получит доступ. Это может привести к неприятной ситуации в том случае, если в фазе, когда ресурс доступен по чтению, и имеется ожидающий процесс-писатель, будут появляться новые и новые читающие процессы. <span class="math">\(\times\)</span>тобы этого избежать, можно модифицировать алгоритм таким образом, чтобы в случае, если имеется хотя бы один ожидающий процесс-писатель, новые процессы-читатели не получали доступа к ресурсу, а ожидали, когда процесс-писатель обновит данные. В этой ситуации процесс-писатель должен будет ожидать окончания работы с ресурсом только тех читателей, которые получили доступ раньше, чем он его запросил. Однако, обратная сторона данного решения в том, что оно несколько снижает производительность процессов-читателей, т.к. вынуждает их ждать в тот момент, когда ресурс не занят в эксклюзивном режиме.</p>
<p><span><em>Задача о «спящем парикмахере»</em></span> Рассмотрим парикмахерскую, в которой работает один парикмахер, имеется одно кресло для стрижки и несколько кресел в приемной для посетителей, ожидающих своей очереди. Если в парикмахерской нет посетителей, парикмахер засыпает прямо на своем рабочем месте. Появившийся посетитель должен его разбудить, в результате чего парикмахер приступает к работе. Если в процессе стрижки появляются новые посетители, они должны либо подождать своей очереди, либо покинуть парикмахерскую, если в приемной нет свободного кресла для ожидания. Задача состоит в том, чтобы корректно запрограммировать поведение парикмахера и посетителей. Одно из возможных решений этой задачи представлено ниже. Процедура <span><strong>barber()</strong></span> описывает поведение парикмахера (она включает в себя бесконечный цикл – ожидание клиентов и стрижку). Процедура <span><strong>customer()</strong></span> описывает поведение посетителя. Несмотря на кажущуюся простоту задачи, понадобится целых 3 семафора: <span><strong>customers</strong></span> – подсчитывает количество посетителей, ожидающих в очереди, <span><strong>barbers</strong></span> – обозначает количество свободных парикмахеров (в случае одного парикмахера его значения либо 0, либо 1) и <span><strong>mutex</strong></span> – используется для синхронизации доступа к разделяемой переменной <span><strong>waiting</strong></span>. Переменная <span><strong>waiting</strong></span>, как и семафор <span><strong>customers</strong></span>, содержит количество посетителей, ожидающих в очереди, она используется в программе для того, чтобы иметь возможность проверить, имеется ли свободное кресло для ожидания, и при этом не заблокировать процесс, если кресла не окажется. Заметим, что как и в предыдущем примере, эта переменная является разделяемым ресурсом, и доступ к ней охраняется семафором <span><strong>mutex</strong></span>. Это необходимо, т.к. для обычной переменной, в отличие от семафора, чтение и последующее изменение не являются неделимой операцией.</p>
<p>#define CHAIRS 5 typedef int semaphore; /* некий семафор */</p>
<p>semaphore customers = 0; /* посетители, ожидающие в очереди */ semaphore barbers = 0; /* парикмахеры, ожидающие посетителей */ semaphore mutex = 1; /* контроль за доступом к переменной waiting */ int waiting = 0;</p>
<p>void barber() <span class="math">\(\{\)</span> while (true) <span class="math">\(\{\)</span> down(customers); /* если customers == 0, т.е. посетителей нет, то заблокируемся до появления посетителя */</p>
<p>down(&amp;mutex); /* получаем доступ к waiting */</p>
<p>waiting = wating – 1; /* уменьшаем кол-во ожидающих клиентов */</p>
<p>up(&amp;barbers); /* парикмахер готов к работе */</p>
<p>up(&amp;mutex); /* освобождаем ресурс waiting */</p>
<p>cut_hair(); /* процесс стрижки */ <span class="math">\(\}\)</span>;<span class="math">\(\}\)</span></p>
<p>void customer() <span class="math">\(\{\)</span></p>
<p>down(&amp;mutex); /* получаем доступ к waiting */</p>
<p>if (waiting <span class="math">\(&lt;\)</span> CHAIRS) /* есть место для ожидания */</p>
<p><span class="math">\(\{\)</span> waiting = waiting + 1; /* увеличиваем кол-во ожидающих клиентов */</p>
<p>up(&amp;customers); /* если парикмахер спит, это его разбудит*/</p>
<p>up(&amp;mutex); /* освобождаем ресурс waiting */ down(barbers); /* если парикмахер занят, переходим в состояние ожидания, иначе – занимаем парикмахера*/</p>
<p>get_haircut(); /* занять место и перейти п стрижке */</p>
<p><span class="math">\(\}\)</span> else <span class="math">\(\{\)</span> up(&amp;mutex); /* нет свободного кресла для ожидания – придется уйти */ <span class="math">\(\}\)</span> <span class="math">\(\}\)</span></p>
<p><span><strong>8. Виртуальная память. Модели организации оперативной памяти. </strong></span></p>
<p><span><em>Аппарат виртуальной памяти</em></span></p>
<p>Рассмотрим некоторые проблемы организации адресации в программах/процессах и связанные с ними проблемы использования ОЗУ в целом.</p>
<p>В общем случае схема получения исполняемого кода программы следующая:</p>
<p><img src="image3" alt="image" /> Данная схема достаточно очевидна, так как она связана с привычным для нас процессами трансляции. Остановимся подробней на исполняемом модуле. Данный модуль представляет собой готовую к выполнению программу в машинных кодах. При этом внутри программы к моменту образования исполняемого модуля используется модель организации адресного пространства программы (эта модель, в общем случае не связана с теми ресурсами ОЗУ, которые предполагается использовать позднее). Для простоты будем считать, что данная модель представляет собой непрерывный фрагмент адресного пространства, в пределах которого размещены данные и команды программы. Будем называть подобную организацию адресации в <span><strong><span><em>программе программной адресацией или логической/виртуальной адресацией</em></span></strong></span>. Итак, повторяем, на уровне исполняемого кода имеется программа в машинных кодах, использующая адреса данных и команд. Эти адреса в общем случае не являются адресами конкретных физических ячеек памяти, в которых размещены эти данные, более того, в последствии мы увидим, что виртуальным (или программным) адресам могут ставиться в соответствие произвольные физические адреса памяти. То есть при реальном исполнении программы далеко не всегда виртуальная адресация, используемая в программе совпадает с физической адресацией, используемой ЦП при выполнении данной программы.</p>
<p>Элементарное программно-аппаратное решение – использование возможности <span><strong><span><em>базирования адресов</em></span></strong></span>. Суть его состоит в следующем: пусть имеется исполняемый программный модуль. Виртуальное адресное пространство этого модуля лежит в диапазоне [0, A<span class="math">\({}_{кон}\)</span>]. В ЭВМ выделяется специальный регистр базирования R<span class="math">\({}_{баз.}\)</span>, который содержит физический адрес начала области памяти, в которой будет размещен код данного исполняемого модуля. При этом исполняемые адреса, используемые в модуле будут автоматически преобразовываться в адреса физического размещения данных путем их сложения с регистром R<span class="math">\({}_{баз.}\)</span>. Таким образом код используемого модуля может перемещаться по пространству физического ОЗУ. Эта схема является элементарным решением организации простейшего <span><strong><span><em>аппарата виртуальной памяти</em></span></strong></span>. То есть аппарата, позволяющего автоматически преобразовывать <span><strong><span><em>виртуальные адреса программы</em></span></strong></span> в адреса физической памяти. Рассмотрим более сложные механизмы организации виртуальной памяти.</p>
<p><img src="image4" alt="image" /><img src="image5" alt="image" /> Пусть имеется вычислительная система, функционирующая в мультипрограммном режиме. То есть одновременно в системе обрабатываются несколько программ/процессов. Один из них занимает ресурсы ЦП. Другие ждут завершения операций обмена, третьи – готовы к исполнению и ожидают предоставления ресурсов ЦП. При этом происходит завершение выполнявшихся процессов и ввод новых, это приводит к возникновению проблемы фрагментации ОЗУ. Суть ее следующая. При размещении новых программ/процессов в ОЗУ ЭВМ (для их мультипрограммной обработки) образуются свободные фрагменты ОЗУ между программами/процессами. Суммарный объем свободных фрагментов может быть достаточно большим, но, в то же время, размер самого большого свободного фрагмента недостаточно для размещения в нем новой программы/процесса. В этой ситуации возможна деградация системы – в системе имеются незанятые ресурсы ОЗУ, но они не могут быть использованы. Путь решения этой проблемы – использование более развитых механизмов организации ОЗУ и виртуальной памяти, позволяющие отображать виртуальное адресное пространство программы/процесса не в одну непрерывную область физической памяти, а в некоторую совокупность областей. <span>**<span><strong></span></strong></span> <span><strong><span><em>Организация страничной памяти</em></span></strong></span> Страничная организация памяти предполагает разделение всего пространства ОЗУ на блоки одинакового размера – страницы. Обычно размер страницы равен 2<span class="math">\({}^{k}\)</span>. В этом случае адрес, используемый в данной ЭВМ, будет иметь следующую структуру: <img src="image6" alt="image" /> <img src="image7" alt="image" /></p>
<p>Модельная (упрощенная) схема организации функционирования страничной памяти ЭВМ следующая: Пусть одна система команд ЭВМ позволяет адресовать и использовать m страниц размером 2<span class="math">\({}^{k}\)</span> каждая. То есть виртуальное адресное пространство программы/процесса может использовать для адресации команд и данных до m страниц.</p>
<p>Физическое адресное пространство, в общем случае может иметь произвольное число физических страниц (их может быть больше m, а может быть и меньше). Соответственно структура исполнительного физического адреса будет отличаться от структуры исполнительного виртуального адреса за счет размера поля ”номер страницы”.</p>
<p>В виртуальном адресе размер поля определяется максимальным числом виртуальных страниц – m.</p>
<p>В физическом адресе – максимально возможным количеством физических страниц, которые могут быть подключены к данной ЭВМ (это также фиксированная аппаратная характеристика ЭВМ).</p>
<p>В ЦП ЭВМ имеется аппаратная таблица страниц (иногда таблица приписки) следующей структуры:</p>
<p>Таблица содержит m строк. Содержимое таблицы определяет соответствие виртуальной памяти физической для выполняющейся в данный момент программы/процесса. Соответствие определяется следующим образом: i-я строка таблицы соответствует i-й виртуальной странице. Содержимое строки <span class="math">\(\alpha \)</span><span class="math">\({}_{i}\)</span> определяет, чему соответствует i-я виртуальная страница программы/процесса. Если <span class="math">\(\alpha \)</span><span class="math">\({}_{i}\)</span> ≥ 0, то это означает, что <span class="math">\(\alpha \)</span><span class="math">\({}_{i}\)</span> есть номер физической страницы, которая соответствует виртуальной странице программы/процесса. Если <span class="math">\(\alpha \)</span><span class="math">\({}_{i}\)</span>= -1, то это означает, что для i-й виртуальной страницы нет соответствия физической странице ОЗУ (обработка этой ситуации ниже).</p>
<p>Итак, рассмотрим последовательность действий при использовании аппарата виртуальной страничной памяти.</p>
<p>При выполнении очередной команды схемы управления ЦП вычисляют некоторый адрес операнда (операндов) A<span class="math">\({}_{исп}\)</span>. Это виртуальный исполнительный адрес.</p>
<p>Из A<span class="math">\({}_{исп.}\)</span> Выделяются значимые поля номер страницы (номер виртуальной страницы). По этому значению происходит индексация и доступ к соответствующей строке таблицы страниц.</p>
<p>Если значение строки ≥ 0, то происходит замена содержимого поля номер страницы на соответствующее значение строки таблицы, таким образом, получается физический адрес. И далее ЦП осуществляет работу с физическим адресом.</p>
<p>Если значение строки таблицы равно –1 это означает, что полученный виртуальный адрес не размещен в ОЗУ. Причины такой ситуации? Их две. Первая – данная виртуальная страница отсутствует в перечне станиц, доступных для программы/процесса, то есть имеет место попытка обращения в “ чужую”, не легитимную память. Вторая ситуация, когда операционная система в целях оптимизации использования ОЗУ, откачала некоторые страницы программы/процесса в ВЗУ(свопинг, о действиях ОС при свопинге позднее). <span class="math">\(\times\)</span>то происходит в системе, если значение строки таблицы страниц –1, и мы обратились к этой строке? Происходит прерывание “ защита памяти”, управление передается операционной системе (по стандартной схеме обработки прерывания и далее происходит программная обработка ситуации (обращаем внимание, что все, что выполнялось до сих пор – пункт 1, 2, 3 и 4 – это действия аппаратуры, без какого-либо участия программного обеспечения).ОС по содержимому внутренних данных определяет конечную причину данного прерывания: или это действительно защита памяти, или мы пытались обратиться к странице ОЗУ, которая временно размещена во внешней памяти.</p>
<p>Таким образом, предложенная модель организации виртуальной памяти позволяет решить проблему фрагментации ОЗУ. На самом деле, некоторая фрагментация остается (если в странице занят хотя бы 1 байт, то занята вся страница), но она является контролируемой и не оказывает значительного влияния на производительность системы.</p>
<p>Далее, данная схема позволяет простыми средствами организовать защиту памяти, а также своппирование страниц.</p>
<p>Предложенная модель организации виртуальной памяти позволяет иметь отображение виртуального адресного пространства программы/процесса в произвольные физические адреса, также позволяет выполнять в системе программы/процессы, размещенные в ОЗУ частично (оставшаяся часть может быть размещена во внешней памяти).</p>
<p>Недостаток – необходимость наличия в ЦП аппаратной таблицы значительных размеров.</p>
<p>Итак мы рассмотрели модельный, упрощенный вариант организации виртуальной памяти. Реальные решения используемые в различных архитектурах ЭВМ могут быть гораздо сложнее, но основные идеи остаются неизменными.</p>
<p><span><em>Управление оперативной памятью</em></span></p>
<p>Решение следующих задач:</p>
<p>распределение физической памяти ОЗУ между процессами</p>
<p>программная поддержка виртуальной памяти</p>
<p>подкачка (свопинг)</p>
<p>защита памяти</p>
<p>Конкретные алгоритмы зависят от свойств конкретной ЭВМ. Для модельной ЭВМ будем рассматривать страничную организацию ОЗУ. Пусть имеется ОЗУ, включающее до N физических страниц. Система команд машины позволяет адресовать до k страниц. Рассмотрим пример частичных действий модельно ОС по управлению ОП.</p>
<p>Операционная система формирует таблицу страниц (ТС):</p>
<p>Каждая строка ТС содержит информацию о статусе соответствующей физической страницы:</p>
<p>свободна</p>
<p>принадлежит j-му процессу (в этом случае в строке помещается ссылка на контекст соответствующего процесса)</p>
<p>Для каждого процесса, обрабатываемого в системе в данный момент времени (размещенного в БОП), ОС формирует программные структуры данных, в которых размещается информация контекста. Среди прочих значений в контексте размещается таблица страниц процесса (ТСП). По содержимому ТСП можно получить данные об используемых в процессе виртуальных страницах и их месторасположении. Под месторасположением считаем соответствие виртуальной страницы некоторой физической странице или указание координат места на ВЗУ, где размещена копия данной страницы. Соответственно поддержка решения задач управления ОП будет следующая.</p>
<p>При поступлении процесса в БОП заполняется ТСП. В начальный момент из описателей процесса, сформированных на этапе обработки в БВП выбирается список виртуальных страниц, который размещается в ТСП. Затем ОС анализирует содержимое ТС и «приписывает» виртуальным страницам их физические эквиваленты (при этом идет загрузка содержимого соответствующих виртуальных страниц из внешней памяти в физические страницы ОЗУ).</p>
<p>Для виртуальных страниц процесса, которым не были выделены физические страницы, в ТСП устанавливается признак отсутствия физической страницы (этот признак, также будет проставлен во все строки таблицы, соответствующие виртуальным страницам, не используемым процессом). Формируется содержимое таблицы «откаченных» страниц процесса ТОСП (указывается номер виртуальной страницы и ее месторасположение во внешней памяти).</p>
<p>Далее ОС из контекста данного процесса заполняет содержимое таблицы виртуальных страниц ТВС процессора и передает управление на начало выполнения процесса.</p>
<p>В рассмотренном примере затронуты элементы решения задач распределения физической памяти, поддержки использования аппарата виртуальной памяти, подкачки страниц. На самом деле в реальности полная логика действий существенно сложнее и окончательные настройки аппаратных средств (виртуальной памяти, защиты) есть вершина айсберга тех логически сложных действий, которые предшествуют чисто аппаратной реализации этих функций.</p>
<p>СВОППИНГ</p>
<p>ЗАЩИТА ПАМЯТИ</p>
<p><span>****</span></p>
<p><span><strong>9. Алгоритм Сети-Ульмана оптимального распределения регистров и его обоснование.</strong></span></p>
<p>Пусть система команд машины имеет неограниченное число универсальных регистров, в которых выполняются арифметические команды. Рассмотрим, как можно сгенерировать код, используя для данного арифметического выражения минимальное число регистров. <img src="image8" alt="image" /> Предположим сначала, что распределение регистров осуществляется по простейшей схеме слева-направо. Тогда к моменту генерации кода для поддерева LR занято <span><em>n</em></span> регистров. Пусть поддерево L требует <span><em>n<span class="math">\({}_{l}\)</span></em></span> регистров, а поддерево R - <span><em>n<span class="math">\({}_{r}\)</span></em></span> регистров. Если <span><em>n<span class="math">\({}_{l}\)</span></em></span>=<span><em>n<span class="math">\({}_{r}\)</span></em></span>, то при вычислении L будет использовано <span><em>n<span class="math">\({}_{l}\)</span></em></span> регистров и под результат будет занят <span><em>n</em></span>+1-й регистр. Еще <span><em>n<span class="math">\({}_{r}\)</span></em></span> (=<span><em>n<span class="math">\({}_{l}\)</span></em></span>) регистров будет использовано при вычислении R. Таким образом, общее число использованных регистров будет равно <span><em>n</em></span>+<span><em>n<span class="math">\({}_{l}\)</span></em></span>+1. Если <span><em>n<span class="math">\({}_{l}\)</span></em></span><span class="math">\(&gt;\)</span><span><em>n<span class="math">\({}_{r}\)</span></em></span>, то при вычислении L будет использовано <span><em>n<span class="math">\({}_{l}\)</span></em></span> регистров. При вычислении R будет использовано <span><em>n<span class="math">\({}_{r}\)</span></em></span><span class="math">\(&lt;\)</span><span><em>n<span class="math">\({}_{l}\)</span></em></span> регистров, и всего будет использовано не более чем <span><em>n</em></span>+<span><em>n<span class="math">\({}_{l}\)</span></em></span> регистров. Если <span><em>n<span class="math">\({}_{l}\)</span></em></span><span class="math">\(&lt;\)</span><span><em>n<span class="math">\({}_{r}\)</span></em></span>, то после вычисления L под результат будет занят один регистр (предположим <span><em>n</em></span>+1-й) и <span><em>n<span class="math">\({}_{r}\)</span></em></span> регистров будет использовано для вычисления R. Всего будет использовано <span><em>n</em></span>+<span><em>n<span class="math">\({}_{r}\)</span></em></span>+1 регистров. Видно, что для деревьев, совпадающих с точностью до порядка потомков каждой вершины, минимальное число регистров при распределении их слева-направо достигается на дереве, у которого в каждой вершине слева расположено более “сложное” поддерево, требующее большего числа регистров. Таким образом, если дерево таково, что в каждой внутренней вершине правое поддерево требует меньшего числа регистров, чем левое, то, обходя дерево слева направо, можно оптимально распределить регистры. Без перестройки дерева это означает, что если в некоторой вершине дерева справа расположено более сложное поддерево, то сначала сгенерируем код для него, а затем уже для левого поддерева.</p>
<p>Алгоритм работает следующим образом. Сначала осуществляется разметка синтаксического дерева по следующим правилам:</p>
<p>если вершина - правый лист или дерево состоит из единственной вершины, помечаем эту вершину числом 1, если вершина - левый лист, помечаем ее 0</p>
<p>если вершина имеет прямых потомков с метками <span><em>l</em></span><span class="math">\({}_{1}\)</span> и <span><em>l</em></span><span class="math">\({}_{2}\)</span>, то в качестве метки этой вершины выбираем большее из чисел <span><em>l</em></span><span class="math">\({}_{1}\)</span> или <span><em>l</em></span><span class="math">\({}_{2}\)</span> либо число <span><em>l</em></span><span class="math">\({}_{1}\)</span>+1, если <span><em>l</em></span><span class="math">\({}_{1}\)</span>=<span><em>l</em></span><span class="math">\({}_{2}\)</span>. Эта разметка позволяет определить, какое из поддеревьев требует большего количества регистров для своего вычисления.</p>
<p>Затем осуществляется распределение регистров для результатов операций:</p>
<p>Корню назначается первый регистр.</p>
<p>Если метка левого потомка меньше метки правого, то левому потомку назначается регистр на единицу больший, чем предку, а правому - с тем же номером (сначала вычисляется правое поддерево и его результат помещается в регистр R).</p>
<p>Если же метка левого потомка больше или равна метке правого потомка, то наоборот, сначала вычисляется левое поддерево и его результат помещается в регистр R. После этого формируется код по следующим правилам.</p>
<p>Правила генерации кода:</p>
<p>если вершина - правый лист с меткой 1, то ей соответствует код “LOAD X,R”, где R - регистр, назначенный этой вершине, а X - адрес переменной, связанной с вершиной.</p>
<p>если вершина внутренняя, и ее левый потомок - лист с меткой 0, то ей соответствует код “Op X,R”, где снова R - регистр, назначенный этой вершине, X - адрес переменной, связанной с вершиной, а Op - операция, примененная в вершине.</p>
<p>если непосредственные потомки вершины не листья и метка правой вершины больше метки левой, то вершине соответствует код “Op R+1,R”, где R – регистр назначенный левой вершине, а R+1 – правой.</p>
<p>Если метка правой вершины меньше или равна метке левой вершины, то вершине соответствует код “Op R,R+1; MOVE R+1,R”, где R – регистр назначенный левой вершине, а R+1 – правой. Последняя команда генерируется для того, чтобы получить результат в нужном регистре (в случае коммутативной операции операнды операции можно поменять местами и избежать дополнительной пересылки).</p>
<p><span>****</span></p>
<p><span><strong>10. Основные принципы объектно-ориентированного программирования. </strong></span> <span><strong>Определение</strong></span>. Объектно-ориентированное программирование - это методология программирования, которая основана на представлении программы в виде совокупности объектов, каждый из которых является реализацией определенного класса, а классы образуют иерархию на принципах наследования.</p>
<p>Ключевыми отличиями ООП от других методологий программирования являются следующие отличия:</p>
<p>ООП использует в качестве элементов конструкции объекты, а не алгоритмы</p>
<p>Каждый объект является реализацией какого-либо определенного типа (класса)</p>
<p>Классы организованы иерархически</p>
<p>При несоблюдении хотя бы одного из указанных требований программа перестает быть ОО. (В частности при нарушении 3 имеем программирование на основе Абстрактных Типов Данных)</p>
<p><span><strong>Определение</strong></span>. Язык программирования называется объектно-ориентированным тогда и только тогда, когда выполнены следующие условия:</p>
<p>Имеется поддержка объектов в виде абстракции данных имеющих интерфейсную часть в виде поименованных операций и защищенную область локальных данных</p>
<p>Объекты относятся к соответствующим типам (классам)</p>
<p>Классы могут наследовать атрибуты и методы от суперклассов (базовых классов)</p>
<p>Имеется поддержка полиморфных функций</p>
<p>Объектно-ориентированный подход основывается на следующих элементах:</p>
<p>Абстрагирование</p>
<p>Инкапсуляция (ограничение доступа)</p>
<p>Иерархия (в частности наследование)</p>
<p>Полиморфизм</p>
<p><span><em>Абстрагирование</em></span> <span><strong>Определение</strong></span>. Абстракция - это такие существенные характеристики некоторого объекта, которые отличают его от всех других видов объектов, и, таким образом четко определяют особенности данного объекта с точки зрения дальнейшего рассмотрения и анализа.</p>
<p>Абстрагирование концентрирует внимание на внешних особенностях объекта и позволяет отделить самые существенные особенности поведения от деталей их осуществления.</p>
<p>ОО стиль программирования связан с воздействием на объекты (например передача ему сообщения). Путем воздействия на объект вызывается определенная реакция этого объекта. Операции, которые можно выполнить по отношению к данному объекту, и реакция объекта на внешние воздействия составляют характер поведения объекта.</p>
<p><span><em>Инкапсуляция (ограничение доступа)</em></span> <span><strong>Определение</strong></span>. Ограничение доступа - это процесс защиты отдельных элементов объекта, не затрагивающий существенных характеристик объекта как целого.</p>
<p>Ограничение доступа позволяет вносить в программу изменения, сохраняя ее надежность и позволяя минимизировать затраты на этот процесс.</p>
<p>Абстрагирование и ограничение доступа дополняют друг друга: абстрагирование фокусирует внимание на внешних особенностях объекта, а ограничение доступа не позволяет объектам-пользователям различать внутреннее устройство объекта.</p>
<p>В описании класса можно выделить две части:</p>
<p>Интерфейс, который отражает внешнее проявление объекта, создавая абстракцию поведения всех объектов данного класса. В интерфейсной части собрано все, что касается взаимодействия данного объекта с любыми другими объектами.</p>
<p>Реализация, которая описывает механизмы достижения желаемого поведения объекта. Реализация скрывает от других объектов все детали, не имеющие отношение к процессу взаимодействия объектов.</p>
<p>Изменение реализации, вообще говоря, не влечет за собой изменение интерфейса.</p>
<p><span><em>Иерархия</em></span> <span><strong>Определение</strong></span>. Иерархия в ОО - это ранжированная или упорядоченная иерархия абстракций.</p>
<p>Основными видами иерархических структур применительно к сложным системам являются структура классов (иерархия по номенклатуре) и структура объектов (иерархия по составу).</p>
<p>Примеры иерархий:</p>
<p>Наследование означает такое соотношение между классами, когда один класс использует структурную или функциональную часть одного или нескольких других классов (соответственно простое или множественное наследование). Иными словами, наследование - такая иерархия абстракций, в которой подклассы наследуют строение от одного или нескольких суперклассов. (Иерархия обобщение - специализация)</p>
<p>Агрегирование (отношение по составу). Объект состоит из подобъектов.</p>
<p>Принципы абстрагирования, ограничения доступа и иерархии конкурируют между собой. Абстрагирование данных состоит в установлении жестких границ, защищающих состояние и функции объекта; принцип наследования требует открыть доступ и к состоянию, и к функциям объекта для производных классов. В связи с этим интерфейсная часть класса может быть разделена на три части:</p>
<p>Обособленную (private) - видимая только для самого класса</p>
<p>Защищенную (protected) - видимую также и для подклассов</p>
<p>Общедоступную (public) - видимую для всех</p>
<p><span><em>Полиморфизм</em></span> <span><strong>Определение</strong></span>. Полиморфизм – это способность операции (функции) с одним и тем же именем выполнять различные действия в зависимости от типа своих операндов. <span>****</span> Полиморфизм может быть статическим и динамическим:</p>
<p>Статический - перекрытие операций (Ада, C++,Object Pascal).</p>
<p>Динамический - механизм виртуальных функций</p>
<p>Виртуальные функции являются примером полиморфных функций. Виртуальная функция может быть переопределена в производном классе, следовательно ее реализация зависит от всей последовательности методических описаний и наследственной иерархии. Какая именно из виртуальных функций будет вызвана - зависит от динамического типа объекта и определяется в момент обращения к виртуальной функции. Для этого используется таблица виртуальных функций, определенная для каждого класса. <span>****</span></p>
<p><span><em>Дополнительные возможности ОО языков:</em></span> Некоторые языки позволяют определять несколько специальных методов класса:</p>
<p>Конструктор - специальная процедура класса для создания и/или инициализации начального состояния объекта. В частности, конструктор может инициализировать таблицу виртуальных функций.</p>
<p>Деструктор - специальная процедура класса, которая делает состояние объекта неопределенным и (или) ликвидирует сам объект.</p>
<p>Некоторые преимущества ОО подхода:</p>
<p>Использование объектного подхода существенно повышает качество разработки в целом и ее фрагментов. ОО Системы часто получаются более компактными чем их не-ОО аналоги</p>
<p>Использование объектного подхода приводит к построению систем на основе стабильных промежуточных описаний, что упрощает процесс внесения изменений. Это дает системе возможность развиваться постепенно и не приводит к ее полной переработке в случае существенных изменений исходных требований</p>
<p>Ориентирован на человеческое восприятие мира</p>
<p><span>****</span></p>
<p><span>****</span></p>
<p><span>****</span></p>
<p><span><strong>11. Основные этапы компиляции (лексический анализ, синтаксический анализ, семантический анализ, генерация кода и т.д.). </strong></span></p>
<p><span><em>Структура компилятора</em></span> Обобщенная структура компилятора и основные фазы компиляции показаны на рис. 1.1.</p>
<p>На фазе лексического анализа входная программа, представляющая собой поток литер, разбивается на лексемы - слова в соответствии с определениями языка. Основными формализмами, лежащим в основе реализации лексических анализаторов, являются конечные автоматы и регулярные выражения. Лексический анализатор может работать в двух основных режимах: либо как подпрограмма, вызываемая синтаксическим анализатором для получения очередной лексемы, либо как полный проход, результатом которого является файл лексем. В процессе выделения лексем лексический анализатор может как самостоятельно строить таблицы объектов (идентификаторов, строк, чисел и т.д.), так и выдавать значения для каждой лексемы при очередном к нему обращении. В этом случае таблицы объектов строятся в последующих фазах (например, в процессе синтаксического анализа). На этапе лексического анализа обнаруживаются некоторые (простейшие) ошибки (недопустимые символы, неправильная запись чисел, идентификаторов и др.). Основная задача синтаксического анализа - разбор структуры программы. Как правило, под структурой понимается дерево, соответствующее разбору в контекстно-свободной грамматике языка. В настоящее время чаще всего используется либо LL(1)-анализ (и его вариант - рекурсивный спуск), либо LR(1)-анализ и его варианты (LR(0), SLR(1), LALR(1) и другие). Рекурсивный спуск чаще используется при ручном программировании синтаксического анализатора, LR(1) - при использовании систем автоматического построения синтаксических анализаторов. Результатом синтаксического анализа является синтаксическое дерево со ссылками на таблицы объектов. В процессе синтаксического анализа также обнаруживаются ошибки, связанные со структурой программы. На этапе контекстного анализа выявляются зависимости между частями программы, которые не могут быть описаны контекстно-свободным синтаксисом. Это в основном связи «описание-использование», в частности, анализ типов объектов, анализ областей видимости, соответствие параметров, метки и другие. В процессе контекстного анализа таблицы объектов пополняются информацией об описаниях (свойствах) объектов. Основным формализмом, использующимся при контекстном анализе, является аппарат атрибутных грамматик. Результатом контекстного анализа является атрибутированное дерево программы. Информация об объектах может быть как рассредоточена в самом дереве, так и сосредоточена в отдельных таблицах объектов. В процессе контекстного анализа также могут быть обнаружены ошибки, связанные с неправильным использованием объектов. Затем программа может быть переведена во внутреннее представление. Это делается для целей оптимизации и/или удобства генерации кода. Еще одной целью преобразования программы во внутреннее представление является желание иметь переносимый компилятор. Тогда только последняя фаза (генерация кода) является машинно-зависимой. В качестве внутреннего представления может использоваться префиксная или постфиксная запись, ориентированный граф, тройки, четверки и другие. Фаз оптимизации может быть несколько. Оптимизации обычно делят на машинно-зависимые и машинно-независимые, локальные и глобальные. <span class="math">\(\times\)</span>асть машинно-зависимой оптимизации выполняется на фазе генерации кода. Глобальная оптимизация пытается принять во внимание структуру всей программы, локальная - только небольших ее фрагментов. Глобальная оптимизация основывается на глобальном потоковом анализе, который выполняется на графе программы и представляет по существу преобразование этого графа. При этом могут учитываться такие свойства программы, как межпроцедурный анализ, межмодульный анализ, анализ областей жизни переменных и т.д. Наконец, генерация кода - последняя фаза трансляции. Результатом ее является либо ассемблерный модуль, либо объектный (или загрузочный) модуль. В процессе генерации кода могут выполняться некоторые локальные оптимизации, такие как распределение регистров, выбор длинных или коротких переходов, учет стоимости команд при выборе конкретной последовательности команд. Для генерации кода разработаны различные методы, такие как таблицы решений, сопоставление образцов, включающее динамическое программирование, различные синтаксические методы. Конечно, те или иные фазы транслятора могут либо отсутствовать совсем, либо объединяться. В простейшем случае однопроходного транслятора нет явной фазы генерации промежуточного представления и оптимизации, остальные фазы объединены в одну, причем нет и явно построенного синтаксического дерева.</p>
<p><span>****</span></p>
<p><span><strong>13. Построение канонического множества LR(1) ситуаций и таблиц действии и переходов для LR(1) грамматик. </strong></span></p>
<p><span><strong>Определение</strong></span>. Пусть G=<span class="math">\(&lt;\)</span>N,T,P,S<span class="math">\(&gt;\)</span> - контекстно-свободная грамматика, где N - множество нетерминальных символов, T - множество терминальных символов, P - множество правил вывода и S - аксиома. Будем говорить, что uxv выводится за один шаг из uAv (и записывать это как uAv<span class="math">\(\Rightarrow \)</span>uxv), если A<span class="math">\(\to \)</span>x - правило вывода и u и v - произвольные строки из (N <span class="math">\(\bigcup \)</span>T)*. Если u<span class="math">\({}_{1}\)</span><span class="math">\(\Rightarrow \)</span>u<span class="math">\({}_{2}\)</span><span class="math">\(\Rightarrow \)</span>...<span class="math">\(\Rightarrow \)</span>u<span class="math">\({}_{n}\)</span>, будем говорить, что из u<span class="math">\({}_{1}\)</span> выводится u<span class="math">\({}_{n}\)</span>, и записывать это как u<span class="math">\({}_{1}\)</span><span class="math">\(\Rightarrow \)</span>*u<span class="math">\({}_{n}\)</span>. Т.е.:</p>
<p>u<span class="math">\(\Rightarrow \)</span>*u для любой строки u,</p>
<p>если u<span class="math">\(\Rightarrow \)</span>*v и v<span class="math">\(\Rightarrow \)</span>*w, то u<span class="math">\(\Rightarrow \)</span>*w. Аналогично, “<span class="math">\(\Rightarrow \)</span><span class="math">\({}^{+}\)</span>” означает “выводится за один или более шагов”.</p>
<p><span><strong>Определение</strong></span>. Языком L(G), порожденным грамматикой G с начальным символом S называется множество L(G) = <span class="math">\(\{\)</span>ww содержит только терминальные символы и S<span class="math">\(\Rightarrow \)</span><span class="math">\({}^{+}\)</span>w<span class="math">\(\}\)</span>. Строка w называется предложением в G. <span><strong>Определение</strong></span>. Если S<span class="math">\(\Rightarrow \)</span>*u, где u может содержать нетерминалы, то u называется сентенциальной формой в G. Предложение - это сентенциальная форма, не содержащая нетерминалов. <span><strong>Определение</strong></span>. Рассмотрим выводы, в которых в любой сентенциальной форме на каждом шаге делается подстановка самого левого нетерминала. Такой вывод называется левосторонним. Если S<span class="math">\(\Rightarrow \)</span>*u в процессе левостороннего вывода, то u - левая сентенциальная форма. Аналогично определяется правосторонний вывод. <span><strong>Определение</strong></span>. Упорядоченным графом называется пара (V,E), где V обозначает множество вершин, а E - множество линейно упорядоченных списков дуг, каждый элемент которого имеет вид ((v,e<span class="math">\({}_{1}\)</span>),(v,e<span class="math">\({}_{2}\)</span>),...,(v,e<span class="math">\({}_{n}\)</span>)). Этот элемент указывает, что из вершины a выходят n дуг, причем первой из них считается дуга, входящая в вершину e<span class="math">\({}_{1}\)</span>, второй - дуга, входящая в вершину e<span class="math">\({}_{2}\)</span>, и т.д. <span><strong>Определение</strong></span>. Упорядоченное помеченное дерево D называется деревом вывода (или деревом разбора) в КС-грамматике G(S)=(N,T,P,S), если выполнены следующие условия:</p>
<p>корень дерева D помечен S;</p>
<p>каждый лист помечен либо a<span class="math">\(\in \)</span>T, либо e;</p>
<p>каждая внутренняя вершина помечена нетерминалом;</p>
<p>если N - нетерминал, которым помечена внутренняя вершина и X<span class="math">\({}_{1}\)</span>,...,X<span class="math">\({}_{n}\)</span> - метки ее прямых потомков в указанном порядке, то N<span class="math">\(\to \)</span>X<span class="math">\({}_{1}\)</span>...X<span class="math">\({}_{k}\)</span> - правило из множества P. <span><strong>Определение</strong></span>. Автомат с магазинной памятью (сокращенно МП-автомат) - это семерка P=(Q,T,Г,D,q<span class="math">\({}_{0}\)</span>,Z<span class="math">\({}_{0}\)</span>,F), где</p>
<p>Q - конечное множество символов состояний, представляющих всевозможные состояния управляющего устройства;</p>
<p>T - конечный входной алфавит.</p>
<p>Г - конечный алфавит магазинных символов.</p>
<p>D - функция переходов - отображение множества Qx(T <span class="math">\(\bigcup \)</span><span class="math">\(\{\)</span>e<span class="math">\(\}\)</span>)xГ в множество конечных подмножеств QxГ*.</p>
<p>q<span class="math">\({}_{0}\)</span><span class="math">\(\in \)</span>Q - начальное состояние управляющего устройства.</p>
<p>Z<span class="math">\({}_{0}\)</span><span class="math">\(\in \)</span>Г - символ, находящийся в магазине в начальный момент (начальный символ).</p>
<p>F<span class="math">\(\subseteq \)</span>Q - множество заключительных состояний. <span><strong>Определение</strong></span>. Конфигурацией МП-автомата называется тройка (q,w,u)<span class="math">\(\in \)</span> QxT*xГ*, где</p>
<p>q - текущее состояние управляющего устройства;</p>
<p>w - неиспользованная часть входной цепочки; первый символ цепочки w находится под входной головкой; если w = e, то считается, что вся входная лента прочитана;</p>
<p>u - содержимое магазина; самый левый символ цепочки u считается верхним символом магазина; если u = e, то магазин считается пустым. <span><strong>Определение</strong></span>. Такт работы МП-автомата P будем представлять в виде бинарного отношения <span class="math">\(\succ \)</span>, определенного на конфигурациях. Будем писать (q,aw,Zu) <span class="math">\(\succ \)</span> (q’,w,vu) если множество D(q,a,Z) содержит (q’,v), где q, q’<span class="math">\(\in \)</span>Q, a<span class="math">\(\in \)</span>T <span class="math">\(\bigcup \)</span><span class="math">\(\{\)</span>e<span class="math">\(\}\)</span>, w<span class="math">\(\in \)</span>T*, Z<span class="math">\(\in \)</span>Г, u,v<span class="math">\(\in \)</span>Г*. <span><strong>Определение</strong></span>. Начальной конфигурацией МП-автомата P называется конфигурация вида (q<span class="math">\({}_{0}\)</span>,w,Z<span class="math">\({}_{0}\)</span>), где w<span class="math">\(\in \)</span>T*, т.е. управляющее устройство находится в начальном состоянии, входная лента содержит цепочку, которую нужно распознать, а в магазине есть только начальный символ Z<span class="math">\({}_{0}\)</span>. Заключительная конфигурация - это конфигурация вида (q,e,u), где q<span class="math">\(\in \)</span>F, u<span class="math">\(\in \)</span>Г*. <span><strong>Определение</strong></span>. Говорят, что цепочка w допускается МП-автоматом P, если (q<span class="math">\({}_{0}\)</span>,w,Z<span class="math">\({}_{0}\)</span>) <span class="math">\(\succ \)</span>*(q,e,u) для некоторых q<span class="math">\(\in \)</span>F и u<span class="math">\(\in \)</span>Г*. Языком, определяемым (или допускаемым) автоматом P (обозначается L(P)), называют множество цепочек, допускаемых автоматом P.</p>
<p><span><em>Разбор снизу-вверх типа сдвиг-свертка</em></span> В процессе разбора снизу-вверх типа сдвиг-свертка строится дерево разбора входной строки, начиная с листьев (снизу) к корню (вверх). Этот процесс можно рассматривать как “свертку” строки w к начальному символу грамматики. На каждом шаге свертки подстрока, которую можно сопоставить правой части некоторого правила вывода, заменяется символом левой части этого правила вывода, и если на каждом шаге выбирается правильная подстрока, то в обратном порядке прослеживается правосторонний вывод. <span><strong>Определение</strong></span>. Подстрока сентенциальной формы, которая может быть сопоставлена правой части некоторого правила вывода, свертка по которому к левой части правила соответствует одному шагу в обращении правостороннего вывода, называется <span><em>основой</em></span> строки. Самая левая подстрока, которая сопоставляется правой части некоторого правила вывода A<span class="math">\(\to \)</span>v, не обязательно является основой, поскольку свертка по правилу A<span class="math">\(\to \)</span>v может дать строку, которая не может быть сведена к аксиоме. <span><strong>Определение</strong></span>. Замена основы в сентенциальной форме на нетерминал левой части называется отсечением основы. Таким образом, главная задача анализатора типа сдвиг-свертка - это выделение и отсечение основы.</p>
<p><span><em>LR(k)-анализаторы</em></span> LR-анализатор состоит из входа, выхода, магазина, управляющей программы и таблицы анализа, которая имеет две части - действий и переходов. Управляющая программа одна и та же для всех анализаторов, разные анализаторы различаются таблицами анализа. Программа анализатора читает символы из входного буфера по одному за шаг. В процессе анализа используется магазин, в котором хранятся строки вида S<span class="math">\({}_{0}\)</span>X<span class="math">\({}_{1}\)</span>S<span class="math">\({}_{1}\)</span>X<span class="math">\({}_{2}\)</span>S<span class="math">\({}_{2}\)</span>...X<span class="math">\({}_{m}\)</span>S<span class="math">\({}_{m}\)</span> (S<span class="math">\({}_{m}\)</span> - верхушка магазина). Каждый X<span class="math">\({}_{i}\)</span> - символ грамматики (терминальный или нетерминальный), а S<span class="math">\({}_{i}\)</span> - символ, называемый состоянием. Таблица анализа состоит из двух частей: действия (action) и переходов (goto). Определение. Конфигурацией LR анализатора называется пара, первая компонента которой - содержимое магазина, а вторая - непросмотренный вход: (S<span class="math">\({}_{0}\)</span>X<span class="math">\({}_{1}\)</span>S<span class="math">\({}_{1}\)</span>X<span class="math">\({}_{2}\)</span>S<span class="math">\({}_{2}\)</span> ... X<span class="math">\({}_{m}\)</span>S<span class="math">\({}_{m}\)</span>, a<span class="math">\({}_{i}\)</span> a<span class="math">\({}_{i+1}\)</span> ... a<span class="math">\({}_{n}\)</span> $) Эта конфигурация соответствует правой сентенциальной форме X<span class="math">\({}_{1}\)</span>X<span class="math">\({}_{2}\)</span> ... X<span class="math">\({}_{m}\)</span>a<span class="math">\({}_{i}\)</span>a<span class="math">\({}_{i+1}\)</span>...a<span class="math">\({}_{n}\)</span> Префиксы правых сентенциальных форм, которые могут появиться в магазине анализатора, называются активными префиксами. Основа сентенциальной формы всегда располагается на верхушке магазина. Таким образом, активный префикс - это такой префикс правой сентенциальной формы, который не переходит правую границу основы этой формы. Очередной шаг анализатора определяется текущим входным символом a<span class="math">\({}_{i}\)</span> и символом состояния на верхушке магазина S<span class="math">\({}_{m}\)</span>. Элемент таблицы действий action[S<span class="math">\({}_{m}\)</span>,a<span class="math">\({}_{i}\)</span>] для состояния S<span class="math">\({}_{m}\)</span> и входа a<span class="math">\({}_{i}\)</span>, может иметь одно их четырех значений:</p>
<p>shift S, сдвиг, где S - состояние,</p>
<p>reduce A<span class="math">\(\to \)</span>w, свертка по правилу грамматики A<span class="math">\(\to \)</span>w,</p>
<p>accept, допуск,</p>
<p>error, ошибка. Схема работы автомата на каждом шаге следующая:</p>
<p>Если action[S<span class="math">\({}_{m}\)</span>,a<span class="math">\({}_{i}\)</span>]=shift S, то анализатор выполняет шаг сдвига, переходя в конфигурацию (S<span class="math">\({}_{0}\)</span>X<span class="math">\({}_{1}\)</span>S<span class="math">\({}_{1}\)</span> ... X<span class="math">\({}_{m}\)</span>S<span class="math">\({}_{m}\)</span>a<span class="math">\({}_{i}\)</span>S, a<span class="math">\({}_{i+1}\)</span> ... a<span class="math">\({}_{n}\)</span>$)</p>
<p>Если action[S<span class="math">\({}_{m}\)</span>,a<span class="math">\({}_{i}\)</span>]=reduce A<span class="math">\(\to \)</span>w, то анализатор выполняет свертку, переходя в конфигурацию (S<span class="math">\({}_{0}\)</span>X<span class="math">\({}_{1}\)</span>S<span class="math">\({}_{1}\)</span> ... X<span class="math">\({}_{m}\)</span><span class="math">\({}_{-}\)</span><span class="math">\({}_{r}\)</span>S<span class="math">\({}_{m}\)</span><span class="math">\({}_{-}\)</span><span class="math">\({}_{r}\)</span>AS, a<span class="math">\({}_{i}\)</span>a<span class="math">\({}_{i}\)</span><span class="math">\({}_{+1}\)</span>...a<span class="math">\({}_{n}\)</span>$), где S=goto[S<span class="math">\({}_{m-r}\)</span>,A] и r - длина w, правой части правила вывода.</p>
<p>Если action[S<span class="math">\({}_{m}\)</span>,a<span class="math">\({}_{i}\)</span>]=accept, то автомат останавливается с успешным результатом</p>
<p>Если action[S<span class="math">\({}_{m}\)</span>,a<span class="math">\({}_{i}\)</span>]=error, то автомат останавливается с ошибкой.</p>
<p><span><strong>14. Архитектура параллельных вычислительных систем. </strong></span> Параллельная обработка данных, воплощая идею одновременного выполнения нескольких действий, имеет две разновидности: конвейерность и собственно параллельность. Оба вида параллельной обработки интуитивно понятны, поэтому сделаем лишь небольшие пояснения.</p>
<p>Параллельная обработка. Если некое устройство выполняет одну операцию за единицу времени, то тысячу операций оно выполнит за тысячу единиц. Если предположить, что есть пять таких же независимых устройств, способных работать одновременно, то ту же тысячу операций система из пяти устройств может выполнить уже не за тысячу, а за двести единиц времени. Аналогично система из N устройств ту же работу выполнит за 1000/N единиц времени.</p>
<p>Идея конвейерной обработки заключается в выделении отдельных этапов выполнения общей операции, причем каждый этап, выполнив свою работу, передавал бы результат следующему, одновременно принимая новую порцию входных данных. Получаем очевидный выигрыш в скорости обработки за счет совмещения прежде разнесенных во времени операций. Предположим, что в операции можно выделить пять микроопераций, каждая из которых выполняется за одну единицу времени. Если есть одно неделимое последовательное устройство, то 100 пар аргументов оно обработает за 500 единиц. Если каждую микрооперацию выделить в отдельный этап (или иначе говорят - ступень) конвейерного устройства, то на пятой единице времени на разной стадии обработки такого устройства будут находится первые пять пар аргументов, а весь набор из ста пар будет обработан за 5+99=104 единицы времени - ускорение по сравнению с последовательным устройством почти в пять раз (по числу ступеней конвейера).</p>
<p>Казалось бы, конвейерную обработку можно с успехом заменить обычным параллелизмом, для чего продублировать основное устройство столько раз, сколько ступеней конвейера предполагается выделить. В самом деле, пять устройств предыдущего примера обработают 100 пар аргументов за 100 единиц времени, что быстрее времени работы конвейерного устройства! В чем же дело? Ответ прост, увеличив в пять раз число устройств, мы значительно увеличиваем как объем аппаратуры, так и ее стоимость.</p>
<p><span><em>Классификация Флинна</em></span> Cамой ранней и наиболее известной является классификация архитектур вычислительных систем, предложенная в 1966 году М.Флинном. Классификация базируется на понятии потока, под которым понимается последовательность элементов, команд или данных, обрабатываемая процессором. На основе числа потоков команд и потоков данных Флинн выделяет четыре класса архитектур: SISD, MISD, SIMD, MIMD.</p>
<p>SISD (single instruction stream / single data stream) - одиночный поток команд и одиночный поток данных. К этому классу относятся, прежде всего, классические последовательные машины, или иначе, машины фон-неймановского типа, например, PDP-11 или VAX 11/780. В таких машинах есть только один поток команд, все команды обрабатываются последовательно друг за другом и каждая команда инициирует одну операцию с одним потоком данных. Не имеет значения тот факт, что для увеличения скорости обработки команд и скорости выполнения арифметических операций может применяться конвейерная обработка - как машина CDC 6600 со скалярными функциональными устройствами, так и CDC 7600 с конвейерными попадают в этот класс.</p>
<p>SIMD (single instruction stream / multiple data stream) - одиночный поток команд и множественный поток данных. В архитектурах подобного рода сохраняется один поток команд, включающий, в отличие от предыдущего класса, векторные команды. Это позволяет выполнять одну арифметическую операцию сразу над многими данными - элементами вектора. Способ выполнения векторных операций не оговаривается, поэтому обработка элементов вектора может производиться либо процессорной матрицей, как в ILLIAC IV, либо с помощью конвейера, как, например, в машине CRAY-1.</p>
<p>MISD (multiple instruction stream / single data stream) - множественный поток команд и одиночный поток данных. Определение подразумевает наличие в архитектуре многих процессоров, обрабатывающих один и тот же поток данных. Однако ни Флинн, ни другие специалисты в области архитектуры компьютеров до сих пор не смогли представить убедительный пример реально существующей вычислительной системы, построенной на данном принципе.</p>
<p>MIMD (multiple instruction stream / multiple data stream) - множественный поток команд и множественный поток данных. Этот класс предполагает, что в вычислительной системе есть несколько устройств обработки команд, объединенных в единый комплекс и работающих каждое со своим потоком команд и данных. Предложенная схема классификации вплоть до настоящего времени является самой применяемой при начальной характеристике того или иного компьютера. Если говорится, что компьютер принадлежит классу SIMD или MIMD, то сразу становится понятным базовый принцип его работы, и в некоторых случаях этого бывает достаточно. Однако видны и явные недостатки. В частности, некоторые заслуживающие внимания архитектуры, например dataflow и векторно-конвейерные машины, четко не вписываются в данную классификацию. Другой недостаток - это чрезмерная заполненность класса MIMD. Необходимо средство, более избирательно систематизирующее архитектуры, которые по Флинну попадают в один класс, но совершенно различны по числу процессоров, природе и топологии связи между ними, по способу организации памяти и, конечно же, по технологии программирования.</p>
<p><span><em>Массивно-параллельные системы (MPP)</em></span> Система состоит из однородных вычислительных узлов, включающих:</p>
<p>один или несколько центральных процессоров (обычно RISC),</p>
<p>локальную память (прямой доступ к памяти других узлов невозможен),</p>
<p>коммуникационный процессор или сетевой адаптер</p>
<p>иногда - жесткие диски (как в SP) и/или другие устройства В/В К системе могут быть добавлены специальные узлы ввода-вывода и управляющие узлы. Узлы связаны через некоторую коммуникационную среду (высокоскоростная сеть, коммутатор и т.п.) Общее число процессоров в реальных системах достигает нескольких тысяч (ASCI Red, Blue Mountain). Существуют два основных варианта ОС для управления такими компьютерами:</p>
<p>Полноценная ОС работает только на управляющей машине (front-end), на каждом узле работает сильно урезанный вариант ОС, обеспечивающие только работу расположенной в нем ветви параллельного приложения. Пример: Cray T3E.</p>
<p>На каждом узле работает полноценная UNIX-подобная ОС (вариант, близкий к кластерному подходу). Пример: IBM RS/6000 SP + ОС AIX, устанавливаемая отдельно на каждом узле. Программирование в рамках модели передачи сообщений ( MPI, PVM, BSPlib)</p>
<p>Примеры: IBM RS/6000 SP2, Intel PARAGON/ASCI Red, SGI/CRAY T3E, Hitachi SR8000, транспьютерные системы Parsytec.</p>
<p><span><em>Симметричные мультипроцессорные системы (SMP)</em></span> Система состоит из нескольких однородных процессоров и массива общей памяти (обычно из нескольких независимых блоков). Все процессоры имеют доступ к любой точке памяти с одинаковой скоростью. Процессоры подключены к памяти либо с помощью общей шины (базовые 2-4 процессорные SMP-сервера), либо с помощью crossbar-коммутатора (HP 9000). Аппаратно поддерживается когерентность кэшей. Наличие общей памяти сильно упрощает взаимодействие процессоров между собой, однако накладывает сильные ограничения на их число - не более 32 в реальных системах. Для построения масштабируемых систем на базе SMP используются кластерные или NUMA-архитектуры. Вся система работает под управлением единой ОС (обычно UNIX-подобной, но для Intel-платформ поддерживается Windows NT). ОС автоматически (в процессе работы) распределяет процессы/нити по процессорам (scheduling), но иногда возможна и явная привязка. Программирование в модели общей памяти. (POSIX threads, OpenMP). Для SMP-систем существуют сравнительно эффективные средства автоматического распараллеливания.</p>
<p>Примеры: HP 9000 V-class, N-class; SMP-cервера и рабочие станции на базе процессоров Intel (IBM, HP, Compaq, Dell, ALR, Unisys, DG, Fujitsu и др.).</p>
<p><span><em>Системы с неоднородным доступом к памяти (NUMA)</em></span> Система состоит из однородных базовых модулей (плат), состоящих из небольшого числа процессоров и блока памяти. Модули объединены с помощью высокоскоростного коммутатора. Поддерживается единое адресное пространство, аппаратно поддерживается доступ к удаленной памяти, т.е. к памяти других модулей. При этом доступ к локальной памяти в несколько раз быстрее, чем к удаленной. В случае, если аппаратно поддерживается когерентность кэшей во всей системе (обычно это так), говорят об архитектуре cc-NUMA (cache-coherent NUMA) Масштабируемость NUMA-систем ограничивается объемом адресного пространства, возможностями аппаратуры поддежки когерентности кэшей и возможностями операционной системы по управлению большим числом процессоров. На настоящий момент, максимальное число процессоров в NUMA-системах составляет 256 (Origin2000). Обычно вся система работает под управлением единой ОС, как в SMP. Но возможны также варианты динамического “подразделения” системы, когда отдельные “разделы” системы работают под управлением разных ОС (например, Windows NT и UNIX в NUMA-Q 2000). Программирование аналогично SMP.</p>
<p>Примеры: HP HP 9000 V-class в SCA-конфигурациях, SGI Origin2000, Sun HPC 10000, IBM/Sequent NUMA-Q 2000, SNI RM600.</p>
<p><span><em>Параллельные векторные системы (PVP)</em></span> Основным признаком PVP-систем является наличие специальных векторно-конвейерных процессоров, в которых предусмотрены команды однотипной обработки векторов независимых данных, эффективно выполняющиеся на конвейерных функциональных устройствах. Как правило, несколько таких процессоров (1-16) работают одновременно над общей памятью (аналогично SMP) в рамках многопроцессорных конфигураций. Несколько таких узлов могут быть объединены с помощью коммутатора (аналогично MPP). Эффективное программирование подразумевает векторизацию циклов (для достижения разумной производительности одного процессора) и их распараллеливание (для одновременной загрузки нескольких процессоров одним приложением).</p>
<p>Примеры: NEC SX-4/SX-5, линия векторно-конвейерных компьютеров CRAY: от CRAY-1, CRAY J90/T90, CRAY SV1, серия Fujitsu VPP.</p>
<p><span><em>Кластерные системы</em></span> Набор рабочих станций (или даже ПК) общего назначения, используется в качестве дешевого варианта массивно-параллельного компьютера. Для связи узлов используется одна из стандартных сетевых технологий (Fast/Gigabit Ethernet, Myrinet) на базе шинной архитектуры или коммутатора. При объединении в кластер компьютеров разной мощности или разной архитектуры, говорят о гетерогенных (неоднородных) кластерах. Узлы кластера могут одновременно использоваться в качестве пользовательских рабочих станций. В случае, когда это не нужно, узлы могут быть существенно облегчены и/или установлены в стойку. Используются стандартные для рабочих станций ОС, чаще всего, свободно распространяемые - Linux/FreeBSD, вместе со специальными средствами поддержки параллельного программирования и распределения нагрузки. Программирование, как правило, в рамках модели передачи сообщений (чаще всего - MPI). Дешевизна подобных систем оборачивается большими накладными расходами на взаимодействие параллельных процессов между собой, что сильно сужает потенциальный класс решаемых задач.</p>
<p>Примеры: NT-кластер в NCSA, Beowulf-кластеры.</p>
<p><span><em>Историческая справка</em></span> IBM 701 (1953), IBM 704 (1955): разрядно-параллельная память, разрядно-параллельная арифметика. Все самые первые компьютеры (EDSAC, EDVAC, UNIVAC) имели разрядно-последовательную память, из которой слова считывались последовательно бит за битом. Первым коммерчески доступным компьютером, использующим разрядно-параллельную память (на CRT) и разрядно-параллельную арифметику, стал IBM 701, а наибольшую популярность получила модель IBM 704 (продано 150 экз.), в которой, помимо сказанного, была впервые применена память на ферритовых сердечниках и аппаратное АУ с плавающей точкой.</p>
<p>IBM 709 (1958): независимые процессоры ввода/вывода. Процессоры первых компьютеров сами управляли вводом/выводом. Однако скорость работы самого быстрого внешнего устройства, а по тем временам это магнитная лента, была в 1000 раз меньше скорости процессора, поэтому во время операций ввода/вывода процессор фактически простаивал. В 1958г. к компьютеру IBM 704 присоединили 6 независимых процессоров ввода/вывода, которые после получения команд могли работать параллельно с основным процессором, а сам компьютер переименовали в IBM 709. Данная модель получилась удивительно удачной, так как вместе с модификациями было продано около 400 экземпляров, причем последний был выключен в 1975 году - 20 лет существования!</p>
<p>IBM STRETCH (1961): опережающий просмотр вперед, расслоение памяти. В 1956 году IBM подписывает контракт с Лос-Аламосской научной лабораторией на разработку компьютера STRETCH, имеющего две принципиально важные особенности: опережающий просмотр вперед для выборки команд и расслоение памяти на два банка для согласования низкой скорости выборки из памяти и скорости выполнения операций.</p>
<p>ATLAS (1963): конвейер команд. Впервые конвейерный принцип выполнения команд был использован в машине ATLAS, разработанной в Манчестерском университете. Выполнение команд разбито на 4 стадии: выборка команды, вычисление адреса операнда, выборка операнда и выполнение операции. Конвейеризация позволила уменьшить время выполнения команд с 6 мкс до 1,6 мкс. Данный компьютер оказал огромное влияние, как на архитектуру ЭВМ, так и на программное обеспечение: в нем впервые использована мультипрограммная ОС, основанная на использовании виртуальной памяти и системы прерываний.</p>
<p>CDC 6600 (1964): независимые функциональные устройства. Фирма Control Data Corporation (CDC) при непосредственном участии одного из ее основателей, Сеймура Р.Крэя (Seymour R.Cray) выпускает компьютер CDC-6600 - первый компьютер, в котором использовалось несколько независимых функциональных устройств.</p>
<p>CDC 7600 (1969): конвейерные независимые функциональные устройства. CDC выпускает компьютер CDC-7600 с восемью независимыми конвейерными функциональными устройствами - сочетание параллельной и конвейерной обработки.</p>
<p>ILLIAC IV (1974): матричные процессоры. Проект: 256 процессорных элементов (ПЭ) = 4 квадранта по 64ПЭ, возможность реконфигурации: 2 квадранта по 128ПЭ или 1 квадрант из 256ПЭ, такт 40нс, производительность 1Гфлоп;</p>
<p>CRAY 1 (1976): векторно-конвейерные процессоры В 1972 году С.Крэй покидает CDC и основывает свою компанию Cray Research, которая в 1976г. выпускает первый векторно-конвейерный компьютер CRAY-1: время такта 12.5нс, 12 конвейерных функциональных устройств, пиковая производительность 160 миллионов операций в секунду, оперативная память до 1Мслова (слово - 64 разряда), цикл памяти 50нс. Главным новшеством является введение векторных команд, работающих с целыми массивами независимых данных и позволяющих эффективно использовать конвейерные функциональные устройства.</p>
<p><span><em>Конвейерность и параллелизм</em></span> При параллелизме совмещение операций достигается путем воспроизведения в нескольких копиях аппаратной структуры. Высокая производительность достигается за счет одновременной работы всех элементов структур, осуществляющих решение различных частей задачи.</p>
<p>Конвейеризация (или конвейерная обработка) в общем случае основана на разделении подлежащей исполнению функции на более мелкие части, называемые ступенями, и выделении для каждой из них отдельного блока аппаратуры. Выполнение типичной команды можно разделить на следующие этапы:</p>
<p>выборка команды - IF (по адресу, заданному счетчиком команд, из памяти</p>
<p>извлекается команда);</p>
<p>декодирование команды / выборка операндов из регистров - ID;</p>
<p>выполнение операции / вычисление эффективного адреса памяти - EX;</p>
<p>обращение к памяти - MEM;</p>
<p>запоминание результата - WB. <span class="math">\(\times\)</span>тобы конвейеризовать эту схему, мы можем просто разбить выполнение команд на указанные выше этапы, отведя для выполнения каждого этапа один такт синхронизации, и начинать в каждом такте выполнение новой команды.</p>
<p>При реализации конвейерной обработки возникают ситуации, которые препятствуют выполнению очередной команды из потока команд в предназначенном для нее такте. Такие ситуации называются конфликтами. Конфликты снижают реальную производительность конвейера, которая могла бы быть достигнута в идеальном случае.</p>
<p>Существуют три класса конфликтов:</p>
<p>Структурные конфликты, которые возникают из-за конфликтов по ресурсам, когда аппаратные средства не могут поддерживать все возможные комбинации команд в режиме одновременного выполнения с совмещением.</p>
<p>Конфликты по данным, возникающие в случае, когда выполнение одной команды зависит от результата выполнения предыдущей команды.</p>
<p>Конфликты по управлению, которые возникают при конвейеризации команд переходов и других команд, которые изменяют значение счетчика команд.</p>
<p><span><strong>15. Технологии параллельного программирования. </strong></span></p>
<p><span><strong>Крaткая характеристика MPI.</strong></span></p>
<p>MPI представляет собой программный инструмент, предназначенных для поддержки работы параллельных процессов в терминах передачи сообщений для обеспечения связи между ветвями параллельного приложения. MPI предоставляет программисту единый механизм взаимодействия ветвей внутри параллельного приложения независимо от машинной архитектуры (однопроцессорные / многопроцессорные с общей/раздельной памятью), взаимного расположения ветвей (на одном процессоре / на разных) и API операционной системы. Параллельное приложение состоит из нескольких ветвей, или процессов, или задач, выполняющихся одновременно. Разные процессы могут выполняться как на разных процессорах, так и на одном и том же - для программы это роли не играет, поскольку в обоих случаях механизм обмена данными одинаков. При программировании на MPI программа должна содержать код всех ветвей сразу. MPI-загрузчиком запускается указываемое количество экземпляров программы. Каждый экземпляр определяет свой порядковый номер в запущенном коллективе, и в зависимости от этого номера и размера коллектива выполняет ту или иную ветку алгоритма. Такая модель параллелизма называется <span><em>Single program/Multiple data</em></span> ( SPMD ), и является частным случаем модели <span><em>Multiple instruction/Multiple data</em></span> ( MIMD ). Каждая ветвь имеет пространство данных, полностью изолированное от других ветвей. Процессы обмениваются друг с другом данными в виде сообщений. Сообщения проходят под  идентификаторами, которые позволяют программе и библиотеке связи отличать их друг от друга. Для совместного проведения тех или иных расчетов процессы внутри приложения объединяются в группы. Каждый процесс может узнать у библиотеки связи свой номер внутри группы, и, в зависимости от номера приступает к выполнению соответствующей части расчетов. Количество ветвей фиксировано - в ходе работы порождение новых ветвей невозможно. Если MPI-приложение запускается в сети, запускаемый файл приложения должен быть построен на каждой машине. В состав MPI входят, как правило, два обязательных компонента: библиотека программирования для языков Си, Си++ и Фортран, загрузчик исполняемых файлов. Кроме того, может присутствовать справочная система, командные файлы для облегчения компиляции/компоновки программ и др. в зависимости от версии.</p>
<p><span><strong>Коммуникаторы, группы и области связи.</strong></span></p>
<ul>
<li>это некое множество ветвей. Одна ветвь может быть членом нескольких групп. В распоряжение программиста предоставлен тип <span><strong>MPI_Group</strong></span> и набор функций, работающих с переменными и константами этого типа. Констант, собственно, две: MPI_GROUP_EMPTY может быть возвращена, если группа с запрашиваемыми характеристиками в принципе может быть создана, но пока не содержит ни одной ветви; MPI_GROUP_NULL возвращается, когда запрашиваемые характеристики противоречивы. Согласно концепции MPI, после создания группу нельзя дополнить или усечь - можно создать только новую группу под требуемый набор ветвей на базе существующей.</li>
</ul>
<p>(“communication domain”) - это нечто абстрактное: в распоряжении программиста нет типа данных, описывающего непосредственно области связи, как нет и функций по управлению ими. Области связи автоматически создаются и уничтожаются вместе с коммуникаторами. Абонентами одной области связи являются ВСЕ задачи либо одной, либо двух групп.</p>
<p>, или описатель области связи - это верхушка трехслойного пирога (группы, области связи, описатели областей связи), в который “запечены” задачи: именно с коммуникаторами программист имеет дело, вызывая функции пересылки данных, а также подавляющую часть вспомогательных функций. Одной области связи могут соответствовать несколько коммуникаторов. Коммуникаторы являются “несообщающимися сосудами”: если данные отправлены через один коммуникатор, ветвь-получатель сможет принять их только через этот же самый коммуникатор, но ни через какой-либо другой.</p>
<p>Зачем вообще нужны разные группы, разные области связи и разные их описатели? По существу, они служат той же цели, что и идентификаторы сообщений - помогают ветви-приемнику и ветви-получателю надежнее определять друг друга, а также содержимое сообщения. Ветви внутри параллельного приложения могут объединяться в подколлективы для решения промежуточных задач - посредством создания групп, и областей связи над группами. Пользуясь описателем этой области связи, ветви гарантированно ничего не примут извне подколлектива, и ничего не отправят наружу. Параллельно при этом они могут продолжать пользоваться любым другим имеющимся в их распоряжении коммуникатором для пересылок вне подколлектива, например, MPI_COMM_WORLD для обмена данными внутри всего приложения. Коллективные функции создают дубликат от полученного аргументом коммуникатора, и передают данные через дубликат, не опасаясь, что их сообщения будут случайно перепутаны с сообщениями функций “точка-точка”, распространямыми через оригинальный коммуникатор. Программист с этой же целью в разных кусках кода может передавать данные между ветвями через разные коммуникаторы, один из которых создан копированием другого. Коммуникаторы распределяются автоматически (функциями семейства “Создать новый комуникатор”), и для них не существует джокеров (“принимай через какой угодно коммуникатор”) - вот еще два их существенных достоинства перед идентификаторами сообщений. Идентификаторы (целые числа) распределяются пользователем вручную, и это служит источником двух частых ошибок вследствие путаницы на приемной стороне:</p>
<p>сообщениям, имеющим разный смысл, вручную по ошибке назначается один и тот же идентификатор;</p>
<p>функция приема с джокером сгребает все подряд, в том числе и те сообщения, которые должны быть приняты и обработаны в другом месте ветви.</p>
<p><span><strong>Обрамляющие функции. Начало и завершение.</strong></span></p>
<p>Существует несколько функций, которые используются в любом, даже самом коротком приложении MPI. Занимаются они не столько собственно передачей данных, сколько ее обеспечением:</p>
<p>Инициализация библиотеки. Одна из первых инструкций в функции main (главной функции приложения): MPI_Init( &amp;argc, &amp;argv ); Она получает адреса аргументов, стандартно получаемых самой main от операционной системы и хранящих параметры командной строки. В конец командной строки программы MPI-загрузчик <span><strong>mpirun</strong></span> добавляет ряд информационных параметров, которые требуются MPI_Init. (Пример №1).</p>
<p>Аварийное закрытие библиотеки. Вызывается, если пользовательская программа завершается по причине ошибок времени выполнения, связанных с MPI: MPI_Abort( описатель области связи<span><strong>,</strong></span> код ошибки MPI ); Вызов MPI_Abort из любой задачи принудительно завершает работу ВСЕХ задач, подсоединенных к заданной области связи. Если указан описатель MPI_COMM_WORLD, будет завершено все приложение (все его задачи) целиком, что, по-видимому, и является наиболее правильным решением. Используйте код ошибки MPI_ERR_OTHER, если не знаете, как охарактеризовать ошибку в классификации MPI.</p>
<p>Нормальное закрытие библиотеки: MPI_Finalize(); Рекомендуется не забывать вписывать эту инструкцию перед возвращением из программы, то есть:</p>
<p>перед вызовом стандартной функции Си <span><strong>exit</strong></span> ;</p>
<p>перед каждым после MPI_Init оператором <span><strong>return</strong></span> в функции main ;</p>
<p>если функции main назначен тип void, и она не заканчивается оператором return, то MPI_Finalize() следует поставить в конец main.</p>
<p>Две информационных функции: сообщают размер группы (то есть общее количество задач, подсоединенных к ее области связи) и порядковый номер вызывающей задачи:</p>
<p>int size, rank; MPI_Comm_size( MPI_COMM_WORLD, &amp;size ); MPI_Comm_rank( MPI_COMM_WORLD, &amp;rank ); Использование MPI_Init, MPI_Finalize, MPI_Comm_size и MPI_Comm_rank. – пример: /* * Начало и завершение: * MPI_Init, MPI_Finalize * Определение количества задач в приложениии и своего порядкового номера: * MPI_Comm_size, MPI_Comm_rank */ #include <span class="math">\(&lt;\)</span>mpi.h<span class="math">\(&gt;\)</span> #include <span class="math">\(&lt;\)</span>stdio.h<span class="math">\(&gt;\)</span></p>
<p>int main( int argc, char **argv ) <span class="math">\(\{\)</span> int size, rank, i;</p>
<p>/* Инициализируем библиотеку */ MPI_Init( &amp;argc, &amp;argv );</p>
<p>/* Узнаем количество задач в запущенном приложении */ MPI_Comm_size( MPI_COMM_WORLD, &amp;size );</p>
<p>/* ... и свой собственный номер: от 0 до (size-1) */ MPI_Comm_rank( MPI_COMM_WORLD, &amp;rank );</p>
<p>/* задача с номером 0 сообщает пользователю размер группы, * к которой прикреплена область связи, * к которой прикреплен описатель (коммуникатор) MPI_COMM_WORLD, * т.е. число процессов в приложении!! */ if( rank==0 ) printf(“Total processes count = %d\n”, size );</p>
<p>/* Каждая задача выводит пользователю свой номер */ printf(“Hello! My rank in MPI_COMM_WORLD = %d\n”, rank );</p>
<p>/* Точка синхронизации, затем задача 0 печатает * аргументы командной строки. В командной строке * могут быть параметры, добавляемые загрузчиком MPIRUN. */ MPI_Barrier( MPI_COMM_WORLD ); if( rank == 0 ) for( puts (“Command line of process 0:”), i=0; i<span class="math">\(&lt;\)</span>argc;i++)</p>
<p>printf( “%d: \”%s\“\n”, i, argv[i] ); /* Все задачи завершают выполнение */ MPI_Finalize(); return 0; <span class="math">\(\}\)</span></p>
<p><span><strong>Функции пересылки данных.</strong></span> <span>****</span></p>
<p>Хотя с теоретической точки зрения ветвям для организации обмена данными достаточно всего двух операций (прием и передача), на практике все обстоит гораздо сложнее. Одними только коммуникациями “точка-точка” (т.е. такими, в которых ровно один передающий процесс и ровно один принимающий) занимается порядка 40 функций. Пользуясь ими, программист имеет возможность выбрать:</p>
<p>способ зацепления процессов - в случае неодновременного вызова двумя процессами парных функций приема и передачи могут быть произведены:</p>
<p>автоматический выбор одного из трех нижеприведенных вариантов;</p>
<p>буферизация на передающей стороне - функция передачи заводит временный буфер, копирует в него сообщение и возвращает управление вызвавшему процессу. Содержимое буфера будет передано в фоновом режиме;</p>
<p>ожидание на приемной стороне, завершение с кодом ошибки на передающей стороне;</p>
<p>ожидание на передающей стороне, завершение с кодом ошибки на приемной стороне.</p>
<p>способ взаимодействия коммуникационного модуля MPI с вызывающим процессом:</p>
<p>блокирующий - управление вызывающему процессу возвращается только после того, как данные приняты или переданы (или скопированы во временный буфер);</p>
<p>неблокирующий - управление возвращается немедленно (т.е. процесс блокируется до завершения операции), и фактическая приемопередача происходит в фоне. Функция неблокирующего приема имеет дополнительный параметр типа “квитанция”. Процесс не имеет права производить какие-либо действия с буфером сообщения, пока квитанция не будет “погашена”;</p>
<p>персистентный - в отдельные функции выделены:</p>
<p>создание “канала” для приема/передачи сообщения,</p>
<p>инициация приема/передачи,</p>
<p>закрытие канала. Такой способ эффективен, к примеру, если приемопередача происходит внутри цикла, а создание/закрытие канала вынесены за его границы.</p>
<p>Две простейшие (но и самые медленные) функции - MPI_Recv и MPI_Send - выполняют блокирующую приемопередачу с автоматическим выбором зацепления (кстати сказать, все функции приема совместимы со всеми функциями передачи). Таким образом, MPI - весьма разветвленный инструментарий. То, что в конкурирующих пакетах типа PVM реализовано одним-единственным способом, в MPI может быть сделано несколькими, про которые говорится: способ А прост в использовании, но не очень эффективен; способ Б сложнее, но эффективнее; а способ В сложнее и эффективнее при определенных условиях. Замечание о разветвленности относится и к коллективным коммуникациям (при которых получателей и/или отправителей несколько): в MPI эта категория представлена 9 функциями 5 типов: broadcast: один-всем, scatter: один-каждому, gather: каждый-одному, allgather: все-каждому, alltoall: каждый-каждому.</p>
<p>На первый взгляд может показаться, что программисту легче будет в случае необходимости самому написать такую функцию, но при этом он, скорее всего, будет использовать функции типа MPI_Send и MPI_Recv, в то время как имеющиеся в MPI функции оптимизированы - не пользуясь функциями “точка-точка”, они напрямую (на что, согласно идеологии MPI, программа пользователя права не имеет) обращаются к разделяемой памяти и семафорам и к TCP/IP при работе в сети. А если такая архитектурно-зависимая оптимизация невозможна, используется оптимизация архитектурно-независимая: передача производится не напрямую от одного ко всем (время передачи линейно зависит от количества ветвей-получателей), а по двоичному дереву (время передачи логарифмически зависит от количества). Как следствие, скорость работы повышается.</p>
<p><span><strong>Связь “точка-точка”. Простейший набор. Пример.</strong></span></p>
<p>Это самый простой тип связи между задачами: одна ветвь вызывает функцию передачи данных, а другая -  функцию приема. В MPI это выглядит, например, так: Задача 1 передает: int buf[10]; MPI_Send( buf, 5, MPI_INT, 1, 0, MPI_COMM_WORLD ); Задача 2 принимает: int buf[10]; MPI_Status status; MPI_Recv( buf, 10, MPI_INT, 0, 0, MPI_COMM_WORLD, &amp;status ); Аргументы функций: , из которого в задаче 1 берутся, а в задаче 2 помещаются данные. Наборы данных у каждой задачи свои, поэтому, например, используя одно и то же имя массива в нескольких задачах, указываете не одну и ту же область памяти, а разные, никак друг с другом не связанные. . Задается <span><strong>не в байтах</strong></span>, а в количестве ячеек. Для MPI_Send указывает, сколько ячеек требуется передать (в примере передаются 5 чисел). В MPI_Recv означает максимальную емкость приемного буфера. Если фактическая длина пришедшего сообщения меньше - последние ячейки буфера останутся нетронутыми, если больше - произойдет ошибка времени выполнения. . MPI_Send и MPI_Recv оперируют массивами однотипных данных. Для описания базовых типов Си в MPI определены константы MPI_INT, MPI_CHAR, MPI_DOUBLE и так далее, имеющие тип MPI_Datatype. Их названия образуются префиксом “MPI_” и именем соответствующего типа (int, char, double, ...), записанным заглавными буквами. Пользователь может “регистрировать” в MPI свои собственные типы данных, например, структуры, после чего MPI сможет обрабатывать их наравне с базовыми. , с которой происходит обмен данными. Все задачи внутри созданной MPI группы автоматически нумеруются от 0 до (размер группы-1). В примере задача 0 передает задаче 1, задача 1 принимает от задачи 0. . Это целое число от 0 до 32767, которое пользователь выбирает сам. Оно служит той же цели, что и, например, расширение файла - задача-приемник: по идентификатору определяет смысл принятой информации ; сообщения, пришедшие в неизвестном порядке, может извлекать из общего входного потока в нужном алгоритму порядке. Хорошим тоном является обозначение идентификаторов символьными именами посредством операторов “#define” или “const int”. (коммуникатор). Обязан быть одинаковым для MPI_Send и MPI_Recv. . Содержит информацию о принятом сообщении: его идентификатор, номер задачи-передатчика, код завершения и количество фактически пришедших данных.</p>
<p><span><strong>Коллективные функции.</strong></span></p>
<p>Под термином “коллективные” в MPI подразумеваются три группы функций:</p>
<p>точки синхронизации, или барьеры;</p>
<p>функции коллективного обмена данными (о них уже упоминалось выше);</p>
<p>функции поддержки распределенных операций.</p>
<p>Коллективная функция одним из аргументов получает описатель области связи (коммуникатор). Вызов коллективной функции является корректным, только если произведен из всех процессов-абонентов соответствующей области связи, и именно с этим коммуникатором в качестве аргумента (хотя для одной области связи может иметься несколько коммуникаторов, подставлять их вместо друг друга нельзя). В этом и заключается коллективность: либо функция вызывается всем коллективом процессов, либо никем; третьего не дано. Как поступить, если требуется ограничить область действия для коллективной функции только частью присоединенных к коммуникатору задач, или наоборот - расширить область действия? Нужно создавать временную группу/область связи/коммуникатор на базе существующих.   <span><strong>Основные особенности и отличия от коммуникаций типа “точка-точка”: </strong></span></p>
<p><span>****</span>на прием и/или передачу работают одновременно все задачи-абоненты указываемого коммуникатора;</p>
<p>коллективная функция выполняет одновременно и прием, и передачу; она имеет большое количество параметров, часть которых нужна для приема, а часть для передачи; в разных задачах та или иная часть игнорируется;</p>
<p>как правило, значения ВСЕХ параметров (за исключением адресов буферов) должны быть идентичными во всех задачах;</p>
<p>MPI назначает идентификатор для сообщений автоматически; кроме того, сообщения передаются не по указываемому коммуникатору, а по временному коммуникатору-дупликату; тем самым потоки данных коллективных функций надежно изолируются друг от друга и от потоков, созданных функциями “точка-точка”. <span>****</span> <span><strong>MPI_Bcast</strong></span> рассылает содержимое буфера из задачи, имеющей в указанной области связи номер <span><strong>root</strong></span>, во все остальные: MPI_Bcast( buf, count, dataType, rootRank, communicator ); <span><strong>MPI_Gather</strong></span> (“совок”) собирает в приемный буфер задачи root передающие буфера остальных задач. Векторный вариант “совка” - <span><strong>MPI_Gatherv</strong></span> - позволяет задавать разное количество отправляемых данных в разных задачах-отправителях. Соответственно, на приемной стороне задается массив позиций в приемном буфере, по которым следует размещать поступающие данные, и максимальные длины порций данных от всех задач. Оба массива содержат позиции/длины <span><strong>не</strong></span> в байтах, а в количестве ячеек типа recvCount. <span><strong>MPI_Scatter</strong></span> (“разбрызгиватель”) : выполняет обратную “совку” операцию - части передающего буфера из задачи root распределяются по приемным буферам всех задач И ее векторный вариант - <span><strong>MPI_Scatterv</strong></span>, рассылающая части неодинаковой длины в приемные буфера неодинаковой длины. <span><strong>MPI_Allgather</strong></span> аналогична MPI_Gather, но прием осуществляется не в одной задаче, а во ВСЕХ: каждая имеет специфическое содержимое в передающем буфере, и все получают одинаковое содержимое в буфере приемном. Как и в MPI_Gather, приемный буфер последовательно заполняется данными изо всех передающих. Вариант с неодинаковым количеством данных называется <span><strong>MPI_Allgatherv</strong></span>. <span><strong>MPI_Alltoall</strong></span> : каждый процесс нарезает передающий буфер на куски и рассылает куски остальным процессам; каждый процесс получает куски от всех остальных и поочередно размещает их приемном буфере. Это “совок” и “разбрызгиватель” в одном флаконе. Векторный вариант называется <span><strong>MPI_Alltoallv</strong></span>. Коллективные функции несовместимы с “точка-точка”: недопустимым, например, является вызов в одной из принимающих широковещательное сообщение задач MPI_Recv вместо MPI_Bcast.</p>
<p><span><strong>Точки синхронизации, или барьеры.</strong></span></p>
<p>Этим занимается всего одна функция:</p>
<p>int MPI_Barrier( MPI_Comm comm ); MPI_Barrier останавливает выполнение вызвавшей ее задачи до тех пор, пока не будет вызвана изо всех остальных задач, подсоединенных к указываемому коммуникатору. Гарантирует, что к выполнению следующей за MPI_Barrier инструкции каждая задача приступит одновременно с остальными. Это единственная в MPI функция, вызовами которой гарантированно синхронизируется во времени выполнение различных ветвей! Некоторые другие коллективные функции в зависимости от реализации могут обладать, а могут и не обладать свойством одновременно возвращать управление всем ветвям; но для них это свойство является побочным и необязательным - если Вам нужна синхронность, используйте только MPI_Barrier. Когда может потребоваться синхронизация? Например, синхронизация используется перед аварийным завершением. Это утверждение непроверено, но: алгоритмическое необходимости в барьерах, как представляется, нет. Параллельный алгоритм для своего описания требует по сравнению с алгоритмом классическим всего лишь двух дополнительных операций - приема и передачи из ветви в ветвь. Точки синхронизации несут чисто технологическую нагрузку вроде той, что описана в предыдущем абзаце. Иногда случается, что ошибочно работающая программа перестает врать, если ее исходный текст хорошенько нашпиговать барьерами. Однако программа начнет работать медленнее, например: Без барьеров: 0 xxxx....xxxxxxxxxxxxxxxxxxxx</p>
<p>1 xxxxxxxxxxxx....xxxxxxxxxxxx 2 xxxxxxxxxxxxxxxxxxxxxx....xx C барьерами: 0 xxxx....xx(xxxxxxxx(xxxxxxxx(xx 1 xxxxxx(x....xxxxxxx(xxxxxxxx(xx 2 xxxxxx(xxxxxxxx(..xxxxxxxx(xx —————————– <span class="math">\(&gt;\)</span> Время</p>
<p>Обозначения: x нормальное выполнение . ветвь простаивает - процессорное время отдано под другие цели ( вызван MPI_Barrier MPI_Barrier ждет своего вызова в остальных ветвях Так что “задавить” ошибку барьерами хорошо только в качестве временного решения на период отладки.  </p>
<p><span><strong>Распределенные операции.</strong></span> <span>**<span><strong></span></strong></span></p>
<p>Идея проста: в каждой задаче имеется массив. Над нулевыми ячейками всех массивов производится некоторая операция (сложение/произведение/ поиск минимума/максимума и т.д.), над первыми ячейками производится такая же операция и т.д. <span class="math">\(\times\)</span>етыре функции предназначены для вызова этих операций и отличаются способом размещения результата в задачах. MPI_Reduce : массив с результатами размещается в задаче с номером <span><strong>root</strong></span>: int vector[16]; int resultVector[16]; MPI_Comm_rank( MPI_COMM_WORLD, &amp;myRank ); for( i=0; i$&lt;$16; i++ ) vector[i] = myRank*100 + i; MPI_Reduce( vector, /* каждая задача в коммуникаторе предоставляет вектор */ resultVector, /* задача номер ’root’ собирает данные сюда */ 16, /* количество ячеек в исходном и результирующем массивах */ MPI_INT, /* и тип ячеек */ MPI_SUM, /* описатель операции: поэлементное сложение векторов */ 0, /* номер задачи, собирающей результаты в ’resultVector’ */ MPI_COMM_WORLD /* описатель области связи */ ); if( myRank==0 ) /* печатаем resultVector, равный сумме векторов */</p>
<p>Предопределенных описателей операций в MPI насчитывается 12: <span><strong>1. MPI_MAX</strong></span> и <span><strong>MPI_MIN</strong></span> ищут поэлементные максимум и минимум; <span><strong>2. MPI_SUM</strong></span> вычисляет сумму векторов; <span><strong>3. MPI_PROD</strong></span> вычисляет поэлементное произведение векторов; <span><strong>4. MPI_LAND</strong></span>, <span><strong>MPI_BAND</strong></span>, <span><strong>MPI_LOR</strong></span>, <span><strong>MPI_BOR</strong></span>, <span><strong>MPI_LXOR</strong></span>, <span><strong>MPI_BXOR</strong></span> - логические и двоичные операции И, ИЛИ, исключающее ИЛИ; <span><strong>5. MPI_MAXLOC</strong></span>, <span><strong>MPI_MINLOC</strong></span> - поиск индексированного минимума/максимума.</p>
<p>Количество поддерживаемых операциями типов для ячеек векторов строго ограничено вышеперечисленными. Никакие другие встроенные или пользовательские описатели типов использоваться не могут! Все операции являются ассоциативными ( “(a+b)+c = a+(b+c)” ) и коммутативными ( “a+b = b+a” ). MPI_Allreduce : результат рассылается всем задачам, параметр ’root’ убран. MPI_Reduce_scatter : каждая задача получает не весь массив-результат, а его часть. Длины этих частей находятся в массиве-третьем параметре функции. Размер исходных массивов во всех задачах одинаков и равен сумме длин результирующих массивов. MPI_Scan : аналогична функции MPI_Allreduce в том отношении, что каждая задача получает результрующий массив. Главное отличие: здесь содержимое массива-результата в задаче <span><strong>i</strong></span> является результатом выполнение операции над массивами из задач с номерами от <span><strong>0</strong></span> до <span><strong>i</strong></span> включительно. Помимо встроенных, пользователь может вводить свои собственные операции.</p>
<p><span><strong>Создание коммуникаторов и групп.</strong></span></p>
<p>Самый простой способ создания коммуникатора - скопировать “один-в-один” уже имеющийся: MPI_Comm tempComm; MPI_Comm_dup( MPI_COMM_WORLD, &amp;tempComm ); /* ... передаем данные через tempComm ... */ MPI_Comm_free( &amp;tempComm ); Новая группа при этом не создается - набор задач остается прежним. Новый коммуникатор наследует все свойства копируемого.</p>
<p>Соответствующая коммуникатору группа расщепляется на непересекающиеся подгруппы, для каждой из которых заводится свой коммуникатор. MPI_Comm_split( existingComm, /* существующий описатель, например MPI_COMM_WORLD */ indexOfNewSubComm, /* номер подгруппы, куда надо поместить ветвь */ rankInNewSubComm, /* желательный номер в новой подгруппе */ &amp;newSubComm ); /* описатель области связи новой подгруппы */ Эта функция имеет одинаковый первый параметр во всех ветвях, но разные второй и третий - и в зависимости от них разные ветви определяются в разные подгруппы; возвращаемый в четвертом параметре описатель будет принимать в разных ветвях разные значения (всего столько разных значений, сколько создано подгрупп). Если indexOfNewSubComm равен <span><strong>MPI_UNDEFINED</strong></span>, то в newSubComm вернется MPI_COMM_NULL, то есть ветвь не будет включена ни в какую из созданных групп.</p>
<p>В предыдущих двух случаях коммуникатор создается от существующего коммуникатора напрямую, без явного создания группы: группа либо та же самая, либо создается автоматически. Самый же общий способ таков:</p>
<p>функцией <span><strong>MPI_Comm_group</strong></span> определяется группа, на которую указывает соответствующий коммуникатор;</p>
<p>на базе существующих групп функциями семейства <span><strong>MPI_Group_xxx</strong></span> создаются новые группы с нужным набором ветвей;</p>
<p>для итоговой группы функцией <span><strong>MPI_Comm_create</strong></span> создается коммуникатор. Она должна быть вызвана во <span><strong>всех</strong></span> ветвях-абонентах коммуникатора, передаваемого первым параметром;</p>
<p>все описатели созданных групп очищаются вызовами функции <span><strong>MPI_Group_free</strong></span>. Такой механизм позволяет не только расщеплять группы подобно MPI_Comm_split, но и объединять их. Всего в MPI определено 7 разных функций конструирования групп.</p>
<p><span><strong>MPI и типы данных.</strong></span></p>
<p>О типах передаваемых данных MPI должен знать постольку-поскольку при работе в сетях на разных машинах данные могут иметь разную разрядность (например, тип <span><em>int</em></span> - 4 или 8 байт), ориентацию (младший байт располагается в ОЗУ первым на процессорах Intel, последним - на всех остальных), и представление (это, в первую очередь, относится к размерам мантиссы и экспоненты для вещественных чисел). Поэтому все функции приемопередачи в MPI оперируют не количеством передаваемых байт, а количеством ячеек, тип которых задается параметром функции, следующим за количеством: MPI_INTEGER, MPI_REAL и т.д. Это переменные типа MPI_Datatype (тип “описатель типов”, каждая его переменная описывает для MPI один тип). Они имеются для каждого базового типа, имеющегося в используемом языке программирования. Однако, пользуясь базовыми описателями, можно передавать либо массивы, либо одиночные ячейки (как частный случай массива). А как передавать данные агрегатных типов, например, структуры? В MPI имеется механизм конструирования пользовательских описателей на базе уже имеющихся (как пользовательских, так и встроенных). Более того, разработчики MPI создали механизм конструирования новых типов даже более универсальный, чем имеющийся в языке программирования. Действительно, во всех языках программирования ячейки внутри агрегатного типа (массива или структуры):</p>
<p>не налезают друг на друга, не располагаются с разрывами (выравнивание полей в структурах не в счет). В MPI сняты оба этих ограничения. Это позволяет весьма причудливо “вырезать”, в частности, фрагменты матриц для передачи, и размещать принимаемые данные между собственных. Выигрыш от использования механизма конструирования типов очевиден - лучше один раз вызвать функцию приемопередачи со сложным шаблоном, чем двадцать раз - с простыми.  </p>
<p><span><strong>Зачем MPI знать тип передаваемых данных? </strong></span></p>
<p>Действительно, зачем? Стандартные функции пересылки данных прекрасно обходятся без подобной информации - им требуется знать только размер в байтах. Вместо одного такого аргумента функции MPI получают два: количество элементов некоторого типа и символический описатель указанного типа (MPI_INT, и т.д.). Причин тому несколько:</p>
<p>Пользователю MPI позволяет описывать свои собственные типы данных, которые располагаются в памяти не непрерывно, а с разрывами, или наоборот, с “налезаниями” друг на друга. Переменная такого типа характеризуется не только размером, и эти характеристики MPI хранит в описателе типа.</p>
<p>Приложение MPI может работать на гетерогенном вычислительном комплексе (коллективе ЭВМ с разной архитектурой). Одни и те же типы данных на разных машинах могут иметь разное представление, например: на плавающую арифметику существует 3 разных стандарта (IEEE,IBM,Cray); тип char в терминальных приложениях Windows представлен альтернативной кодировкой ГОСТ, а в Юниксе - кодировкой KOI-8r ; ориентация байтов в многобайтовых числах на ЭВМ с процессорами Intel отличается от общепринятой (у Intel - младший байт занимает младший адрес, у всех остальных - наоборот). Если приложение работает в гетерогенной сети, через сеть задачи обмениваются данными в формате XDR (eXternal Data Representation), принятом в Internet. Перед отправкой и после приема данных задача конвертирует их в/из формата XDR. Естественно, при этом MPI должен знать не просто количество передаваемых байт, но и тип содержимого.</p>
<p>Обязательным требованием к MPI была поддержка языка Фортран в силу его инерционной популярности. Фортрановский тип CHARACTER требует особого обращения, поскольку переменная такого типа содержит не собственно текст, а адрес текста и его длину. Функция MPI, получив адрес переменной, должна извлечь из нее адрес текста и копировать сам текст. Это и произойдет, если в поле аргумента-описателя типа стоит MPI_CHARACTER. Ошибка в указании типа приведет: при отправке - к копированию служебных данных вместо текста, при приеме - к записи текста на место служебных данных. И то, и другое приводит к ошибкам времени выполнения.</p>
<p>Такие часто используемые в Си типы данных, как структуры, могут содержать в себе некоторое пустое пространство, чтобы все поля в переменной такого типа размещались по адресам, кратным некоторому четному числу (часто 2, 4 или 8) - это ускоряет обращение к ним. Причины тому чисто аппаратные. Выравнивание данных настраивается ключами компилятора. Разные задачи одного и того же приложения, выполняющиеся на одной и той же машине (даже на одном и том же процессоре), могут быть построены с разным выравниванием, и типы с одинаковым текстовым описанием будут иметь разное двоичное представление. MPI будет вынужден позаботиться о правильном преобразовании. Например, переменные такого типа могут занимать 9 или 16 байт: typedef struct <span class="math">\(\{\)</span> char c; double d; <span class="math">\(\}\)</span> CharDouble;</p>
<p><span><strong>Использование MPI.</strong></span></p>
<p>MPI сам по себе является средством:</p>
<p>сложным: спецификация на MPI-1 содержит 300 страниц, на MPI-2 - еще 500 (причем это <span><em>только отличия и добавления</em></span> к MPI-1), и программисту для эффективной работы так или иначе придется с ними ознакомиться, помнить о наличии нескольких сотен функций, и о тонкостях их применения;</p>
<p>специализированным: это система связи.</p>
<p>Можно сказать, что сложность (т.е. многочисленность функций и обилие аргументов у большинства из них) является ценой за компромисс между эффективностью и универсальностью. С одной стороны, на SMP-машине должны существовать способы получить <span><em>почти</em></span> столь же высокую скорость при обмене данными между ветвями, как и при традиционном программировании через разделяемую память и семафоры. С другой стороны, все функции должны работать на любой платформе. Таким образом, программист заинтересован в инструментах, которые облегчали бы:</p>
<p>проведение декомпозиции,</p>
<p>запись ее в терминах MPI.</p>
<p>В данном случае это средства, генерирующие на базе входных данных текст программы на стандартном Си или Фортране, обладающей явным параллелизмом, выраженным в терминах MPI; содержащий вызовы MPI-процедур, наиболее эффективные в окружающем контексте. Такие средства делают написание программы не только легче, но и надежнее. Назовем некоторые перспективные типы такого инструментария, который лишал бы программиста необходимости вообще помнить о присутствии MPI.</p>
<p><span><strong>Средства автоматической декомпозиции.</strong></span> Идеалом является такое оптимизирующее средство, которое на входе получает исходный текст некоего последовательного алгоритма, написанный на обычном языке программирования, и выдает на выходе исходный текст этого же алгоритма на этом же языке, но уже в распараллеленном на ветви виде, с вызовами MPI. <span class="math">\(\times\)</span>то ж, такие средства созданы, но никто не торопится раздавать их бесплатно. Кроме того, вызывает сомнение их эффективность.</p>
<p><span><strong>Языки программирования.</strong></span> Это наиболее популярные на сегодняшний день средства полуавтоматической декомпозиции. В синтаксис универсального языка программирования (Си или Фортрана) вводятся дополнения для записи параллельных конструкций кода и данных. Препроцессор переводит текст в текст на стандартном языке с вызовами MPI. Примеры таких систем: mpC (massively parallel C) и HPF (High Performance Fortran).</p>
<p><span><strong>Оптимизированные библиотеки для стандартных языков. </strong></span>В этом случае оптимизация вообще может быть скрыта от проблемного программиста. <span class="math">\(\times\)</span>ем больший объем работы внутри программы отводится подпрограммам такой библиотеки, тем большим будет итоговый выигрыш в скорости ее (программы) работы. Собственно же программа пишется на обычном языке программирования безо всяких упоминаний об MPI, и строится стандартным компилятором. От программиста потребуется лишь указать для компоновки имя библиотечного файла MPI, и запускать полученный в итоге исполняемый код не непосредственно, а через MPI-загрузчик. Популярные библиотеки обработки матриц, такие как Linpack, Lapack и ScaLapack, уже переписаны под MPI.</p>
<p><span><strong>Средства визуального проектирования.</strong></span> Действительно, почему бы не расположить на экране несколько окон с исходным текстом ветвей, и пусть пользователь легким движением мыши протягивает стрелки от точек передачи к точкам приема - а визуальный построитель генерирует полный исходный текст?</p>
<p><span><strong>Отладчики. </strong></span>Об отладчиках пока можно сказать только то, что они нужны. Должна быть возможность одновременной трассировки/просмотра нескольких параллельно работающих ветвей - что-либо более конкретное пока сказать трудно.</p>
<p><span><strong>MPI-1 и MPI-2.</strong></span></p>
<p>В функциональности MPI есть пробелы, которые устранены в следующем проекте, MPI-2. Вкратце перечислим наиболее важные нововведения:</p>
<p>Взаимодействие между приложениями. Поддержка механизма “клиент-сервер”.</p>
<p>Динамическое порождение ветвей. </p>
<p>Для работы с файлами создан архитектурно-независимый интерфейс.  </p>
<p>Сделан шаг в сторону SMP-архитектуры. Теперь разделяемая память может быть не только каналом связи между ветвями, но и местом совместного хранения данных.</p>
<p><span><strong>Пример.</strong></span> /* * Простейшая приемопередача: * MPI_Send, MPI_Recv * Завершение по ошибке: * MPI_Abort */</p>
<p>#include <span class="math">\(&lt;\)</span>mpi.h<span class="math">\(&gt;\)</span> #include <span class="math">\(&lt;\)</span>stdio.h<span class="math">\(&gt;\)</span></p>
<p>/* Идентификаторы сообщений */ #define tagFloatData 1 #define tagDoubleData 2</p>
<p>/* Этот макрос введен для удобства, */ /* он позволяет указывать длину массива в количестве ячеек */ #define ELEMS(x) ( sizeof(x) / sizeof(x[0]) )</p>
<p>int main( int argc, char **argv ) <span class="math">\(\{\)</span> int size, rank, count; float floatData[10]; double doubleData[20]; MPI_Status status; /* Инициализируем библиотеку */ MPI_Init( &amp;argc, &amp;argv ); /* Узнаем количество задач в запущенном приложении */ MPI_Comm_size( MPI_COMM_WORLD, &amp;size ); /* ... и свой собственный номер: от 0 до (size-1) */ MPI_Comm_rank( MPI_COMM_WORLD, &amp;rank ); /* пользователь должен запустить ровно две задачи, иначе ошибка */ if( size != 2 ) <span class="math">\(\{\)</span> /* задача с номером 0 сообщает пользователю об ошибке */ if( rank==0 ) printf(“Error: two processes required instead of %d, abort\n”, size ); /* Все задачи-абоненты области связи MPI_COMM_WORLD * будут стоять, пока задача 0 не выведет сообщение. */ MPI_Barrier( MPI_COMM_WORLD ); /* Без точки синхронизации может оказаться, что одна из задач * вызовет MPI_Abort раньше, чем успеет отработать printf() * в задаче 0, MPI_Abort немедленно принудительно завершит * все задачи и сообщение выведено не будет */ /* все задачи аварийно завершают работу */ MPI_Abort( MPI_COMM_WORLD, /* Описатель области связи, на которую */ /* распространяется действие ошибки */ MPI_ERR_OTHER ); /* Целочисленный код ошибки */ return -1; <span class="math">\(\}\)</span> if( rank==0 ) <span class="math">\(\{\)</span> /* Задача 0 что-то такое передает задаче 1 */ MPI_Send( floatData, /* 1) адрес передаваемого массива */ 5, /* 2) сколько: 5 ячеек, т.е. floatData[0]..floatData[4] */ MPI_FLOAT, /* 3) тип ячеек */ 1, /* 4) кому: задаче 1 */ tagFloatData, /* 5) идентификатор сообщения */ MPI_COMM_WORLD ); /* 6) описатель области связи, через которую */ /* происходит передача */ /* и еще одна передача: данные другого типа */ MPI_Send( doubleData, 6, MPI_DOUBLE, 1, tagDoubleData, MPI_COMM_WORLD ); <span class="math">\(\}\)</span> else <span class="math">\(\{\)</span> /* Задача 1 что-то такое принимает от задачи 0 */ /* дожидаемся сообщения и помещаем пришедшие данные в буфер */ MPI_Recv( doubleData, /* 1) адрес массива, куда складывать принятое */ ELEMS( doubleData ), /* 2) фактическая длина приемного */ /* массива в числе ячеек */ MPI_DOUBLE, /* 3) сообщаем MPI, что пришедшее сообщение */ /* состоит из чисел типа ’double’ */ 0, /* 4) от кого: от задачи 0 */ tagDoubleData, /* 5) ожидаем сообщение с таким идентификатором */ MPI_COMM_WORLD, /* 6) описатель области связи, через которую */ /* ожидается приход сообщения */ &amp;status ); /* 7) сюда будет записан статус завершения приема */</p>
<p>/* Вычисляем фактически принятое количество данных */ MPI_Get_count( &amp;status, /* статус завершения */ MPI_DOUBLE, /* сообщаем MPI, что пришедшее сообщение */ /* состоит из чисел типа ’double’ */ &amp;count ); /* сюда будет записан результат */</p>
<p>/* Выводим фактическую длину принятого на экран */ printf(“Received %d elems\n”, count );</p>
<p>/* Аналогично принимаем сообщение с данными типа float * Обратите внимание: задача-приемник имеет возможность * принимать сообщения не в том порядке, в котором они * отправлялись, если эти сообщения имеют разные идентификаторы */ MPI_Recv( floatData, ELEMS( floatData ), MPI_FLOAT, 0, tagFloatData, MPI_COMM_WORLD, &amp;status ); MPI_Get_count( &amp;status, MPI_FLOAT, &amp;count ); <span class="math">\(\}\)</span> /* Обе задачи завершают выполнение */ MPI_Finalize(); return 0; <span class="math">\(\}\)</span></p>
<p>Приложение.</p>
<p>Коллективные функции:</p>
<div class="figure">
<img src="image10" alt="image" /><p class="caption">image</p>
</div>
<p><span>****</span> <span><strong>Общие функции</strong></span> <span>****</span> <span><strong>int MPI_Init( int* argc, char*** argv)</strong></span> <span><strong>int MPI_Finalize( void )</strong></span></p>
<p><span><strong>int MPI_Comm_size( MPI_Comm comm, int* size)</strong></span> <span><strong>int MPI_Comm_rank( MPI_comm comm, int* rank)</strong></span></p>
<p><span><strong>double MPI_Wtime(void)</strong></span></p>
<p><span><strong>int MPI_Barrier( MPI_Comm comm) </strong></span></p>
<p><span>****</span></p>
<p><span><strong>16. Методы представления знаний в системах искусственного интеллекта (язык предикатов, семантические сети, фреймы, продукции). </strong></span></p>
<p>Составляющие обучения:</p>
<p>Знания - усвоенные Понятия</p>
<p>Умения - автоматизированные действия по решению определенных задач</p>
<p>Навыки - адаптивные способности человека Все три составляющие представляют знания в ИИ. Знания хранятся в Базе Знаний (БЗ).</p>
<p>База знаний состоит из:</p>
<p>Базы фактов</p>
<p>Базы правил</p>
<p>Базы понятий</p>
<p>Базы процедур (то есть умений)</p>
<p>Базы целей</p>
<p>Базы метазнаний (то есть знаний о себе)</p>
<p>Способы представления знаний:</p>
<p>декларативные</p>
<p>процедурные</p>
<p>Метод представления знаний - совокупность взаимосвязанных средств описания знаний и оперирования этими описаниями.</p>
<p><span><em>Методы представления.</em></span></p>
<p><span><strong>Логические методы (язык предикатов)</strong></span> Знания, необходимые для решения задач и организации взаимодействия с пользователем, - факты (утверждения). Факт - формула в некоторой логике. Система знаний - совокупность формул. База знаний - система знаний в компьютерном представлении.</p>
<p>Основные операции: логический вывод (доказательство теорем).</p>
<p>Достоинства:</p>
<p>формальный аппарат вывода (новых фактов/знаний из известных фактов/знаний)</p>
<p>возможность контроля целостности</p>
<p>простая и ясная нотация.</p>
<p>Недостатки:</p>
<p>знания трудно структурировать</p>
<p>при большом количестве формул вывод идет очень долго</p>
<p>при большом количестве формул их совокупность трудно обозрима.</p>
<p><span><strong>Семантические сети</strong></span> Знания, необходимые для решения задач и организации взаимодействия с пользователем, - объекты/события и связи между ними. Статические семантические сети - сети с объектами. Динамические семантические сети (сценарии) - сети с событиями. Система знаний - совокупность сетей (или одна общая сеть). База знаний - система знаний в компьютерном представлении.</p>
<p>Для представления семантических сетей используются графы:</p>
<p>вершина - атомарный объект (событие),</p>
<p>подграф - структурно сложный объект (событие),</p>
<p>дуга - отношение или действие Основные операции: сопоставление с образцом, поиск, замена, взятие копии.</p>
<p>Достоинства: знания хорошо структурированы, структура понятна человеку.</p>
<p>Недостатки:</p>
<p>при большом объеме сети очень долго выполняются все операции;</p>
<p>при большом объеме сети она трудно обозрима.</p>
<p><span><strong>Фреймы</strong></span> Знания, необходимые для решения задач и организации взаимодействия с пользователем, - фреймы. Фрейм-понятие - отношение/действие + связанные этим отношением/участвующие в этом действии объекты. Фрейм-пример - конкретный экземпляр отношения/действия + конкретные объекты (связанные этим отношением/участвующие в этом действии). Система знаний - совокупность фреймов-понятий и фреймов-примеров. База знаний - система знаний в компьютерном представлении.</p>
<p>Фрейм:</p>
<p>ИМЯ - отношение/действие</p>
<p>СЛОТЫ - объекты или другие фреймы. С каждым слотом может быть связана такая информация:</p>
<p>УСЛОВИЕ НА ЗАПОЛНЕНИЕ (тип, “по умолчанию”, связь с другими слотами)</p>
<p>АССОЦИИРОВАННЫЕ ПРОЦЕДУРЫ (действия, выполняемые, например, при заполнении этого слота) Основные операции: поиск фрейма/слота, замена значения слота, взятие копии фрейма-понятия.</p>
<p>Достоинства: знания хорошо структурированы, структура понятна человеку.</p>
<p>Недостатки:</p>
<p>при большом количестве фреймов долго выполняются все операции;</p>
<p>при большом количестве фреймов знания трудно обозримы.</p>
<p><span><strong>Продукции</strong></span> Знания, необходимые для решения задач и организации взаимодействия с пользователем, - продукции (продукционные правила). Продукция - правило вида: p: a<span class="math">\(\to \)</span>b (где: p - предусловие, a - антецедент, b - консеквент). Система знаний - система продукционных правил + стратегия выбора правил. База знаний - система знаний в компьютерном представлении.</p>
<p>Основные операции: вывод (применение правила, определение правила-преемника и т.д.).</p>
<p>Достоинства: простая и ясная нотация.</p>
<p>Недостатки:</p>
<p>при большом количестве правил вывод идет очень долго;</p>
<p>при большом количестве правил их совокупность трудно обозрима.</p>
<p><span>****</span></p>
<p><span><strong>17. Методы поиска решения задач в системах искусственного интеллекта (эвристический поиск в пространстве состояний и на И/ИЛИ деревьях). </strong></span></p>
<p><span><strong>Представление задач в пространстве состояний</strong></span> Ключевым понятием при формализации задачи в пространстве состояний является понятие состояния, характеризующего некоторый момент решения задачи. Среди всех состояний выделяются начальное состояние и целевое состояние (целевая конфигурация), в совокупности определяющие задачу, которую надо решить.</p>
<p>Другим важным понятием для рассматриваемого представления является понятие оператора, или допустимого хода в задаче. Оператор преобразует одно состояние в другое, являясь, по сути, функцией, определенной на множестве состояний и принимающей значения из этого множества.</p>
<p>В терминах состояний и операторов решение задачи есть определенная последовательность операторов, преобразующая начальное состояние в целевое. Решение задачи ищется в пространстве состояний - множестве состояний, достижимых из начального состояния при помощи операторов.</p>
<p>Пространство состояний можно представить в виде графа, вершины которого соответствуют состояниям, а дуги - применяемым операторам. Тогда решение задачи - это путь, ведущий от начального состояния к целевому. Пространства состояний могут быть большими и даже бесконечными, но в любом случае предполагается конечность множества допустимых операторов и счетность множества возможных состояний.</p>
<p>Итак, формализация задачи с использованием пространства состояний включает выявление и определение следующих составляющих:</p>
<p>формы описания состояний и описание исходной задачи;</p>
<p>множество операторов и их воздействий на описания состояний;</p>
<p>указание свойств целевых состояний (или же явное их задание). Эти составляющие задают (неявно) пространство, в котором требуется провести поиск решения задачи. Ясно, что решение задачи, представленной описанным способом, можно в принципе обнаружить, осуществляя последовательный поиск, или перебор вершин, в пространстве состояний. В начале этого процесса к начальному состоянию применяется тот или иной оператор. Затем на каждом шаге поиска к одному из уже полученных (просмотренных) состояний применяется допустимый оператор и строится новая вершина. Поиск заканчивается, когда построено целевое состояние. <span>****</span> <span><strong>Алгоритмы поиска решения (в пространстве состояний)</strong></span> Алгоритмы поиска в пространстве состояний базируются на последовательном переборе вершин пространства состояния - до тех пор, пока не будет обнаружена целевая вершина. Вершины и указатели, построенные в процессе перебора, образуют поддерево всего неявно определенного пространства состояний. Будем называть такое поддерево деревом перебора. Известные алгоритмы поиска в пространстве состояний различаются несколькими характеристиками:</p>
<p>использованием или нет эвристической информации (соответственно, слепые и эвристические алгоритмы);</p>
<p>порядком раскрытия (обхода) вершин (соответственно в ширину и глубину)</p>
<p>полнотой просмотра пространства (просмотр либо полного пространства, либо его части)</p>
<p>направлением поиска (прямые – от начальной вершины к целевой, обратные – от целевой к начальной и двунаправленные). <span>****</span> <span><strong>Поиск на игровых деревьях</strong></span> Будем рассматривать класс игр двух лиц с полной информацией. В таких играх участвуют два игрока, которые поочередно делают свои ходы. В любой момент игры каждому игроку известно все, что произошло в игре к этому моменту и что может быть сделано в настоящий момент. Игра заканчивается либо выигрышем одного игрока (и проигрышем другого), либо ничьей.</p>
<p>Для формализации и изучения игровых стратегий в классе игр с полной информацией может быть использован подход, основанный на редукции задач. Напомним, что при этом должны быть определены следующие составляющие: форма описания задач и подзадач; операторы, сводящие задачи к подзадачам; элементарные задачи; а также задано описание исходной задачи.</p>
<p>Рассмотрим задачу поиска выигрышной стратегии для одного из игроков, отправляясь от некоторой фиксированной конфигурации (позиции) игры (не обязательно начальной). При использовании подхода, основанного на редукции задач, выигрышная стратегия ищется в процессе доказательства того, что игра может быть выиграна. Аналогично, поиск ничейной стратегии, исходя из некоторой конкретной позиции, ведется в процессе доказательства того, что игра может быть сведена к ничьей.</p>
<p>X<span class="math">\({}_{S}\)</span> (или Y<span class="math">\({}_{S}\)</span>) - некоторая конфигурация игры, причем индекс S принимает значения “+” или “-”, указывая тем самым, кому принадлежит следующий ход, то есть в конфигурации X+ следующий ход должен делать первый игрок, а в X- второй. W(X<span class="math">\({}_{S}\)</span>) - задача доказательства того, что первый игрок может выиграть, исходя из конфигурации X<span class="math">\({}_{S}\)</span>; V(X<span class="math">\({}_{S}\)</span>) - задача доказательства того, что второй игрок может выиграть, отправляясь от конфигурации X<span class="math">\({}_{S}\)</span>.</p>
<p>Рассмотрим игровую задачу W(X<span class="math">\({}_{S}\)</span>). Операторы сведения этой задачи к подзадачам определяются исходя из ходов, допустимых в проводимой игре:</p>
<p>Если в некоторой конфигурации X+ очередь делать ход за игроком один, и имеется N допустимых ходов, приводящих соответственно к конфигурациям X<span class="math">\({}_{1}\)</span>-, X<span class="math">\({}_{2}\)</span>-, ..., X<span class="math">\({}_{N}\)</span>- , то для решения задачи W(X+) необходимо решить по крайней мере одну из подзадач W(X<span class="math">\({}_{i}\)</span>-) (так как ход выбирает первый игрок, то он выиграет игру, если хотя бы один из ходов ведет к выигрышу).</p>
<p>Если же в некоторой конфигурации Y- ход должен сделать игрок два, и имеется K допустимых ходов, приводящих к конфигурациям Y<span class="math">\({}_{1}\)</span>+, Y<span class="math">\({}_{2}\)</span>+, ..., Y<span class="math">\({}_{K}\)</span>+, то для решения задачи W(Y-) требуется решить каждую из возникающих подзадач W(Y<span class="math">\({}_{i}\)</span>+) (так как ход выбирает второй игрок, то первый выиграет игру, если выигрыш гарантирован ему после любого хода противника).</p>
<p>Последовательное применение для исходной конфигурации игры данной схемы сведения игровых задач к совокупности подзадач порождает И/ИЛИ-дерево (И/ИЛИ-граф), которое называют деревом (графом) игры. Дуги игрового дерева соответствуют ходам игроков, вершины - конфигурациям игры, причем листья дерева - это позиции, в которых игра завершается выигрышем, проигрышем или ничьей. <span class="math">\(\times\)</span>асть листьев являются заключительными вершинами, соответствующими элементарным задачам - позициям, выигрышным для первого игрока. Заметим, что для конфигураций, где ход принадлежит первому игроку, в игровом дереве получается ИЛИ-вершина, а для позиций, в которых ходит второй игрок, - И-вершина.</p>
<p>Цель построения игрового дерева или графа - получение решающего поддерева (подграфа) для задачи W(X<span class="math">\({}_{S}\)</span>), показывающего, как первый игрок может выиграть игру из позиции X<span class="math">\({}_{S}\)</span> независимо от ответов противника.</p>
<p>В случаях, когда пространство ходов велико (как и во всех сложных играх), вместо нереальной задачи поиска полной игровой стратегии решается, как правило, более простая задача - поиск для заданной позиции игры достаточно хорошего первого хода. <span>****</span> <span><strong>Минимаксная процедура</strong></span> С целью поиска достаточно хорошего первого хода просматривается обычно часть игрового дерева, построенного от заданной конфигурации. Для этого применяется один из переборных алгоритмов (в глубину, в ширину или эвристический) и некоторое искусственное окончание перебора вершин в игровом дереве: например, ограничивается время перебора или же глубина поиска.</p>
<p>После построения таким образом частичного дерева игры вершины в нем оцениваются, и по этим оценкам определяется наилучший ход от заданной игровой конфигурации. При этом:</p>
<p>Листовые вершины оцениваются статической оценочной функций</p>
<p>Нелистовые вершины оцениваются по минимаксному принципу.</p>
<p>Значение статической оценочной функции тем больше, чем больше преимуществ имеет первый игрок (над вторым игроком) в оцениваемой позиции. Очень часто оценочная функция выбирается следующим образом:</p>
<p>статическая оценочная функция положительна в игровых конфигурациях, где первый игрок имеет преимущества;</p>
<p>статическая оценочная функция отрицательна в конфигурациях, где второй игрок имеет преимущества;</p>
<p>статическая оценочная функция близка к нулю в позициях, не дающих преимущества ни одному из игроков.</p>
<p>Минимаксный принцип:</p>
<p>ИЛИ-вершине дерева игры приписывается оценка, равная максимуму оценок ее дочерних вершин;</p>
<p>И-вершине игрового дерева приписывается оценка, равная минимуму оценок ее дочерних вершин.</p>
<p>Основные этапы минимаксной процедуры:</p>
<p>Дерево игры строится (просматривается) одним из известных алгоритмов.</p>
<p>Все концевые вершины полученного дерева, то есть вершины, находящиеся на глубине N, оцениваются с помощью статической оценочной функции.</p>
<p>В соответствии с минимаксным принципом вычисляются оценки всех остальных вершин.</p>
<p>Среди вершин, дочерних к начальной, выбирается вершина с наибольшей оценкой: ход, который к ней ведет, и есть искомый наилучший ход в игровой конфигурации S. <span>****</span> <span><strong>Альфа-бета процедура</strong></span> Правила вычисления оценок вершин дерева игры, в том числе предварительных оценок промежуточных вершин, которые для удобства будем называть <span class="math">\(\alpha \)</span> и <span class="math">\(\beta \)</span>-величинами:</p>
<p>концевая вершина дерева оценивается статической оценочной функцией сразу, как только она построена;</p>
<p>промежуточная вершина предварительно оценивается по минимаксному принципу, как только стала известна оценка хотя бы одной из ее дочерних вершин; каждая предварительная оценка пересчитывается (уточняется) всякий раз, когда получена оценка еще одной дочерней вершины;</p>
<p>предварительная оценка ИЛИ-вершины (<span class="math">\(\alpha \)</span>-величина) полагается равной наибольшей из вычисленных к текущему моменту оценок ее дочерних вершин;</p>
<p>предварительная оценка И-вершины (<span class="math">\(\beta \)</span>-величина) полагается равной наименьшей из вычисленных к текущему моменту оценок ее дочерних вершин. Укажем очевидное следствие этих правил вычисления: <span class="math">\(\alpha \)</span>-величины не могут уменьшаться, а <span class="math">\(\beta \)</span>-величины не могут увеличиваться. Сформулируем теперь правила прерывания перебора, или отсечения ветвей игрового дерева:</p>
<p><span class="math">\(\alpha \)</span>-отсечение: Перебор можно прервать ниже любой И-вершины, <span class="math">\(\beta \)</span>-величина которой не больше, чем <span class="math">\(\alpha \)</span>-величина одной из предшествующих ей ИЛИ-вершин (включая корневую вершину дерева);</p>
<p><span class="math">\(\beta \)</span>-отсечение: Перебор можно прервать ниже любой ИЛИ-вершины, <span class="math">\(\alpha \)</span>-величина которой не меньше, чем <span class="math">\(\beta \)</span>-величина одной из предшествующих ей И-вершин. Утверждение: <span class="math">\(\alpha \)</span>-<span class="math">\(\beta \)</span>процедура всегда приводит к тому же результату (наилучшему первому ходу), что и простая минимаксная процедура той же глубины.</p>
<p><span>****</span></p>
<p><span><strong>18. Организация сетевого взаимодействия. Эталонная модель OSI ISO. Основные элементы и архитектура OSI ISO. Уровни протоколов и их основные функции. </strong></span></p>
<p><span><strong><span><em>Вычислительная сеть</em></span></strong></span> или <span><strong><span><em>сеть ЭВМ</em></span></strong></span> есть, в некотором смысле, развитие и обобщение терминальных комплексов и многомашинных вычислительных комплексов. Вычислительная сеть представляет собой программно-аппаратный комплекс, обладающий следующими основными характеристиками:</p>
<p>сеть может состоять из значительного числа взаимодействующих друг с другом ЭВМ, обеспечивающих сбор, хранение, обработку и передачу информации;</p>
<p>сеть ЭВМ предполагает возможность распределенной обработки информации;</p>
<p>расширяемость сети – возможность развития сети по протяженности (размещению), по расширению пропускной способности каналов связи, по количеству и производительности ЭВМ;</p>
<p>возможность применения симметричных интерфейсов обмена информацией между ЭВМ сети.</p>
<p>В общем случае, будем считать, что сеть состоит из двух разновидностей ЭВМ:</p>
<p><span><strong><span><em>абонентские или основные ЭВМ</em></span></strong></span>, которые обеспечивают информационно-вычислительные услуги сети;</p>
<p><span><strong><span><em>коммуникационные или вспомогательные ЭВМ</em></span></strong></span>, обеспечивают выполнение всех служебных функций по преобразованию и передаче информации.</p>
<p>В реальности, в современных сетях ЭВМ функции абонентских и коммуникационных ЭВМ совмещаются.</p>
<p>Для обобщения определения сети ЭВМ рассмотрим пример. Пусть дана сеть, состоящая из абонентских и коммуникационных ЭВМ. Абонентские машины могут осуществлять взаимодействие друг с другом через <span><strong><span><em>коммуникационную среду или коммуникационную сеть</em></span></strong></span>. Коммуникационная среда включает в себя <span><strong><span><em>каналы передачи данных</em></span></strong></span>, обеспечивающие взаимодействие между машинами и коммуникационными машинами. Конкретная топология сети зависит от назначения данной сети и определяется составом абонентских ЭВМ и топологией коммуникационной среды. Итак, абонентские машины могут осуществлять взаимодействие друг с другом через коммуникационную среду, в рамках которой используются каналы передачи данных и коммуникационные машины.</p>
<p>Существует классическое разделение сетей на три типа: сеть коммутации каналов, сеть коммутации сообщений и сеть коммутации пакетов. Рассмотрим основные свойства каждой из перечисленных разновидностей сетей.</p>
<p><span><strong><span><em>Сеть коммутации каналов</em></span></strong></span>. Сеть строится на основе использования коммутируемых каналов (см. Терминальные комплексы), т.е. для обеспечения сеанса связи двух абонентских ЭВМ на время всего сеанса выделяется коммутируемый канал – устанавливается прямое соединение между взаимодействующими абонентскими ЭВМ. Для этих целей осуществляется поиск пути в сети, по которому будет происходить соединение (при наличии нескольких путей выбирается какой-то один из них; на том, по какому именно критерию выбирается путь в случае альтернативы, мы останавливаться не будем). На время сеанса связи найденный путь считается монопольно выделенным для этих двух машин. Достоинства такого вида сети - простота реализации и эффективность работы в случае успешной коммутации, так как скорость взаимодействия между машинами равна скорости самого медленного компонента сети, участвующего в связи (это максимально возможная скорость). Главный недостаток заключается в том, что такая связь может блокировать другие соединения. Уйти от этой проблемы можно потребовав от коммутационной среды большой избыточности, т.е. организовать дополнительные (дублирующие) каналы.</p>
<p><span><strong><span><em>Сеть коммутации сообщений</em></span></strong></span><span><em>.</em></span> Если коммутация каналов - это коммутация на время всего сеанса связи, то коммутация сообщений - это связь, при которой весь сеанс разделяется на передачу сообщений (сообщение - некоторая, логически завершенная, порция данных). Взаимодействие ЭВМ в данных сетях осуществляется в терминах передачи сообщений. При этом для передачи сообщения не требуется установления прямого соединения между взаимодействующими абонентскими ЭВМ. Сообщение начинает передаваться по сети по мере освобождения каналов в коммуникационной среде (<span><strong><span><em>абонентская_ЭВМ<span class="math">\(\Leftrightarrow\)</span>коммуникационная_ЭВМ</em></span></strong></span>; <span><strong><span><em>коммуникационная_ЭВМ<span class="math">\(\Leftrightarrow\)</span>коммуникационная_ЭВМ</em></span></strong></span>). При этом на коммуникационные машины ложится значительная дополнительная нагрузка – коммуникационные ЭВМ должны обеспечивать буферизацию сообщений, так как прямого соединения не устанавливается, и возможна ситуация при которой канал, необходимый для продолжения передачи сообщений, занят. Достоинства - логическая и физическая простота, снижение монопольного фактора по сравнению с сетью коммутации каналов. Недостатки - снижение скорости работы в сети, отсутствие детерминированности в определении времени доставки информации, необходимость существенного увеличения мощности коммуникационных ЭВМ для обеспечения буферизации.</p>
<p><span><strong><span><em>Сеть коммутации пакетов</em></span></strong></span>. Сеанс разбивается на сообщения, сообщения, в свою очередь, разбиваются на порции данных одинакового объема - пакеты. По сети перемещаются не сообщения, а пакеты. Здесь действует принцип горячей картошки: основное действие коммутационной машины - как можно быстрее избавиться от пакета, определив кому его далее можно «перекинуть». Поскольку все пакеты одинакового объема, то не возникает проблем с буферизацией, потому что мы всегда можем рассчитать необходимую буферную способность коммутационных машин. Логически происходит достаточно быстрое соединение, потому что сеть коммутации пакетов практически не имеет ситуаций, когда какие-то каналы заблокированы на продолжительное время. За счет того, что происходит дробление сеанса на пакеты, имеется возможность оптимизации обработки ошибок при передаче данных. Если возникает ошибка в режиме коммутации каналов, то надо повторить весь сеанс, если в режиме коммутации сообщений, то надо повторить сообщение, при коммутации пакетов достаточно повторить передачу пакета, в котором обнаружена ошибка.</p>
<p>В реальных системах используются многоуровневые сети, которые в каких-то режимах работают в режиме коммутации каналов, в каких-то режимах работают в режиме коммутации сообщений и т.д. На сегодняшний день можно сказать, что сетей, однозначно принадлежащих к одному из вышеперечисленных типов, нет, а используется их комбинация.</p>
<p>Важным понятием, используемым при функционировании сетей ЭВМ является понятие протокола связи. В общем случае существует множество определений понятия <span><strong><span><em>протокол</em></span></strong></span>. Рассмотрим одно из простейших. <span><strong><span><em>Протокол</em></span></strong></span> - формальное описание сообщений и правил, по которым сетевые устройства (вычислительные системы) осуществляют обмен информацией.<span>****</span></p>
<p>Развитие многомашинных ассоциаций вообще, и сетей ЭВМ в частности, определило возникновение необходимости стандартизации взаимодействия, происходящего в сети. Развитие любого технического новшества всегда испытывает трудности в связи с отсутствием единого стандарта. Поэтому в конце 70-х начале 80-х годов ISO (International Standard Organization) предложила т.н. стандарт взаимодействия открытых систем ISO/OSI (Open System Interface), который должен был стандартизировать основные интерфейсы, позволяющие строить и развивать сети ЭВМ. Была предложена семиуровневая модель организации взаимодействия в сети.</p>
<p>Каждый уровень представляет собой условный, логически целостный набор действий и форматов данных, предназначенных для передачи данных взаимодействующих в сети вычислительных систем. В некоторых случаях предполагалась регламентация взаимодействия на уровне аппаратных компонентов вычислительных систем, в некоторых – программных.</p>
<p>В общем случае, каждый из уровней модели ISO/OSI есть абстракция, которой может быть поставлено в соответствие некоторое количество протоколов данного уровня. Т.е. каждый протокол, реализованный в соответствии с данной моделью принадлежит некоторому единственному уровню, но, вместе с тем, каждому уровню модели может соответствовать произвольной количество протоколов.</p>
<p>Модель OSI служит функциональным руководством при решении связных задач, и поэтому не специфицирует каких-либо коммуникационных стандартов, позволяющих решать эти задачи. Однако многие коммуникационные стандарты и протоколы вполне согласуются с положениями Модели OSI.</p>
<p>В модели OSI центральными являются три понятия:</p>
<p>сервис - определяет что делает уровень, но ничего не говорит как</p>
<p>интерфейс - определяет для вышележащего уровня доступа к сервису</p>
<p>протокол - определяет реализацию сервиса Наибольшее методологическое значение этой модели в четком выделении и разделении этих понятий.</p>
<p>В Модели OSI применяется стратегия “разделяй и властвуй”. Каждый уровень выполняет определенные функции. Уровни и их функции были выбраны на основе естественного разделения на подзадачи. Каждый уровень на одной ЭВМ связывается с аналогичным уровнем другой ЭВМ, однако данная связь реализуется в результате передачи сообщений через соответствующие нижележащие уровни. При этом межуровневая связь четко определяется. Уровень N использует услуги уровня N-1, обеспечивая услуги для уровня N+1.</p>
<p>В каждом запросе имеется так называемый заголовок, содержащий управляющую информацию. Любой уровень может добавлять заголовок к сообщению. На каждом уровне сообщение представляется в виде двух частей: заголовок и данные. Важно понять, что эти термины являются относительными. Когда уровень 4 добавляет свой заголовок и передает сообщение на уровень 3, третий уровень может добавить свой собственный заголовок к тому, что получено от уровня 4. При этом “данные” уровня 3 включают заголовок и данные уровня 4.</p>
<p>Добавление заголовков является необходимым, но при этом происходит добавление довольно большого количества информации даже к очень коротким сообщениям. Например, к моменту достижения 15-ти символьным почтовым сообщением среды передачи данных его длина может увеличиться в 5 раз. Исходное почтовое сообщение и его заголовки передаются по сети в устройство назначения. ЭВМ назначения отделяет и обрабатывает заголовки в обратном порядке. В конце концов пользователь получит исходное почтовое сообщение.</p>
<p>Информационные блоки именуются по-разному в зависимости от обсуждаемого уровня Модели. На физическом уровне мы говорим о битах. На звеньевом уровне логические группы информации называются кадрами. На сетевом уровне часто - дейтаграммой. На транспортном уровне те же базовые элементы данных называются сегментами. На прикладном уровне элементы данных обычно называются сообщениями. Другие термины (включая пакет) также применяются на различных уровнях.</p>
<p><span><strong>Физический уровень</strong></span> Физический уровень отвечает за передачу последовательности битов через канал связи. Основной проблемой является как гарантировать что если на одном конце послали 1, то на другом получили 1, а не 0. На этом уровне решают такие вопросы, как: каким напряжением надо представлять 1, а каким - 0; сколько микросекунд тратиться на передачу одного бита; следует ли поддерживать передачу данных в обоих направлениях одновременно; как устанавливается начальное соединение и как оно разрывается; каково количество контактов на сетевом разъеме, для чего используется каждый контакт. Здесь в основном вопросы механики, электрики.</p>
<p><span><strong>Уровень канала данных</strong></span> Основной задачей уровня канала данных - превратить несовершенную среду передачи в надежный канал, свободный от ошибок передачи. Эта задача решается разбиением данных отправителя на фреймы (обычно от нескольких сотен до нескольких тысяч байтов), передачей фреймов последовательно и обработкой фреймов уведомления, поступающих от получателя. Поскольку физический уровень не распознает структуры в передаваемых данных, то это целиком и полностью задача канала данных определить границы фрейма. Эта задача решается введением специальной последовательности битов, которая добавляется в начало и в конец фрейма и всегда интерпретируется как границы фрейма.</p>
<p>Помехи на линии могут разрушить фрейм. В этом случае он должен быть передан повторно. Он будет повторен также и в том случае если фрейм уведомление будет потерян. И это уже заботы уровня как бороться с дубликатами одного и того же фрейма, потерями или искажениями фреймов. Уровень канала данных может поддерживать сервис разных классов для сетевого уровня, разного качества и стоимости.</p>
<p>Другой проблемой, возникающей на уровне канала данных ( равно как и на других вышележащих уровнях) как управлять потоком передачи. Например, как предотвратить “захлебывание” получателя. Как сообщить передающему размер буфера, для приема передаваемых данных имеющийся у получателя в этот момент.</p>
<p>Если канал позволяет передавать данные в обоих направлениях одновременно, то возникает новая проблема: фреймы уведомления для потока от А к В используют тот же канал, что и трафик от В к А. Решение - использовать фреймы DU для передачи фреймов уведомлений.</p>
<p>В сетях с вещательным способом передачи возникает проблема управления доступом к общему каналу. За это отвечает специальный подуровень - подуровень доступа к среде (MAC - Media ACcess ).</p>
<p><span><strong>Сетевой уровень</strong></span> Сетевой уровень отвечает за функционирование подсети. Основной проблемой здесь является то, как маршрутизировать пакеты от отправителя к получателю. Маршруты могут быть определены заранее и прописаны в статической таблице, которая не изменяется. Они могут определяться в момент установления соединения. Наконец, они могут строиться динамически в зависимости от загрузки сети.</p>
<p>Если в подсети циркулирует слишком много пакетов, то они могут использовать одни и те же маршруты, что будет приводить к заторам. Эта проблема так же решается на сетевом уровне.</p>
<p>Поскольку за использование подсети, как правило, предполагается оплата, то на этом уровне также присутствуют функции учета: как много байт, символов послал или получил абонент сети. Если абоненты расположены в разных странах, где разные тарифы, то надо должным образом скорректировать цену услуги.</p>
<p>Если пакет адресован в другую сеть, то надо предпринять надлежащие меры: там может быть другой формат пакетов, отличный способ адресации, размер пакетов, протоколы и т.д. - это все проблемы неоднородных сетей решаются на сетевом уровне.</p>
<p>В сетях с вещательной передачей проблемы маршрутизации просты и этот уровень часто отсутствует.</p>
<p><span><strong>Транспортный уровень</strong></span> Основная функция транспортного уровня это: принять данные с уровня сессии, разделить, если надо, на более мелкие единицы, передать на сетевой уровень и позаботиться, чтобы все они дошли в целостности до адресата. Все это должно быть сделано эффективно и так, чтобы скрыть от вышележащего уровня непринципиальные изменения на нижних.</p>
<p>В нормальных условиях транспортный уровень должен создать специальное сетевое соединение для каждого транспортного соединения по запросу уровня сессии. Если транспортное соединение требует высокой пропускной способности, то транспортный уровень может создать несколько сетевых соединений, между которыми транспортный уровень буден распределять передаваемые данные. И наоборот, если требуется обеспечить недорогое транспортное соединение, то транспортный уровень может использовать одно и то же сетевое соединение для нескольких транспортных соединений. В любом случае, такое мультиплексирование должно быть незаметным на уровне сессии.</p>
<p>Сетевой уровень определяет, какой тип сервиса предоставить вышележащим уровням и пользователям сети. Наиболее часто используемым сервисом является канал точка-точка без ошибок, обеспечивающий доставку сообщений или байтов в той последовательности, в какой они были отправлены. Другой вид сервиса - доставка отдельных сообщений без гарантии сохранения их последовательности, рассылка одного сообщения многим в режиме вещания. Тип сервиса определяется при установлении транспортного соединения.</p>
<p>Транспортный уровень - это действительно уровень, обеспечивающий соединение точка-точка. Активности транспортного уровня на машине отправителя общаются с равнозначными активностями транспортного уровня на машине получателя. Этого нельзя сказать про активности на нижележащих уровнях. Они общаются с равнозначными активностями на соседних машинах! В этом одно из основных отличий уровней 1-3 от уровней 4-7. Последние обеспечивают соединение точка-точка.</p>
<p>Многие хост-машины - мультипрограммные, поэтому транспортный уровень для одной такой машины должен поддерживать несколько транспортных соединений. Для того, чтобы определить к какому соединению относиться тот или иной пакет, в его заголовке помещается необходимая информация.</p>
<p>Транспортный уровень также отвечает за установление и разрыв транспортного соединения в сети. Это предполагает наличие механизма именования, т.е. процесс на одной машине должен уметь указать с кем в сети ему надо обменяться информацией. Транспортный уровень также должен предотвращать “захлебывание” получателя в случае очень “быстро говорящего” отправителя. Механизм для этого называется управление потоком. Он есть и на других уровнях. Однако, управление потоком между хостами отличен от управление потоком между маршрутизаторами.</p>
<p><span><strong>Уровень сессии</strong></span> Уровень сессии позволяет пользователям на разных машинах (напомним, что пользователем может быть программа) устанавливать сессии. Сессия позволяет передавать данные, как это может делать транспортный уровень, но кроме этого этот уровень имеет более сложный сервис, полезный в некоторых приложениях. Например, вход в удаленную систему, передать файл между двумя приложениями.</p>
<p>Одним из видов услуг на этом уровне - управление диалогом. Потоки данных могут быть разрешены в обоих направлениях одновременно, либо поочередно в одном направлении. Сервис на уровне сессии будет управлять направлением передачи.</p>
<p>Другим видом сервиса - управление маркером. Для некоторых протоколов недопустимо выполнение одной и той же операции на обоих концах соединения одновременно. Для этого уровень сессии выделяет активной стороне маркер. Операцию может выполнять тот, кто владеет маркером.</p>
<p>Другой услугой уровня сессии является синхронизация. Пусть нам надо передать файл такой, что его пересылка займет два часа, между машинами, время наработки на отказ у которых один час. Ясно что “в лоб” такой файл средствами транспортного уровня не решить. Уровень сессии позволяет расставлять контрольные точки. В случае отказа одной из машин передача возобновиться с последней контрольной точки.</p>
<p><span><strong>Уровень представления</strong></span> Уровень представления предоставляет решения для часто возникающих проблем, чем облегчает участь пользователей. В основном это проблемы семантики и синтаксиса передаваемой информации. Этот уровень имеет дело с информацией, а не с потоком битов.</p>
<p>Типичным примером услуги на этом уровне - унифицированная кодировка данных. Дело в том, что на разных машинах используются разные способы кодировки ASCII, Unicode и т.п. для символов, разные способы представления целых - в прямом, обратном или дополнительном коде, нумерация бит в байте слева направо или наоборот и т.п. Пользователи как правило используют структуры данных, а не случайный набор байт. Для того, чтобы машины с разной кодировкой и представлением данных могли взаимодействовать, передаваемые структуры данных определяются специальным абстрактным способом, не зависящим от кодировки, используемой при передачи. Уровень представления работает со структурами данных в абстрактной форме, преобразует это представление во внутреннее для конкретной машины и из внутреннего, машинного представления в стандартное представление для передачи по сети.</p>
<p><span><strong>Уровень приложений</strong></span> Уровень приложений обеспечивает нужные часто используемые протоколы. Например, существуют сотни разных типов терминалов. Если мы захотим создать сетевой экранный редактор, то нам придется писать для каждого типа терминала свою версию.</p>
<p>Есть другой путь: определить сетевой виртуальный терминал и для него написать редактор. Для каждого типа терминала написать программу отображения этого терминала на сетевой виртуальный терминал. Все программное обеспечение для виртуального сетевого терминала расположено на уровне приложений.</p>
<p>Другой пример - передача файлов. Разные операционные системы используют разные механизмы именования, представления текстовых строк и т.д. Для передачи файлов между разными системами надо преодолевать все такие различия. Для этого есть приложение FTP, также расположенное на уровне приложений. На этом же уровне находятся: электронная почта, удаленная загрузка программ, удаленный просмотр информации и т.д.</p>
<p><span><strong>19. Организация сетевого взаимодействия. Семейство протоколов TCP/IP. Сравнение с эталонной моделью OSI ISO. Основные функции протоколов IP и TCP. Основные прикладные протоколы архитектуры TCP/IP. </strong></span> Протоколы семейства TCP/IP не следуют строго модели ISO/OSI. Они разбиты на <span><em>четыре</em></span> уровня.</p>
<p>Так же, как и в модели ISO/OSI, в TCP/IP данные проходят путь от уровня прикладных программ к уровню доступа к сети при передаче данных и в обратном порядке при их получении. Каждый уровень TCP/IP добавляет к исходной порции данных свою контрольную информацию для обеспечения правильной доставки. Эта контрольная информация называется заголовком, потому что помещается перед посылаемыми данными. При передаче каждый следующий уровень рассматривает порцию данных, пришедшую от предыдущего, как единое целое и помещает перед ней свой заголовок.</p>
<p>После того, как данные переданы по сети и получены уровнем доступа к сети, происходит обратный процесс. Каждый уровень вырезает свой заголовок из порции данных, а после этого передает оставшуюся часть следующему уровню. Таким образом, при прохождении данных снизу вверх (то есть при ее расшифровке), они рассматривается уже не как единое целое, а как совокупность заголовка и некоторой информации.</p>
<p>Протоколы каждого из уровней оперируют порциями данных, имеющих зависящие от конкретного уровня названия и структуру. Протоколы уровня доступа к сети используют при передаче и приеме данных пакеты, называемые <span><strong><span><em>фреймами.</em></span></strong></span> На межсетевом уровне используются <span><strong><span><em>дейтаграммы</em></span></strong></span>. Уровень транспортных протоколов семейства представляется двумя протоколами TCP и UDP. Протокол TCP оперирует <span><strong><span><em>сегментами</em></span></strong></span>. UDP – <span><strong><span><em>пакетами</em></span></strong></span>. На уровне прикладных программ, системы построенные на использовании протокола TCP используют <span><strong><span><em>поток</em></span></strong></span> данных, а системы использующие UDP - <span><strong><span><em>сообщения</em></span></strong></span>.</p>
<p><span><em>Эталонная модель TCP/IP</em></span> Прототипом для модели TCP/IP послужил прародитель всех компьютерных сетей - сеть ARPA. Эта сеть образовалась в результате НИР, проведенного по инициативе Министерства Обороны США. Позднее к этому проекту подключились сотни университетов и гос. учреждений Америки. С самого начала эта сеть задумывалась как объединение нескольких разных сетей. Одной из основных целей этого проекта было разработать унифицированные способы соединения сетей. С появлением спутниковых и радио цифровых каналов связи проблема становилась только актуальнее. Так появилась модель TCP/IP. Свое название она получила по именам двух основных протоколов: TCP - протокол управления передачей (Transmission Control Protocol), и IP - межсетевой протокол (Internet Protocol).</p>
<p>Другой целью проекта ARPA было создание протоколов, независящих от характеристик конкретных хост-машин, маршрутизаторов, шлюзов и т.п.</p>
<p>Кроме этого связь должна поддерживаться даже если отдельные сети компоненты будут выходить из строя во время соединения. Другими словами связь должна поддерживаться до тех пор, пока источник информации и получатель информации работоспособны. Архитектура сети не должна ограничивать приложения, начиная от простой передачи файлов до предачи речи и изображения в реальном времени.</p>
<div class="figure">
<img src="image11" alt="image" /><p class="caption">image</p>
</div>
<p><span><strong>Межсетевой уровень</strong></span> В силу вышеперечисленных требований выбор очевиден: сеть с коммутацией пакетов с межсетевым уровнем без соединений. Этот уровень называется межсетевым уровнем. Он является основой всей архитектуры. Его назначение обеспечить доставку пакетов, движущихся в сети независимо друг от друга, даже если получатель принадлежит другой сети. Причем пакеты могут поступать к получателю не в том порядке, в каком они были посланы. Упорядочить их в надлежащем порядке - задача вышележащего уровня.</p>
<p>Межсетевой уровень определяет межсетевой протокол IP и формат пакета. Ни протокол, ни формат пакета не являются официальными международными стандартами, в отличие от протоколов эталонной модели OSI.</p>
<p>Итак, назначение межсетевого уровня в TCP/IP доставить IP пакет по назначению. Это как раз то, за что отвечает сетевой уровень в ISO модели.</p>
<p><span><strong>Транспортный уровень</strong></span> Над межсетевым уровнем расположен транспортный уровень. Как и OSI модели его задача обеспечить связь точка-точка между двумя равнозначными активностями. В рамках TCP/IP модели было разработано два транспортных протокола. Первый TCP: надежный протокол с соединением. Он получает поток байт, фрагментирует его на отдельные сообщения и передает их на межсетевой уровень. На машине получателе равнозначная активность TCP протокола собирает эти сообщения в поток байтов. TCP протокол также обеспечивает управление потоком.</p>
<p>Второй протокол UDP (User Datagram Protocol). Это ненадежный протокол без соединения для тех приложений, которые используют свои механизмы фрагментации, управления потоком. Он часто используется для передачи коротких сообщений в клиент - серверных приложениях, а также там где скорость передачи важнее ее точности.</p>
<p><span><strong>Уровень приложений</strong></span> В TCP/IP модели нет уровней сессии и представления. Необходимость в них была не очевидна для ее создателей. На сегодня дело обстоит так, что разработчик сложного приложения берет на себя проблемы этих уровней.</p>
<p>Над транспортным протоколом располагается уровень приложений. Этот уровень включает виртуальный терминал - TELNET, передачу файлов - FTP, электронную почту - SMTP. Позднее к ним добавились: служба имен домена - DNS (Domain Name Service) отображающая логические имена хост-машин на их сетевые адреса, протокол для передачи новостей - NNTP, и протокол для работы с гипертекстовыми документами во всемирной паутине (WWW) - HTTP.</p>
<p>Под межсетевым уровнем в TCP/IP модели великая пустота. Модель ничего не говорит что происходит так, лишь что хост-машина должна быть связана с сетью через некоторый протокол. Никаких ограничений на этот протокол, равно как и рекомендаций нет.</p>
<p><span><em>Сравнение моделей МОС и TCP/IP</em></span> Обе модели имеют много общего. Обе имеют уровневую иерархию, поддерживают понятие стека протоколов. Назначение их уровней примерно одинаково. Все уровни от транспортного и ниже используют протоколы для поддержки взаимодействия типа точка-точка, не зависящего от организации сети. Все уровни выше транспортного ориентированы на приложения.</p>
<p>В модели OSI центральными являются три понятия:</p>
<p>сервис</p>
<p>интерфейс</p>
<p>протокол. Здесь можно провести аналогию с объектно-ориентированным программированием. У каждого объекта есть набор методов - сервис, которые определяют те операции, которые этот объект может выполнять. Иными словами, сервис - это семантика методов. Каждый метод имеет интерфейс - набор параметров, имя и т.п. Реализация методов скрыта в объекте - протокол; и не видима пользователю.</p>
<p>В TCP/IP модели нет столь же четкого выделения этих понятий. Там понятие протокола не столь четко “упрятано” и независимо от остальных частей модели. Этот факт есть следствие того как создавались эти модели. TCP/IP модель создавалась post factum, а OSI до того как появились протоколы. Поэтому понятие протокола там абсолютно не зависит от остальных частей модели. Например, изначально протоколы канального уровня в OSI создавались для соединений точка-точка. Позднее, когда появились средства типа вещания, на этот уровень были добавлены соответствующие протоколы. Никаких других изменений не последовало.</p>
<p>TCP/IP модель была создана когда TCP/IP стек уже существовал. Поэтому эта модель прекрасно описывала этот стек, но только этот стек и никакой другой.</p>
<p>Модели имеют разное число уровней. Обе имеют уровень приложений, транспортный уровень и сетевой уровень. Все остальные уровни разные.</p>
<p>OSI модель поддерживает на сетевом уровне как сервис с соединением, так и без соединения. На транспортном уровне этой модели поддерживается сервис только с соединением. В TCP/IP наоборот: сетевой уровень обеспечивает сервис без соединения, но транспортный - как с соединением, так и без.</p>
<p><span><em>Основные прикладные протоколы архитектуры TCP/IP </em></span> <span><strong>Межсетевой протокол - IP</strong></span> Протокол IP обеспечивает негарантированную доставку пакетов Транспортного уровня (называемых транспортными протокольными блоками данных, TPDU - Transport Protocol Data Units) в пределах интерсети в режиме без установления соединения (в дейтаграммном режиме). В протоколе IP предусмотрена операция фрагментации TPDU на более мелкие пакеты в том случае, когда это необходимо, и соответственно - обратная операция сборки, выполняемые обычно в маршрутизаторах или же в целевой ЭВМ. Каждый TPDU или фрагмент снабжается IP заголовком и передается как кадр низкоуровневыми протоколами.</p>
<p>Заголовок IP пакетов состоит из нескольких полей, их определение приведено ниже.</p>
<p>Версия (Version) - некоторый номер, отражающий определенный этап развития протокола. Оконечные системы и маршрутизаторы должны иметь согласованые номера версий, что гарантирует корректную обработку заголовка.</p>
<p>Длина IP заголовка (IP Header Length-IHL) - длина заголовка дейтаграммы в 32 битовых словах.</p>
<p>Тип услуги (Type of Service) С помощью данного 8-ми битового поля высокоуровневые протоколы имеют возможность указать протоколу IP (точнее, соответствующему IP-обьекту) каким образом должна быть обработана конкретная дейтаграмма.</p>
<p>Длина (length) - размер в байтах всего IP-пакета, включая область данных и заголовок пакета.</p>
<p>Идентификатор (Identification) - некоторое число, которое идентифицирует данную дейтаграмму. Совместно с адресом источника содержимое поля уникально идентифицирует дейтаграмму. Фрагменты, имеющие одинаковые адрес источника и идентификатор, обьединяются вместе с учетом значения параметра “индекс фрагмента”. Операция “сборки” выполняется в маршрутизаторах или в оконечных узлах.</p>
<p>Флаги (Flags) - Два младших бита трехбитового поля применяются в процессе фрагментации. Первый бит DF (Don’t Fragment) указывает, является ли дейтаграмма фрагментом, второй бит MF (More Fragment) указывает, является ли данный фрагмент последним.</p>
<p>Индекс (смещение) фрагмента (Fragment Offset) - индекс фрагмента в дейтаграмме.</p>
<p>Время жизни (TTL - Time-to-Live) - счетчик, ограничивающий время существования пакета в сети. Каждый раз при прохождении транзитного маршрутизатора содержимое TTL уменьшается на 1. Когда значение TTL принимает значение 0, пакет уничтожается. Этот механизм позволяет решать проблему бесконечно зацикленных пакетов.</p>
<p>Протокол (Protocol) - транспортный протокол (например, TCP), для которого предназначается данная дейтаграмма. Большинство транспортных протоколов зарегистрированы под определенными номерами в соответствующих центрах интерсети.</p>
<p>Контрольная сумма (КС) заголовка пакета (Header Checksum) - применяется для обеспечения контроля целостности IP- заголовка.</p>
<p>Адрес Источника и Адрес Назначения (Source and Destination Addresses) - с помощью этих полей, содержащих IP-адреса, идентифицируются источник и получатель пакета. IP-адрес специфицирует положение ЭВМ в терминах сеть-машина. IP-адрес - это 32-х битовое число, для удобства чтения представляемое в десятично-точечной нотации: четыре десятичных числа, разделенных точками (например, 192.32.45.1).</p>
<p>Опции. Поле опций имеет переменный размер, что позволяет связать с IP-дейтаграммой различные необязательные услуги.</p>
<p>В настоящее время используются три класса IP-сетей:</p>
<p>Класс А. IP-адрес в первом байте специфицирует сеть (первый бит характеризует класс сети). Следующие 3 байта (24 бита) задают адрес ЭВМ (host) в данной сети. Этот класс сетей применим в случае сетей с большим количеством хостов. Пример - ARPANET;</p>
<p>Класс В. IP - адрес в первых двух байтах специфицирует сеть (два первых бита характеризуют класс сети). Следующие 2 байта (16 бит) задают адрес ЭВМ. Данный класс сетей применяется в случае, когда отдельные сети в интерсети обьединяют среднее число ЭВМ (университеты, коммерческие организвции);</p>
<p>Класс С. IP - адрес в первых трех байтах специфицирует сеть (три первых бита характеризуют класс сети). Последний байт (8 бит) определяет ЭВМ в сети. Этот класс является полезным в случае, когда существует небольшое число ЭВМ, образующих логически связанное объединение. Для всех случаев начальные биты адреса сети идентифицируют класс сети. Данная схема адресации обеспечивает достаточную гибкость при описании любых типов сетей. При разработке интерсети назначаются (распределяются) только номера конкретных сетей. Причем номера сетей выбираются среди свободных на основе определенных характеристик (например, число машин, объединяемых сетью).</p>
<p><span><strong>Протокол управления передачей данных - TCP</strong></span> Протокол управления передачей данных TCP (Transmission Control Protocol) является основным транспортным пртоколом интерсети. TCP обеспечивает прием сообщений любого размера от высокоуровневых протоколов (ULP - Upper-Layer Protocols) и их полнодуплексную, подтверждаемую передачу, ориентированную на соединение с управлением потоком данных. Указанным образом передача сообщений выполняется между двумя обьектами, локализованными в двух различных станциях, подключенных к интерсети, и реализующих протокол TCP.</p>
<p>В соответствии с протоколом TCP данные передаются в виде неструктурированного байтового потока. Каждый байт идентифицируется последовательным номером. В целях экономии времени и оптимального использования полосы пропускания TCP оддерживает определенное число одновременных ULP-взаимодействий.</p>
<p>Формат пакета:</p>
<p>Порт источника (Source Port) - С помощью 16-ти битового поля Порт источника осуществляется идентификация ULP-источника.</p>
<p>Порт назначения (Destination Port)</p>
<p>Номер последовательности (Sequence Number) - тридцатидвухбитовое поле Номер последовательности обычно содержит номер первого байта данных текущего сообщения. В случае, когда сообщение разделяется на несколько частей, TCP использует Поле последовательности для корректной сборки сообщения и гарантированной его доставки высокоуровневому протоколу (ULP).</p>
<p>Подтверждаемый номер (Acknowlegment Number) - В случае, когда установлен бит ACK (определен ниже), в 32-х битовом поле Подтверждаемый номер содержится номер следующего байта данных, прием которого ожидается на стороне передатчика данного сообщения. Механизм подтверждения TCP разработан с целью наиболее эффективного использования полосы пропускания сети. Вместо того, чтобы подтверждать прием каждой порции данных, в TCP подтверждение задерживается до тех пор, пока не будет отработана целая серия актов передач, которые затем совокупно и подтверждаются.</p>
<p>Смещение данных (Data Offset) длина заголовка TCP в 32-х битовых словах. Длина заголовка является переменной, поскольку размер поля “Опции” (определено ниже) переменный.</p>
<p>Резервное (Reserved)</p>
<p>Флаги - используются для передачи управляющей информации.</p>
<p>Окно (Window) - определяет число байтов данных, начиная с номера, указанного в поле “Подтверждаемый номер”, которые хотел бы принять передатчик. Данное поле, совместно с полями Номер последовательности и Подтверждаемый номер, используется при реализации механизма управления потоком данных, основанного на понятии окна.</p>
<p>Контрольная сумма (Checksum)</p>
<p>Указатель срочных данных (Urgent pointer) - смещение относительно значения поля</p>
<p>Номер последовательности, указывающее положение срочных данных. Срочные данные (urgent data) представляют собой данные, которые с точки зрения ULP считаются очень важными. Зачастую, это управляющая информация, например, сигналы прерывания с клавиатуры. В рамках TCP не предпринимается никаких действий в отношении этих данных.</p>
<p>Опции (Options). Наиболее распространенная опция - это “максимальный размер сегмента”, она используется в ходе фазы установления соединения для того, чтобы определить наибольший по размеру сегмент данных, который TCP может принять (от протокола более высокого уровня - ULP).</p>
<p><span><strong>Протокол маршрутизации (Routing information protocol - RIP)</strong></span> Протокол RIP обеспечивает работоспособность протокола IP. С его помощью формируется согласованная информация о сетевых маршрутах и связности интерсетей, которая используется протокольными IP-объектами, резидированными в сетевых ЭВМ. В соответствии с протоколом RIP периодически выполняется передача текущей маршрутной информации. Маршрутная информация представляет собой список сетей назначения с указанием удаления, на котором от них находится источник данной информации. Удаление задается числом переходов (hops) по транзитным сетям до целевой сети (точнее числом промежуточных маршрутизаторов).</p>
<p><span><strong>Межсетевой протокол управления (ICMP - Internet Control Message Protocol)</strong></span> Протокол ICMP сопровождает и обеспечивает работоспособность протокола IP в части контроля за ошибками сети и ее диагностики. Это связано с тем, что протокол IP является дейтаграммным и не обеспечивает исполнение указанных функций. Протокол ICMP в этом смысле дополняет протокол IP, предоставляя протоколу TCP или другим высокоуровневым протоколам, т.е. ULP, диагностическую информацию.</p>
<p><span><strong>Протокол передачи дейтаграмм (UDP - User Datagram Protocol)</strong></span> Протокол UDP подобно протоколу TCP обеспечивает транспортный сервис. Однако в отличие от TCP в протоколе UDP отсутствует фаза установления транспортного соединения и не осуществляется подтверждение приема данных. Протокол UDP выполняет только транспортировку данных (дейтаграмм), полученных от высокоуровневых протоколов (ULP). Протокол UDP не обременен накладными расходами на установление и завершение транспортного соединения, на управление потоком данных и на обеспечение других функций TCP. В результате протокол UDP является более скоростным, чем протокол TCP. По этой же причине и, исходя из простоты реализации, протокол UDP применяется в качестве средства транспортировки данных многими ULP.</p>
<p><span><strong>Протокол передачи файлов (File Transfer Protocol - FTP)</strong></span> Протокол FTP является протоколом сетевых процессов и предоставляет пользователям возможность пересылать копии файлов между двумя ЭВМ интерсети. Протокол FTP обеспечивает также функции регистрации, проверки калалогов, исполнения команд, манипуляции с файлами и другие функции управления сеансом. Все эти функции разрабатывались таким образом, чтобы их исполнение не зависело от операционных систем ЭВМ и различий в аппаратных платформах.</p>
<p><span>****</span></p>
<p><span>****</span></p>
<p><span><strong>20. Средства межсетевого взаимодействия (мосты, маршрутизаторы, шлюзы). </strong></span></p>
<p><span><strong>Определение</strong></span>. Устройства, с помощью которых формируются интерсети, называются межсетевыми устройствами. <span><strong>Определение</strong></span>. Сегмент - это сеть ЭВМ, в которой отсутствуют межсетевые устройства.</p>
<p>Межсетевые устройства разделяются на группы, соответствующие уровням Модели OSI, функции которых они выполняют. Повторители работают на Физическом уровне. Мосты - на Канальном уровне. Маршрутизаторы - на Сетевом уровне. Шлюзы реализуют функции более высоких уровней Модели OSI.</p>
<p><span><strong>Повторители</strong></span> Цифровые и аналоговые сигналы, переносящие информацию, из-за неизбежного ослабления и затухания, а также из-за воздействия помех, приводящих к потере целостности данных, могут передаваться на довольно ограниченные расстояния. Задача заключается в увеличении этого расстояния. Простое усиление сигналов не является лучшим вариантом, поскольку наряду с усилением полезного сигнала усиливаются и шумы.</p>
<p>Повторитель выполняет эту функцию Физического уровня, репродуцируя сигналы и осуществляя их дальнейшую прозрачную передачу. Повторитель не вносит каких-либо изменений в передаваемые данные, не анализирует адресную информацию и структуру данных, относящихся к другим уровням. Только восстанавливает кондиционность принятых данных и их последующую передачу.</p>
<p>Повторитель выделяет и сохраняет принятые цифровые данные. Затем он реконструирует выходной сигнал и осуществляет его передачу. Новый сигнал, с большой точностью повторяющий исходный сигнал, ранее переданный источником данных, передается в следующий сегмент сети. Теоретически эта функция может повторяться необходимое число раз, однако на практике в реальных сетях число повторителей между передающей и принимающей станциями ограничено.</p>
<p><span><strong>Мосты</strong></span> Мосты используются для обьединения двух сетей на Канальном уровне. В качестве устройства Канального уровня мост имеет доступ к адресной информации Физического уровня. Другими словами, он может распознавать физические адреса источника и приемника информации, участвующих в передаче. В результате анализа физических адресов (и другой информации Канального уровня) мост или направляет данные во второй сегмент, или игнорирует их. В отличие от повторителя мост селектирует поток проходящих через него данных. Поскольку мосты фильтруют потоки данных на основе физических адресов станций, они обычно используются для выделения перегруженных участков сети в отдельные сегменты. Такое разбиение на сегменты предохраняет внутренний трафик каждого сегмента от влияния внешних трафиков других сегментов. Поскольку межсегментный трафик не слишком велик, данная стратегия довольно эффективно снижает трафик каждого сегмента.</p>
<p>Мост выполняет следующие действия:</p>
<p>Принимает все данные сегмента А.</p>
<p>Игнорирует все пакеты, адресованные узлам сегмента А.</p>
<p>Переповторяет все другие пакеты во внешние сегменты через соответствующие порты.</p>
<p>Выполняет те же действия для всех других подключенных сегментов.</p>
<p>Существует два вида мостов: прозрачные, называемые также обучающимися (learning bridges), и программируемые или мосты с маршрутизацией потока (source-routing). Программируемые мосты применяются в сетях фирмы IBM. Во всех других сетях используются прозрачные мосты.</p>
<p>Прозрачные мосты не требуют какого-либо предварительного программирования. После включения они “изучают” обстановку, отображая физические адреса устройств в номера линий, к которым эти устройства подключены. Используя найденные отображения, мосты формируют таблицы “физический адрес устройства/сетевой сегмент”. Эти таблицы используются мостом для выбора с помощью физического адреса назначения пакета соответствующего сегмента, в который следует направить пакет. Если найденный сегмент является сегментом, из которого был получен пакет, то мост игнорирует его. В противном случае пакет передается в соответствующую линию (сегмент).</p>
<p>В маршрутных сетях путь следования пакетов к определенной станции назначения указывается в заголовке передаваемых пакетов. Программируемые мосты поэтому проще, их задача сводится к передаче пакета в следующий узел, указанный в маршруте следования пакета. Этим узлом может быть другой мост или целевое устройство. В маршрутных сетях минимизируется стоимость моста, поскольку ему не нужно “обучаться”. С другой стороны, все другие устройства должны располагать маршрутной информацией, описывающей доступ ко всем возможным устройствам.</p>
<p>Устройства в маршрутных сетях определяют пути доступа к целям, выполняя рассылку специальных пакетов, которые называются “пакеты discovery”. Если устройство не получает ответа от устройства назначения на свой пакет discovery в пределах своего сетевого сегмента, то осуществляется передача пакета discovery во все другие сегменты, образующие интерсеть. В пакете discovery, проходящем сегменты интерсети, собирается маршрутная информация, описывающая путь до устройства назначения. Если существует множество путей, то по каждому пути пройдет свой пакет discovery. Устройство назначения отвечает на все принимаемые им пакеты discovery. В результате устройство-инициатор пакета discovery будет располагать маршрутной информацией, позволяющей сделать выбор лучшего пути.</p>
<p><span><strong>Маршрутизаторы</strong></span> Маршрутизаторы имеют доступ к управляющей информации трех нижних уровней Модели OSI (Физического, Канального и Сетевого). Информация третьего уровня обычно описывает, так называемые, логические сетевые адреса. Логические адреса, в отличие от физических адресов, обычно назначаются элементам сети соответствующими административными службами. Именно это отличает первые от вторых.</p>
<p>Физические адреса обычно назначаются производителями оборудования и жестко связаны с соответствующей аппаратурой, в отличие от логических адресов. Физические адреса, как правило, уникальны. С другой стороны, логические адреса могут использоваться сетевой администрацией в целях образования групп устройств, обладающих схожими свойствами (например, принадлежность одному отделению фирмы в рамках здания). Логические адреса по сравнению с физической обеспечивает большую гибкость, поскольку могут быть легко изменены и организованы в иерархические группы.</p>
<p>Маршрутизаторы передают информацию в интерсеть, используя логические адреса. Логически сеть разделяется на так называемые подсети. Подсети могут охватывать один и более сетевых сегментов.</p>
<p>Маршрутизаторы отличаются от мостов тем, что они используют для своей работы логические, а не физические адреса. Маршрутизаторы также применяют один (или более) специальных алгоритмов маршрутизации для вычисления лучшего пути в интерсети. Пути могут вычисляться динамически (в реальном масштабе времени) так, чтобы в большей степени соответствовать изменяющимся условиям в сети.</p>
<p>Алгоритмы динамической маршрутизации отличаются набором тех факторов (метриками), которые принимаются к рассмотрению при вычислении лучшего пути. Например, в одном алгоритме лучший путь определяется на основе минимизации числа переходов до устройства назначения (минимальная длина пути). В другом алгоритме в качестве метрики может использоваться время передачи. Алгоритмы маршрутизации через модемы рассматривают целое множество различных взвешенных факторов. В ряде случаев сетевые администраторы могут изменять веса элементов метрики (например, стоимость использования линии) для того, чтобы настраивать систему в соответствии с изменениями, носящими внешний характер.</p>
<p>Маршрутизаторы выполняют гораздо более интенсивную вычислительную работу, чем мосты. Поэтому их производительность, измеряемая обычно числом переданных пакетов в секунду, не слишком велика. Однако, с другой стороны, маршрутизаторы способны осуществлять довольно сложные вычисления для выбора пути в соответствии с алгоритмами маршрутизации. Существуют и другие их положительные свойства. В связи с этим решение покупать мост или маршрутизатор зависит от конкретных потребностей администрации сети и от существующего сетевого окружения.</p>
<p>Многие модемные маршрутизаторы в действительности обеспечивают и функции мостов (такие маршрутизаторы называют М - маршрутизаторами). Большинство алгоритмов маршрутизации являются специальными протоколами сетевого уровня. М-маршрутизаторы поддерживают наиболее известные протоколы (и их алгоритмы выбора пути), но, кроме этого, могут работать с пакетами, для которых такого рода поддержка не обеспечивается. Другими словами, М-маршрутизатор проверяет принятый пакет, пытаясь определить, поддерживается ли он каким-либо из имеющихся алгоритмов маршрутизации. Если пакет не поддерживается ни одним из алгоритмов маршрутизации, то он обрабатывается в соответствии с правилами моста с использованием содержащейся в нем информации Канального уровня.</p>
<p>Некоторые производители мостов пытаются достичь компромисса с другой стороны, реализуя в своих изделиях некоторые функции маршрутизаторов. Такие устройства обычно называют маршрутными мостами (routing bridges). Маршрутные мосты могут выполнять некоторые минимальные функции выбора пути и обеспечить достаточную безопасность маршрутов передачи данных. И все же из-за того, что эти устройства не имеют доступа к информации 3-его уровня Модели OSI, они не могут также успешно выполнять процедуры выбора пути, как это делают маршрутизаторы.</p>
<p><span><strong>Шлюзы</strong></span> Ни одно из устройств, которые мы рассмотрели выше, не решает проблемы объединения двух и более подсетей, которые имеют различные протоколы над Сетевым уровнем. Поскольку малые разнородные сети интегрируются в большие гетерогенные сети, для обеспечения их работоспособности необходимо решить проблему взаимодействия различных протокольных уровней. Устройство, для связи подсетей должно осуществлять трансляцию (преобразование) одних протокольных соглашений в другие. Преобразование протокольных соглашений является функцией шлюза.</p>
<p>Шлюзы изготавливаются или в виде отдельного конструктива, или в виде программно-аппаратных компонентов, которые встраиваются в существующие ЭВМ. Устройства, выполненные в виде отдельного конструктива, более дорогие, но в то же время обладают большей производительностью. Устройства со встроенными компонентами могут функционировать или в выделенном режиме (т.е. в режиме исключительного исполнения функций шлюза), или в совмещенном режиме (функции шлюза исполняются наряду с решением другого рода задач).</p>
<p><span>****</span></p>
<p><span>****</span></p>
<p><span><strong>21. Методы защиты от несанкционированного доступа в компьютерных сетях. </strong></span></p>
<p><span><em><img src="image12" alt="image" /><img src="image13" alt="image" />7.1. Сетевая безопасность </em></span>         Пока сети использовались лишь в университетах для научных исследований, а в крупных организациях для совместного использования устройств, например, принтеров, вопросы безопасности сетей просто не возникали. Теперь, кода сетью пользуется обыватель для управления банковским счетом, покупки, уплаты налогов – безопасность становится серьезной проблемой.         Проблема безопасности сети очень многогранна и охватывает широкий спектр вопросов. Большую их часть можно разделить на следующие группы: 4.    Секретность</p>
<p>несанкционированный доступ к информации (никто не может прочесть ваши письма);</p>
<p>несанкционированное изменение информации (никто без вашего разрешения не может изменить данные о вашем банковском счете); 2.    Идентификация подлинности пользователей</p>
<p>имея с кем-то дело через сеть, вы должны быть уверены, что это тот, за кого он себя выдает (если вы получили сообщение от налоговой инспекции уплатить определенную сумму денег, вы должны быть уверены, что это не шутка). 3.    Идентификация подлинности документа</p>
<p>как правило, это проблема подписи; 4.    Надежность управления</p>
<p>несанкционированное использование ресурсов (если вы получите счет за телефонные переговоры, которые вы не делали, вам это вряд ли понравится);         Разные люди по разным мотивам пытаются нарушить безопасность сети. На <span><strong>рис.7-1</strong></span> показан список категорий людей и возможная их мотивация.         <img src="image14" alt="image" />          Рис. 7-1.         Глядя на эти четыре группы проблем, не трудно видеть что и в обычных системах людям приходится иметь дело с таким проблемами. Распознание подделки документов, ограничение доступа к информации (уровни секретности), опознание людей (биометрические методы) и т.д.         Прежде чем приступить к рассмотрению методов решений перечисленных проблем рассмотрим где, в каком месте стека протоколов должно располагаться обеспечение безопасности, защита сети. Одного такого места нет. Каждый уровень способен сделать свой вклад. Например, на физическом уровне, чтобы контролировать доступ к физическому каналу, можно поместить кабель в опечатанную трубу, заполненную газом под давлением. Любая попытка просверлить трубу приведет к падению давления газа и срабатыванию датчика давления. Это, в свою очередь, включит сигнал тревоги.         На канальном уровне данные могут быть зашифрованы на одной машине и расшифрованы на другой. Об этом шифре верхние уровни могут ничего не знать. Однако, поскольку пакет дешифруется на каждом маршрутизаторе, то там он может стать предметом атаки. Тем не менее, этот метод, называемый шифрованием канала, часто применяется в сетях.         На сетевом уровне распространенным решением является застава (firewall). На транспортном уровне проблема секретности хорошо решается шифрованием всех сегментов транспортного соединения. Однако, до сих пор нет удовлетворительного решения для проблемы идентификации пользователя и идентификации документа.  </p>
<p><span><em>7.1.1. Обычное шифрование </em></span>         История шифрования богата и разнообразна. Традиционно ее развивали четыре группы людей – военные, дипломаты, любители вести дневники и любовники.         Стандартная схема шифрования такова (<span><strong>рис.7-2</strong></span>). Исходный текст, называемый также открытым текстом (plain text), обрабатывается специальной функцией, со специальным параметром, называемым ключом. Получается, так называемый, шифртекст (ciphertext) или криптограмма. Злоумышленник аккуратно копирует все шифртексты. Однако, в отличие от получателя у него нет ключа и он не может быстро прочесть сообщение. Иногда, злоумышленник может не только просто копировать сообщение, но позже отправлять свои, имитируя настоящего отправителя, чьи сообщения он копировал. Такого злоумышленника называю активным. Искусство создания шифра называют криптографией, а вскрытия – криптоанализом. Обе эти дисциплины образуют криптологию.         <img src="image15" alt="image" />          Рис. 7-2.         Основное правило шифрования - криптоаналитик знает основные приемы шифрования. Смена метода шифрования, его создание, тестирование, внедрение – всегда сопровождаются огромными затратами. Как часто надо менять шифр? Как определить, что шифр уже вскрыт?         Одно из решений – шифрование на основе ключей. Ключ – относительно короткая строка текста, которая используется при шифровании и расшифровке сообщений. Тогда, вся схема шифрования всем хорошо известна, менять ничего не надо, надо лишь время от времени изменять ключи.         Публикуя алгоритм шифрования, его автор получает задаром консультации многих исследователей в этой области. Если ни один из них в течении 5 лет не объявил, что он вскрыл алгоритм, то такой алгоритм можно считать вполне надежным.         Основа секретности – ключ. Его длина – один из основных вопросов разработки. Рассмотрим, как пример, комбинационный цифровой замок. Все знают, что его ключ – последовательность цифр. Для замка из двух цифр, надо перебрать 100 комбинаций, для 3 – 1000 и т.д. Длина ключа – объем работы, который надо проделать криптоаналитику, чтобы вскрыть шифр. Этот объем растет экспоненциально от длины ключа. Секретность достигается открытостью алгоритма и длиной ключа. <span class="math">\(\times\)</span>тобы защититься от чтения почты 64 разрядного ключа вполне достаточно. Для секретности государственных документов потребуется 128 или даже 256 разрядов.         С точки зрения криптоаналитика проблема дешифровки возникает в трех вариантах:</p>
<p>есть только шифрограмма;</p>
<p>есть шифрограмма и само сообщение;</p>
<p>есть фрагменты исходного сообщения и их шифрограммы.  </p>
<p><span><strong>Шифрование  замещением </strong></span>         Все приемы шифрования исторически делились на шифрование замещением и шифрование перестановкой.         Шифрование замещением состоит в том, что буква или группа букв замещается другой буквой или группой букв. Например, шифр Юлия Цезаря состоял в замене каждой буквы третьей следующей за ней в алфавите. а б в г д е ё ж з и й к л м н о п р с т у ф х ц ч ш щ ъ ы ь э ю я г д е ё ж з и й к л м н о п р с т у ф х ц ч ш щ ъ ы ь э ю я а б в           пришёл увидел победил         тулыио целжзо тсдзжло         Это, так называемое, моноалфавитное замещение, где ключом является 33 буквенная строка, соответствующая алфавиту. Здесь возможно 26! = 4х10<img src="image16" alt="image" /> ключей. Даже если на применение одного ключа компьютер будет тратить 1 <img src="image17" alt="image" />сек, то на расшифровку уйдет около 10<img src="image18" alt="image" /> лет. Однако если применить знания частотных характеристик языка, а именно частоту встречаемости отдельных букв, двух буквенных буквосочетаний, трехбуквенных сочетаний и т.д., то решение можно получить быстрее. Надо подсчитать  частоту букв в шифртексте и попытаться сопоставить наиболее часто встречающимся буквам в шифре сопоставить наиболее часто встречающиеся в языке. Затем найти устойчивые буквосочетания и т.д. Поэтому важное значение имеют дополнительные сведения: на каком языке написано исходное сообщение, его длина. <span class="math">\(\times\)</span>ем длиннее сообщение, тем представительнее выборка для анализа по встречаемости букв, буквосочетаний.  </p>
<p><span><strong>Шифрование перестановкой </strong></span>         Шифрование перестановкой состоит в изменении порядка букв без изменения самих букв. Один из таких методов – шифрование по столбцам. Выбираем ключ – последовательность неповторяющихся символов. Символы в этой последовательности нумеруются в соответствии с их местом в алфавите. Номер один получает буква, расположенная ближе всего к началу алфавита, номер два, следующая за ней и т.д. <span class="math">\(\times\)</span>ем ближе к началу алфавита символ, тем меньше его номер. Шифруемый текст размещается по строкам. Длина строки – длина ключа. Получаем массив. Столбцы нумеруются в соответствии с ключом. Каждому столбцу соответствует символ ключа, который имеет определенный номер. Упорядочим столбцы по возрастанию этих номеров. Все символы первого столбца выписываются первыми, затем символы второго и т.д. (<span><strong>рис.7-3</strong></span>). Этот метод можно усовершенствовать многими способами.         <img src="image19" alt="image" />          Рис. 7-3.         Для раскрытия этого типа шифров криптоаналитик, прежде всего, должен убедиться, что он имеет дело с шифрованием перестановкой. Для этого он должен подсчитать частоту встречаемости букв в шифре. Если она соответствует частоте букв в языке, то это означает, что он имеет дело именно с перестановкой. Намек на порядок столбцов могут дать устойчивые буквосочетания в языке.  </p>
<p><span><strong>Одноразовые подложки </strong></span>         Построить не раскрываемый шифр достаточно просто. Выберем случайным образом битовую строку. Текст представим как битовую строку. Выполним над этими строками операцию «исключающее или» EXCLUSIVE OR. Полученная новая строка и есть криптограмма.         Этот метод, называемый методом одноразовой подложки, имеет ряд недостатков. Трудно запомнить ключ. Его где-то надо записать или носить с собой. Это делает метод уязвимым. Объем передаваемых данных по этому методу ограничен длиной ключа. Метод так же очень чувствителен к потере символов при передаче. Правда, используя возможности компьютеров, этот метод вполне применим в некоторых случаях. Набор одноразовых подложек можно записать на CD и закамуфлировать под запись последних хитов.  </p>
<p><span><strong>Рассеивание и перемешивание </strong></span>         Основная угроза раскрытия текста при криптоанализе состоит в высокой избыточности естественного языка. Например, частотные характеристики встречаемости букв, устойчивые буквосочетания, приветствия и т.д. В связи с этим Шеннон предложил два основных криптографических метода: рассеивание и перемешивание.         Цель рассеивания состоит в перераспределении избыточности исходного языка на весь исходный текст. Этот прием может быть реализован как перестановкой по некоторому правилу, так и замещением. Последнее, например, достигается тем, что замещающая комбинация, зависит не только от замещаемой буквы, но от ей предшествующих букв.         Цель перемешивания состоит в том, чтобы сделать зависимость между ключом и шифртекстом настолько сложной, на сколько это возможно. Криптоаналитик на основе анализа шифртекста не должен получать сколь-нибудь полезной информации о ключе. Этот метод как раз реализуется с помощью перестановок.         Следует учитывать, что применение порознь ни рассеивания, ни перемешивания не дает желаемого результата. Их совместное использование делает криптосистему намного более стойкой.  </p>
<p><span><em><img src="image20" alt="image" />7.1.2. Два основных принципа шифрования </em></span>         Методов шифрования существует множество. Некоторые из них мы рассмотрим через несколько страниц. Однако, есть два важных, основополагающих принципа, которые должны соблюдаться в каждом методе. <span><em>Первый, все шифруемые сообщения должны иметь избыточность</em></span>, т.е. информацию, которая не нужна для понимания сообщения.         Эта избыточность позволит нам отличить нормально зашифрованное сообщение от подсунутого. Пример с уволенным сотрудником, который может наслать ложных сообщений, если он знает структуру служебных сообщений в компании. Избыточность позволит обнаружить подделку. Например, если в заказах на поставку после имени заказчика стоит 3 байтовое поле заказа (2 байта – код продукта и 1 байт количество), зашифрованное с помощью ключа, то злоумышленник, прихватив с работы справочник заказчиков, может устроить компании «веселую жизнь», сгенерировав от имени заказчиков из справочника заявки, где последние 3 байта – случайные числа. Если же заявку сделать не 3, а, например, 12 байтов, где первые 9 байтов – 0 и шифровать эту избыточную запись, то уже случайными числами здесь обойтись трудно, подделку легко распознать.         Однако такая избыточность имеет недостаток, эта избыточность может служить для криптоаналитика дополнительной информацией. Например, если в первом случае догадка о ключе и применение этого ключа к записи не дает криптоаналитику дополнительной информации о правильности ключа, то во втором случае, если в результате применение ключа-догадки, мы получим запись из 9 нулей с последующими данными, то это уже будет дополнительной информацией о правильности догадки.         <span><em>Второй – надо позаботиться о специальных мерах от активного злоумышленника, который может копировать, а потом пересылать модифицированные копии</em></span>. Например, временная метка позволит обнаружить сообщения, которые где-то были задержаны по непонятным причинам.  </p>
<p><span><em><img src="image21" alt="image" />7.1.3. Алгоритмы с секретными ключами </em></span>         Современная криптология использует те же идеи, что и раньше. Однако акценты расставлены иначе. Если раньше алгоритм был прост, а вся сложность заключалась в ключе, то теперь наоборот стараются алгоритм делать как можно изощреннее. Его стараются делать таким, чтобы, если криптоаналитик получил как угодно много зашифрованного текста, он не смог ничего сделать.         <img src="image22" alt="image" />          Рис. 7-4.         Перестановка и замещение реализуются простыми схемами, показанными на <span><strong>рис.7-4</strong></span>. P и S схемы могут объединять в сложные каскады. В этом случае выход становится очень сложной функцией входа. На этом рисунке Р схема выполняет перестановку над словом из 8 разрядов. Схема S действует несколько сложнее, выполняя операцию замещения. Она кодирует трех разрядное слово одной из 8 линий на выходе, устанавливая ее в 1. Затем схема Р переставляет эти 8 разрядов, после чего S схема выполняет замещение 8 на 3.  </p>
<p><span><strong>Алгоритм DES </strong></span>         В январе 1977 правительство США приняло стандарт в области шифрования (Data Encryption Standard), созданный на базе разработки фирмы IBM. На <span><strong>рис.7-5</strong></span> показана схема этого алгоритма.         <img src="image23" alt="image" />          Рис. 7-5.         Алгоритм состоит из 19 этапов. На первом этапе исходный текст разбивается на блоки по 64 бит каждый. Над каждым блоком выполняется перестановка. Последний этап является инверсией первой перестановки. Предпоследний этап состоит в обмене местами 32 самых левых битов с 32 самыми правыми битами.         Из исходного ключа с помощью специального преобразования строят 16 частных ключей для каждого промежуточного этапа алгоритма со второго по семнадцатый.         Все промежуточные этапы схожи. У них два входа по 32 бита. Правые 32 бита входа копируют на выход, как левые 32 бита. Над каждым битом из правых 32 битов выполняется преобразование, которое состоит из EXCLUSIVE OR с соответствующим левым битом и значением специальной функции над правым битом и частным ключом данного этапа. Вся сложность алгоритма заключена в этой функции. Функция состоит из четырех шагов. На первом строят 48 разрядный номер Е, как расширение 32 разрядного Ri-1 в соответствии с определенными правилами дублирования и перестановки. Над полученным номером и ключом данного шага выполняется операция EXCLUSIVE OR – это второй шаг. Результат разбивается на 8 групп по 6 бит в каждой. Каждая группа пропускается через свой S-box с четырьмя выходами каждый. На последнем шаге 8х4 бит пропускаются через P-box.         На каждой из 16 итераций используется свой ключ. До начала итераций к исходному ключу применяют 56 разрядную перестановку. Перед каждой итерацией ключ разбивают на две части по 28 разрядов каждая. Каждую часть циклически сдвигают влево на число разрядов равное номеру итерации. Кi  получают как 48 разрядную выборку из 56 разрядного ключа, полученного циклическими сдвигами с дополнительной перестановкой.         У предложенного алгоритма есть два недостатка. Предложенный алгоритм – это моноалфавитное замещение с 64 разрядным символом. Всегда, когда одни и те же 64 разряда исходного текста подают на вход, одни и теже 64 разряда получают на выходе. Это свойство может использовать криптоаналитик. Одни и те же поля исходного текста попадут в одни и те же места шифра. Этим можно воспользоваться. (Пример с премиями. Один сотрудник может приписать себе премию другого, если знает взаимное расположение соответствующих полей в исходной записи. Шифр ему знать ни к чему (<span><strong>рис.7-6</strong></span>).)         <img src="image24" alt="image" />          Рис. 7-6.         Второй недостаток – для начала шифрования надо иметь сразу весь 64-разрядный блок исходного текста. Это не совсем удобно, когда приходится иметь дело с интерактивными приложениями.         Первый недостаток устраняется модификацией алгоритма DES, в которой очередной блок исходного текста через операцию EXCLUSIVE OR смешивается с шифром предыдущего блока. Для первого блока используется специальный инициирующий блок, который передается вместе с шифром (<span><strong>рис.7-7</strong></span>).         <img src="image25" alt="image" />          Рис. 7-7.         Для устранения второго недостатка используется, так называемая, обратная связь по шифру (<span><strong>рис.7-8</strong></span>). На <span><strong>рисунке 7-8(а)</strong></span> показана ситуация, когда первые 10 байт текста уже были закодированы, а последние 8 из них сохранены в сдвиговом регистре. Когда поступает очередной байт, выбирается самый левый байт 64 разрядного  шифра и над ними выполняется EXCLUSIVE OR, результат посылается по линии, как шифр байта. Этот шифрованный байт посылается в сдвиговый регистр, а левый байт выталкивается из регистра. На стороне получателя над поступившим байтом выполняют ту же самую операцию. Этот алгоритм работает хорошо, пока оба сдвиговых 64 разрядных регистра одинаковы. Если при передаче шифрованного байта произойдет однобитовая ошибка, то пока испорченный байт не вытолкнут из регистра, расшифрованный текст пойдет с ошибкой. После этого ошибка исчезнет. Таким образом, одна битовая ошибка приведет к порче 64 бит текста. Этот алгоритм также предполагает наличие некоторого инициирующего блока, который обеспечивает работу алгоритма, пока все 8 правых байт не поступили.         <img src="image26" alt="image" />          Рис. 7-8.  </p>
<p><span><strong>Раскрытие DES </strong></span>         Появление DES с первых же дней сопровождалось казусами. Во-первых, он был построен на базе шифра IBM, называемого Люцифер. Разница была в том, что IBM использовала 128 разрядный ключ, а не 56, как DES. Всякое появление нового шифра инициирует дискуссию с правительственным ведомством – NSA в США, у нас – ФАПСИ.         IBM засекретило, как был разработан DES. В 1977 году Диффи и Хеллман из Стэнфорда опубликовали проект машины стоимостью в 20 миллионов долларов, которая вскрывала DES. Достаточно было подать на вход этой машине небольшой фрагмент зашифрованного текста и соответствующий фрагмент исходного текста, как эта машина в течении дня находила ключ. Существует много способов атаковать шифр. Все они основаны на распараллеливании перебора множества возможных ключей. Например, 140 000 человек вооруженных компьютерами, способными выполнять 250 000 шифрований с секунду, смогут перебрать пространство 7х1016 ключей за месяц. Основной вывод  - DES не является надежным шифром и его нельзя использовать для ответственных документов. Удвоение длины ключа до 112 бит кардинально меняет ситуацию. Теперь если использовать даже миллиард аппаратных дешифраторов, выполняющих по миллиарду оп.сек., потребуется 100 миллионов лет, чтобы перебрать пространство 2112=5х1033 112 разрядных ключей. Эти рассуждения могут натолкнуть на идею увеличения длины ключа, за счет двукратного применения DES с разными ключами К1 и К2.         Однако, в 1981 году Хеллман и Меркл обнаружили, что просто использование двух ключей не дает надежной схемы. Дело в том, что применение дешифрации к зашифрованному тексту дает шифр, который получается после применения первого ключа к исходному тексту. Эту мысль поясняют следующие формулы Ci = EK2 (EK1  (Pi ));  DK2  (Ci ) = EK1  (Pi )         В этом случае можно предложить следующую процедуру взлома:</p>
<p>вычислить все возможные применения функции Е к шифруемому тексту;</p>
<p>вычислить все возможные дешифрации зашифрованного текста однократным применением дешифрирующей функции;</p>
<p>отсортировать полученные таблицы и искать совпадающие строки;</p>
<p>полученная пара номеров строк – пара ключей;</p>
<p>проверить эту пару на совпадение шифрования; если неудачный результат, продолжить с шага 1.         Однако, тройное шифрование совершенно меняет дело. На <span><strong>рис.7-9</strong></span> показана модификация схемы шифрования с двумя ключами в три этапа - EDE схема. Ее никому еще не удалось вскрыть. Она была положена в основу международного стандарта. Здесь может возникнуть два вопроса. Первый: почему в этой схеме используются 2, а не 3 ключа. Второй: почему используется схема EDE, а не EEE? Ответ на первый вопрос состоит в том, что двух ключей более чем достаточно для большинства применений. Использование схемы EDE вместо ЕЕЕ связано с особенностями организации алгоритма DES.         <img src="image27" alt="image" />                    Рис. 7-9.         Надо отметить, что было предложено много других алгоритмов шифрования.         <img src="image28" alt="image" />          Рис. 7-10.  </p>
<p><span><em><img src="image29" alt="image" />7.1.4. Алгоритмы с открытыми ключами </em></span>         Идея алгоритмов шифрования с открытыми ключами была предложена в 1976 году Диффи и Хеллманом и состоит в следующем. Пусть у нас есть алгоритмы Е и D, которые удовлетворяют следующим требованиям:</p>
<p>D(E(P))=P;</p>
<p><span class="math">\(\times\)</span>резвычайно трудно получить D из E;</p>
<p>Е нельзя вскрыть через анализ исходных текстов. Алгоритм шифрования Е и его ключ публикуют или помещают так, чтобы каждый мог их получить, алгоритм D так же публикуют, чтобы подвергнуть его изучению, а вот ключи к последнему хранят в секрете. В этом случае взаимодействие двух абонентов А и В будет выглядеть следующим образом. Пусть А хочет послать В сообщение Р. А шифрует E<img src="image30" alt="image" />(P), зная алгоритм и открытый ключ для шифрования. В, получив E<img src="image31" alt="image" />(P), использует D<img src="image32" alt="image" /> с секретным ключом, т.е. вычисляет D<img src="image33" alt="image" />(E<img src="image34" alt="image" />(P))=P. Никто не прочтет P кроме A и B, т.к. по условию алгоритм E<img src="image35" alt="image" /> не раскрываем по условию, а D<img src="image36" alt="image" />, не выводим из E<img src="image37" alt="image" />.         Примером такого алгоритма является алгоритм RSA, предложенный Ривестом, Шамиром и Адлеманом в 1978 году. Общая схема этого алгоритма такова   1.    Выберем два больших (больше 10<img src="image38" alt="image" />) простых числа p и q. 2.    Вычислим n=pхq и z=(p-1)х(q-1); 3.    Выберем d относительно простое к z. 4.    Вычислим e такое, что eхd=1 mod z.         Разбиваем исходный текст на блоки Р так, чтобы каждый блок, как число не превосходил  n. Для этого выбираем наибольшее k такое, чтобы P=2<img src="image39" alt="image" /><span class="math">\(&lt;\)</span>n. Вычисляем С=P<img src="image40" alt="image" />(mod n), чтобы зашифровать сообщение P. Для расшифровки вычисляем P=C<img src="image41" alt="image" />(mod n). Для шифрования нам нужны (e,n) – это открытый ключ, для расшифровки (d,n) – это закрытый ключ. Можно доказать, что для любого Р в указанном выше диапазоне, функция шифрования и дешифрования взаимнообратны. Безопасность этого метода основана на высокой вычислительной сложности операции разложения на множители больших чисел. Так, например, разложение на множители 200 разрядного числа потребует 4 миллиардов лет.         <img src="image42" alt="image" />          Рис. 7-11.         На <span><strong>рис.7-11</strong></span> дан простой учебный пример применения RSA алгоритма для p=3, q= 11, n=33, z = 20, d=7 откуда e= 3. Один из основных недостатков алгоритма RSA – он работает медленно.  </p>
<p><span><em><img src="image43" alt="image" />7.1.5. Протоколы установления подлинности </em></span>         Протоколы установления подлинности (аутентификации) позволяют процессу убедиться, что он взаимодействует с тем, кто должен быть, а не с тем, кто лишь представляется таковым.         Очень часто путают проверку прав на выполнение тех или иных операций с аутентификацией. (В первом случае имеем авторизацию.) Аутентификация отвечает на вопрос: как убедиться, что вы взаимодействуете именно с определенным процессом. Если, например, к серверу процесс обратился с запросом удалить файл x.old и объявил себя процессом Вася, то сервер должен убедиться, что перед ним действительно Вася и что Вася имеет право делать то, что просит. Ключевым конечно является первый вопрос, ответ на второй вопрос – это дело просмотра таблицы.         Общая схема всех протоколов аутентификации такова: сторона А и сторона В начинают обмениваться сообщениями между собой или с Центром раздачи ключей (ЦРК). ЦРК всегда надежный партнер. Протокол аутентификации должен быть устроен так, что даже если злоумышленник перехватит сообщения между А и В, то ни А ни В не спутают друг друга с злоумышленником. Обмен данными между А и В будет происходить по алгоритму с закрытым ключом, а вот устанавливаться соединение по алгоритму с открытым ключом.  </p>
<p><span><strong>Аутентификация на основе закрытого разделяемого ключа. </strong></span>         Основная идея нашего первого протокола аутентификации, так называемого <span><em>протокола ответ по вызову</em></span>, состоит в том, что одна сторона посылает некоторое число (вызов), другая сторона, получив это число, преобразует его по определенному алгоритму и отправляет обратно. Посмотрев на результат преобразования и зная исходное число, инициатор может судить правильно ли сделано преобразование или нет. Алгоритм преобразования является общим секретом взаимодействующих сторон. Будем предполагать, что стороны А и В имеют общий секретный ключ КАВ. Этот секретный ключ взаимодействующие стороны как-то установили заранее, например, по телефону. Описанная выше процедура показана на <span><strong>рис.7-12</strong></span>.         <img src="image44" alt="image" />          Рис. 7-12. На этом рисунке: А,В - идентификаторы взаимодействующих сторон; R<img src="image45" alt="image" /> - вызов, где индекс указывает кто его послал; К<img src="image46" alt="image" /> - ключ, индекс которого указывает на его владельца.         <img src="image47" alt="image" />          Рис. 7-13.         <img src="image48" alt="image" />          Рис. 7-14.         На <span><strong>рис.7-13</strong></span> дана схема, где сокращено количество передач между сторонами, по сравнению с <span><strong>рис.7-12</strong></span>, а <span><strong>рис.7-14</strong></span> показывает «дыру» в схеме <span><strong>7-13</strong></span> и как злоумышленник может этой дырой воспользоваться. Это, так называемая, атака отражением. Есть несколько общих правил построения протоколов аутентификации (протокол проверки подлинности или просто подлинности): 1.    Инициатор должен доказать кто он есть прежде, чем вы пошлете ему  какую-то важную информацию. 2.    Инициатор и отвечающий должны использовать разные ключи. 3.    Инициатор и отвечающий должны использовать начальные вызовы из разных непересекающихся  множеств.         В схеме на <span><strong>рис.7-13</strong></span> все эти три правила нарушены.  </p>
<p><span><strong>Установка разделяемого ключа. </strong></span>         До сих пор мы предполагали, что А и В имеют общий секретный ключ. Рассмотрим теперь, как они могут его установить?  Например, они могут воспользоваться телефоном. Однако, как В убедиться, что ему звонит именно А, а не злоумышленник?  Можно договориться о личной встрече, куда принести паспорт и прочее, удостоверяющее личность. Однако есть протокол, который позволяет двум незнакомым людям установить общий ключ даже при условии, что за ними следит злоумышленник.         Это протокол обмена ключом Диффи-Хеллмана. Его схема показана на <span><strong>рис.7-15</strong></span>. Прежде всего А и В должны договориться об использовании двух больших простых чисел n и g, удовлетворяющих определенным условиям. Эти числа могут быть общеизвестны. Затем, А выбирает большое число, скажем x, и хранит его в секрете. То же самое делает В. Его число – y.         <img src="image49" alt="image" />          Рис. 7-15.         А шлет В сообщение (n,g,g<img src="image50" alt="image" />modn), В шлет в ответ (g<img src="image51" alt="image" />modn). Теперь А выполняет операцию (g<img src="image52" alt="image" />modn) <img src="image53" alt="image" />, В – (g<img src="image54" alt="image" />modn) <img src="image55" alt="image" />. Удивительно, но теперь оба имеют общий ключ - g<img src="image56" alt="image" />modn! Например, n=47, g=3, x=8, y=10, то А шлет В сообщение (47,3,28), поскольку 3<img src="image57" alt="image" />mod47 = 28. В шлет А (17). А вычисляет 17<img src="image58" alt="image" />mod47 = 4, B вычисляет 28<img src="image59" alt="image" />mod47 = 4. Ключ установлен – 4!         Злоумышленник следит за всем этим. Единственно, что мешает ему вычислить x и y – это то, что не известно алгоритма с приемлемой сложностью для вычисления логарифма от модуля для простых чисел. Однако, у этого алгоритма есть слабое место. <span><strong>Рис.7-16</strong></span> показывает его. Такой прием называется <span><strong><span><em>чужой в середине</em></span></strong></span>.         <img src="image60" alt="image" />          Рис. 7-16.  </p>
<p><span><strong>Проверка подлинности через центр раздачи ключей. </strong></span>         Договариваться с незнакомцем об общем секрете можно, но вряд ли это следует делать сразу (атака не спелого винограда). Кроме этого, общение с n людьми потребует хранения n ключей, что для общительных или популярных личностей может быть проблемой.         Другое решение можно получить, введя надежный центр распространения ключей (KDC). Его использование иллюстрирует <span><strong>рис.7-17</strong></span>.         <img src="image61" alt="image" />          Рис. 7-17.         Идея этого протокола состоит вот в чем. А выбирает ключ сессии K<img src="image62" alt="image" />. Используя свой ключ К<img src="image63" alt="image" />, шлет в центр KDC запрос на соединение с В. Центр KDC, знает В и его ключ К<img src="image64" alt="image" />. С помощью этого ключа KDC сообщает В ключ сессии K<img src="image65" alt="image" /> и кто хочет с ним с соединиться.         Однако, решение с центром KDC имеет изъян. Пусть злоумышленник как-то убедил А связаться с В и скопировал весь обмен сообщениями. Позже он может воспроизвести этот обмен за А и заставить В действовать так, как если бы с В говорил А! Этот способ атаки называется <span><strong><span><em>атака подменой</em></span></strong></span>.         Против такой атаки есть несколько решений. Одно из них – <span><strong><span><em>временные метки</em></span></strong></span>. Однако, это решение требует синхронизации часов. Поскольку в сети всегда есть расхождение в показаниях часов, то надо будет дать определенный допуск, интервал, в течении которого считать сообщений верным. Злоумышленник может использовать приемом атаки подменой в течении этого интервала.         Другое решение использование <span><strong><span><em>разовых меток</em></span></strong></span>. Однако. каждая из сторон должна помнить все разовые метки, использованные ранее. Это обременительно. Кроме этого, если список использованных разовых меток будет утерян по каким-либо причинам, то весь метод перестанет работать. Можно комбинировать решения разовых меток и временных меток.         Более тонкое решение установления подлинности дает многосторонний вызов-ответ протокол. Хорошо известным примером такого протокола является протокол Нидхема-Шредера, вариант которого показан на <span><strong>рис.7-18</strong></span>. В начале А сообщает KDC, что он хочет взаимодействовать с В. KDC сообщает ключ сессии, разовую метку R<img src="image66" alt="image" />, шифруя сообщение ключом А. Разовая метка защищает А от подмены. Теперь, имея ключ сессии, А начинает обмен сообщениями с В. R<img src="image67" alt="image" /> и R<img src="image68" alt="image" /> – разовые метки, защищающие А и В от подмен.         <img src="image69" alt="image" />          Рис. 7-18.         Хотя этот протокол в целом надежен, но все-таки есть небольшая опасность. Если злоумышленник раздобудет все-таки старый ключ сессии, то он сможет подменить сообщение 3 старым и убедить В, что это А! На <span><strong>рис.7-19</strong></span> приведена схема исправленного протокола, предложенного Отвей и Рисом. В этой модификации KDC следит, чтобы R было одним и тем же в обеих частях сообщения 2.         <img src="image70" alt="image" />          Рис. 7-19.  </p>
<p><span><strong>Установление подлинности протоколом Цербер. </strong></span>         Протокол установления подлинности Цербер используется многими практически действующими системами. Он представляет собой вариант протокола Нидхема-Шредера и был разработан в MIT для безопасного доступа в сеть (предотвратить несанкционированное использование ресурсов сети). В нем существенно использовано предположение, что все часы в сети хорошо синхронизованы.         Протокол Цербер предполагает использование кроме рабочей станции А еще трех серверов:</p>
<p>Сервер установления подлинности (СП) – проверяет пользователей на этапе login;</p>
<p>Сервер выдачи билета (СВБ) – идентификация билетов;</p>
<p>Сервер В – тот кто должен выполнить работу, необходимую А.         СП аналогичен KDC и знает секретный пароль для каждого пользователя. СВБ выдает билеты, которые подтверждают подлинность заказчиков работ.         На <span><strong>рис.7-20</strong></span> показана работа протокола Цербер. Сначала пользователь садится за рабочую станцию и шлет открыто свое имя серверу СП. СП отвечает ключом сессии и билетом – KS, K<img src="image71" alt="image" />(A,K<img src="image72" alt="image" />). Все это зашифровано секретным ключом А. Когда сообщение 2 пришло на рабочую станцию у А запрашивают пароль, чтобы по нему установить K<img src="image73" alt="image" />, для расшифровки сообщения 2. Пароль перезаписывается с временной меткой, чтобы предотвратить его захват злоумышленником. Выполнив login, пользователь может сообщить станции, что ему нужен сервер В. Рабочая станция обращается к СВБ за билетом для использования сервера В. Ключевым элементом этого запроса является K<img src="image74" alt="image" />(A,K<img src="image75" alt="image" />), зашифрованное секретным ключом СВБ. В ответ СВБ шлет ключ для работы А и В - К<img src="image76" alt="image" />.         <img src="image77" alt="image" />          Рис. 7-20.         Теперь А может обращаться непосредственно к В с этим ключом. Это взаимодействие сопровождается временными метками, чтобы защититься от подмены. Если позднее А понадобиться работать с сервером С, то А должен будет повторить сообщение 3, но указать там сервер С.         Поскольку сеть может быть очень большой, то нельзя требовать, чтобы все использовали один и тот же СП. Сеть разбивают на области, в каждой свои СП и СВБ, которые взаимодействую между собой.  </p>
<p><span><strong>Установление подлинности, используя шифрование с открытым ключом </strong></span>         Установить взаимную подлинность можно с помощью шифрования с открытым ключом. Пусть А и В уже знают открытые ключи друг друга. Они их используют, чтобы установить подлинность друг друга, а затем использовать шифрование с секретным ключом, которое на несколько порядков быстрее.         На <span><strong>рис.7-21</strong></span> показана схема установления подлинности с шифрованием открытыми ключами. Здесь R<img src="image78" alt="image" /> и R<img src="image79" alt="image" /> используются, чтобы убедить А и В в их подлинности. Единственным слабым местом этого протокола является предположение, что А и В уже знают открытые ключи друг друга. Обмен такими ключами уязвим для атаки типа чужой в середине.         <img src="image80" alt="image" />          Рис. 7-21.         Ривст и Шамир предложили протокол защищенный от атаки чужой в средине. Это, так называемый, протокол с внутренним замком. Его идея передавать сообщения в два этапа: сначала только четные биты, затем нечетные.  </p>
<p><span><em><img src="image81" alt="image" />7.1.6. Электронная подпись </em></span>         Подлинность многих юридических, финансовых и прочих документов устанавливается наличием подписи уполномоченного лица. Поскольку есть способы отличить фотокопии от подлинника, то  фотокопии не рассматриваются. Такая же проблема возникает для документов в электронной форме.         Проблема электронного аналога для ручной подписи весьма сложна. Нужна система, которая позволяла одной стороне посылать «подписанный» документ другой стороне так, чтобы 1.    Получатель мог удостовериться в подлинности отправителя; 2.    Отправитель позднее не мог отречься от документа; 3.    Получатель не мог подделать документ.         Первое требование важно, например, при взаимодействии с банком, чтобы убедиться, что тот кто проводит операцию, действительно есть владелец счета.         Второе требование – клиент запросил закупить тонну золота, цена которого на бирже неожиданно упала. У клиента может возникнуть соблазн отказаться от своей заявки.         Третье требование предотвращает ситуации типа: цена на золото в предыдущем примере неожиданно подскочила, тогда у банка может появиться соблазн изобразить, что клиент просил купить не тонну, а, скажем, килограмм золота.  </p>
<p><span><strong>Подпись с секретным ключом </strong></span>         Одно из решений проблемы электронной подписи – наделить полномочиями третью сторону, которую знают все, которая знает всех и которой верят все. Назовем ее Сердечный Друг (СД). На <span><strong>рис.7-22</strong></span> показана схема такого решения. <span class="math">\(\times\)</span>то произойдет если А позже откажется от посланного сообщения? В суде В предъявит сообщение А, К<img src="image82" alt="image" />(А,t,P), которое будет отправлено СД, как непререкаемому авторитету. СД расшифрует своим ключом эту запись и все увидят А,t,P.         <img src="image83" alt="image" />          Рис. 7-22.         Единственная слабость такого решения – злоумышленник может скопировать диалог между отправителем и получателем через СД и позже его повторить. Механизм временных меток позволяет уменьшить эту проблему. Кроме этого сохранение последних RA позволяет В заметить их повторное использование.  </p>
<p><span><strong>Подпись на основе открытого ключа. </strong></span>         Недостаток вышеописанного решения в том, что все должны доверять СД, который может читать сообщения. Кандидатами на его роль может быть правительство, банк, нотариус. Однако, далеко не все испытывают доверие к этом организациям.         <img src="image84" alt="image" />          Рис. 7-23.         На <span><strong>рис.7-23</strong></span> показа схема электронной подписи на основе открытых ключей. Здесь:</p>
<p>D<img src="image85" alt="image" />  - закрытый ключ,      E<img src="image86" alt="image" /> – открытый ключ;</p>
<p>Предполагаем E(D(P))=P дополнительно к D(E(P))=P (этим свойством обладает RSA);         Здесь есть два недостатка. Оба основаны на том, что схема работает до тех пор, пока сторона А либо умышленно не рассекретила свой ключ, либо не изменила его в одностороннем порядке. Судебный случай: В предъявляет P и D<img src="image87" alt="image" />(P), так как он не знает Е<img src="image88" alt="image" />, то он не мог подделать D<img src="image89" alt="image" />(P). При этом, должно быть E<img src="image90" alt="image" />( D<img src="image91" alt="image" />(P))=P, в чем суд легко может убедиться.         Если А обращается в суд, то есть Р и E<img src="image92" alt="image" />(P), что легко сопоставить с тем, что есть у В. Однако, если А заявит, что у него украли ключи, а сам тайно передаст их, либо сменит их, не сообщив об этом В. В последнем случае текущий E<img src="image93" alt="image" /> будет не применим к тому D<img src="image94" alt="image" />(P), который предъявит В. Здесь надо сопоставлять даты передачи сообщения и смены ключей.  </p>
<p><span><em><img src="image95" alt="image" />7.4.5. Конфиденциальность почты </em></span>         Пославший почту, естественно предполагает, что ее никто не читает кроме адресата. Однако, если об этом специально не позаботиться, то   гарантировать этого нельзя. Далее мы рассмотрим две широко распространенных безопасных почтовых системы PGP и PEM.  </p>
<p><span><strong>PGP – Pretty Good Privacy </strong></span>         PGP – вполне хорошая конфиденциальность – разработка одного человека Фила Зиммермана (Phil Zimmermann 1995). Это полный пакет безопасности, который включает средства конфиденциальности, установления подлинности, электронной подписи, сжатия и все это в удобной для использования форме. Благодаря этому, а также что это разработка далекого от государственных структур человека, качественная, работает как на платформе Unix, так и MS-DOS/Windows, Macintosh и распространяется бесплатно, этот она получила очень широкое распространение.         Зиммерман был обвинен в нарушении ряда законов США о шифровании. Это позволило ему выдвинуть лозунг «Если конфиденциальность – вне закона, то она доступна только тем, кто вне закона».         PGP использует алгоритмы шифрования RSA, IDEA и MD5. PGP поддерживает компрессию, передаваемых данных, их секретность, электронную подпись и средства управления доступа к ключам. Схема работы PGP показана на <span><strong>рис.7-49</strong></span>. На этом рисунке – DA , DB  личные (закрытые) ключи А и В соответственно, а EA , EB – их открытые ключи. Отметим, что секретный ключ для IDEA строиться автоматически по ходу работы PGP на стороне А и называется ключом сессии - KM,  который затем шифруется алгоритмом RSA с открытым ключом пользователя В. Так же следует  обратить внимание на то, что медленный алгоритм RSA используется для шифрования коротких фрагментов текста: 128 бит MD5 и 128 бит IDEA ключа.         <img src="image96" alt="image" />          Рис. 7-49.         PGP поддерживает три длины ключей:</p>
<p>Обычный – 314 бит (может быть раскрыт за счет больших затрат);</p>
<p>Коммерческий – 512 бит (может быть раскрыт специализированными организациями, названия которых, как правило, состоит из трех букв);</p>
<p>Военный – 1024 бита ( не может быть раскрыт пока ни кем на земле).         Формат PGP сообщения показан на <span><strong>рис.7-50</strong></span>.         <img src="image97" alt="image" />          Рис. 7-50.  </p>
<p><span><strong>PEM – почтовая служба с повышенной конфиденциальность </strong></span>         PEM – имеет статус Internet стандарта (RFC 1421, 1424). Сообщения, пересылаемые с помощью PEM, сначала преобразуют в каноническую форму. В этой форме соблюдены соглашения относительно спецсимволов типа табуляции, последовательных пробелов и т.п. Затем сообщение обрабатывается MD5 или MD2, шифруется с помощью DES (56 разрядный ключ) и передается с помощью base64 кодировки. Передаваемый ключ защищается либо с помощью RSA, либо с помощью DES по схеме EDE.         На <span><strong>рис.7-51</strong></span> дано сравнение этих двух почтовых систем.         <img src="image98" alt="image" />          Рис. 7-51.</p>
<p>Источник: Курс смелянского</p>
<p><span><strong>22. Унифицированный язык моделировании UML. Основные средства языка. </strong></span></p>
<p><span><em>Цели, история создания и назначение UML</em></span> Унифицированный язык моделирования UML (Unified Modeling Language) – это преемник того поколения методов объектно-ориентированного анализа и проектирования, которые появились в конце 80-х и начале 90-х годов. Создание UML фактически началось в конце metricconverterProductID1994 ?1994 г1994 г., когда Гради Буч и Джеймс Рамбо начали работу по объединению их методов под эгидой компании Rational Software. К концу metricconverterProductID1995 ?1995 г1995 г. они создали первую спецификацию объединенного метода, названного ими Unified Method, версия 0.8. Тогда же в metricconverterProductID1995 ?1995 г1995 г. к ним присоединился создатель метода OOSE (Object-Oriented Software Engineering) Ивар Якобсон. Таким образом, UML является прямым объединением и унификацией методов Буча, Рамбо и Якобсона, однако дополняет их новыми возможностями.</p>
<p>UML находится в процессе стандартизации, проводимом консорциумом OMG (Object Management Group), в настоящее время он принят в качестве стандартного языка моделирования и получил широкую поддержку. UML принят на вооружение практически всеми крупнейшими компаниями – производителями программного обеспечения (Microsoft, IBM, Hewlett-Packard, Oracle, Sybase и др.). Кроме того, практически все мировые производители CASE-средств, помимо Rational Software (Rational Rose), поддерживают UML в своих продуктах (Paradigm Plus (CA), System Architect (Popkin Software), Microsoft Visual Modeler и др.).</p>
<p><span><em>Состав диаграмм UML и их назначение</em></span> UML представляют его как язык для определения, представления, проектирования и документирования программных систем, организационно-экономических систем, технических систем и других систем различной природы. UML содержит стандартный набор диаграмм и нотаций самых разнообразных видов. Стандарт UML версии 1.1, принятый OMG в metricconverterProductID1997 ?1997 г1997 г., предлагает следующий набор диаграмм для моделирования:</p>
<p><span><strong>Диаграммы вариантов использования</strong></span> Вариант использования представляет собой последовательность действий (транзакций), выполняемых системой в ответ на событие, инициируемое некоторым внешним объектом (действующим лицом). Вариант использования описывает типичное взаимодействие между пользователем и системой. В простейшем случае вариант использования определяется в процессе обсуждения с пользователем тех функций, которые он хотел бы реализовать.</p>
<p>Действующее лицо (actor) – это роль, которую пользователь играет по отношению к системе. Действующие лица представляют собой роли, а не конкретных людей или наименования работ. Несмотря на то, что на диаграммах вариантов использования они изображаются в виде стилизованных человеческих фигурок, действующее лицо может также быть внешней системой, которой необходима некоторая информация от данной системы. Показывать на диаграмме действующих лиц следует только в том случае, когда им действительно необходимы некоторые варианты использования.</p>
<p>Действующие лица делятся на три основных типа – пользователи системы, другие системы, взаимодействующие с данной, и время. Время становится действующим лицом, если от него зависит запуск каких-либо событий в системе.</p>
<p><span><strong>Диаграммы взаимодействия</strong></span> Диаграммы взаимодействия (interaction diagrams) описывают поведение взаимодействующих групп объектов.</p>
<p>Сообщение (message) – это средство, с помощью которого объект-отправитель запрашивает у объекта получателя выполнение одной из его операций.</p>
<p>Информационное (informative) сообщение – это сообщение, снабжающее объект-получатель некоторой информацией для обновления его состояния.</p>
<p>Сообщение-запрос (interrogative) – это сообщение, запрашивающее выдачу некоторой информации об объекте-получателе.</p>
<p>Императивное (imperative) сообщение – это сообщение, запрашивающее у объекта-получателя выполнение некоторых действий.</p>
<p>Существует два вида диаграмм взаимодействия: диаграммы последовательности (sequence diagrams) и кооперативные диаграммы (collaboration diagrams).</p>
<p>На диаграмме последовательности объект изображается в виде прямоугольника, от которого вниз проведена пунктирная вертикальная линия. Эта линия называется линией жизни (lifeline) объекта. Она представляет собой фрагмент жизненного цикла объекта в процессе взаимодействия.</p>
<p>Подобно диаграммам последовательности, кооперативные диаграммы (collaborations) отображают поток событий через конкретный сценарий варианта использования. Диаграммы последовательности упорядочены по времени, а кооперативные диаграммы больше внимания заостряют на связях между объектами.</p>
<p><span><strong>Диаграммы классов</strong></span> Диаграмма классов определяет типы классов системы и различного рода статические связи, которые существуют между ними. На диаграммах классов изображаются также атрибуты классов, операции классов и ограничения, которые накладываются на связи между классами.</p>
<p>Стереотипы – это механизм, позволяющий разделять классы на категории. В языке UML определены три основных стереотипа классов: Boundary (граница), Entity (сущность) и Control (управление).</p>
<p><span><strong>Диаграммы состояний</strong></span> Диаграммы состояний определяют все возможные состояния, в которых может находиться конкретный объект, а также процесс смены состояний объекта в результате наступления некоторых событий.</p>
<p><span><strong>Диаграммы деятельности</strong></span> В отличие от большинства других средств UML, диаграммы деятельностей не имеют явно выраженного источника в предыдущих работах Буча, Рамбо и Якобсона, и заимствуют идеи из нескольких различных методов, в частности, метода моделирования состояний SDL и сетей Петри. Эти диаграммы особенно полезны в описании поведения, включающего большое количество параллельных процессов.</p>
<p>Самым большим достоинством диаграмм деятельностей является поддержка параллелизма. Благодаря этому они являются мощным средством моделирования потоков работ и, по существу, параллельного программирования. Самый большой их недостаток заключается в том, что связи между действиями и объектами просматриваются не слишком четко.</p>
<p><span><strong>Диаграммы компонентов</strong></span> Диаграммы компонентов показывают, как выглядит модель на физическом уровне. На них изображены компоненты программного обеспечения и связи между ними. При этом на такой диаграмме выделяют два типа компонентов: исполняемые компоненты и библиотеки кода.</p>
<p>Диаграммы компонентов применяются теми участниками проекта, кто отвечает за компиляцию системы. Из нее видно, в каком порядке надо компилировать компоненты, а также какие исполняемые компоненты будут созданы системой. На такой диаграмме показано соответствие классов реализованным компонентам. Она нужна там, где начинается генерация кода.</p>
<p><span><strong>Диаграммы размещения</strong></span> Диаграмма размещения (deployment diagram) отражает физические взаимосвязи между программными и аппаратными компонентами системы. Она является хорошим средством для того, чтобы показать маршруты перемещения объектов и компонентов в распределенной системе. Каждый узел на диаграмме размещения представляет собой некоторый тип вычислительного устройства – в большинстве случаев, часть аппаратуры. Эта аппаратура может быть простым устройством или датчиком, а может быть и мэйнфреймом.</p>
<p>Диаграмма размещения используется менеджером проекта, пользователями, архитектором системы и эксплуатационным персоналом, чтобы понять физическое размещение системы и расположение её отдельных подсистем.</p>
<p><span>****</span></p>
<p><span>****</span></p>
<p><span><strong>23. Основы программной инженерии. Каскадная и итерационная модели жизненного цикла программного обеспечения. </strong></span></p>
<p>Стандарт ISO/IEC 12207 не предлагает конкретную модель ЖЦ и методы разработки ПО (под моделью ЖЦ понимается структура, определяющая последовательность выполнения и взаимосвязи процессов, действий и задач, выполняемых на протяжении ЖЦ. Модель ЖЦ зависит от специфики ИС и специфики условий, в которых последняя создается и функционирует). Его регламенты являются общими для любых моделей ЖЦ, методологий и технологий разработки. Стандарт ISO/IEC 12207 описывает структуру процессов ЖЦ ПО, но не конкретизирует в деталях, как реализовать или выполнить действия и задачи, включенные в эти процессы. К настоящему времени наибольшее распространение получили следующие две основные модели ЖЦ:</p>
<p>каскадная модель (70-metricconverterProductID85 ?85 г85 г.г.);</p>
<p>спиральная модель (86-metricconverterProductID90 ?90 г90 г.г.). В изначально существовавших однородных ИС каждое приложение представляло собой единое целое. Для разработки такого типа приложений применялся каскадный способ. Его основной характеристикой является разбиение всей разработки на этапы, причем переход с одного этапа на следующий происходит только после того, как будет полностью завершена работа на текущем (рис. 1.1). Каждый этап завершается выпуском полного комплекта документации, достаточной для того, чтобы разработка могла быть продолжена другой командой разработчиков. Положительные стороны применения каскадного подхода заключаются в следующем [2]:</p>
<p>на каждом этапе формируется законченный набор проектной документации, отвечающий критериям полноты и согласованности;</p>
<p>выполняемые в логичной последовательности этапы работ позволяют планировать сроки завершения всех работ и соответствующие затраты. <img src="image99" alt="image" /> <span><em>Рис. 1.1. Каскадная схема разработки ПО</em></span> Каскадный подход хорошо зарекомендовал себя при построении ИС, для которых в самом начале разработки можно достаточно точно и полно сформулировать все требования, с тем чтобы предоставить разработчикам свободу реализовать их как можно лучше с технической точки зрения. В эту категорию попадают сложные расчетные системы, системы реального времени и другие подобные задачи. Однако, в процессе использования этого подхода обнаружился ряд его недостатков, вызванных прежде всего тем, что реальный процесс создания ПО никогда полностью не укладывался в такую жесткую схему. В процессе создания ПО постоянно возникала потребность в возврате к предыдущим этапам и уточнении или пересмотре ранее принятых решений. В результате реальный процесс создания ПО принимал следующий вид (рис. 1.2): <img src="image100" alt="image" /> <span><em>Рис. 1.2. Реальный процесс разработки ПО по каскадной схеме</em></span> Основным недостатком каскадного подхода является существенное запаздывание с получением результатов. Согласование результатов с пользователями производится только в точках, планируемых после завершения каждого этапа работ, требования к ИС “заморожены” в виде технического задания на все время ее создания. Таким образом, пользователи могут внести свои замечания только после того, как работа над системой будет полностью завершена. В случае неточного изложения требований или их изменения в течение длительного периода создания ПО, пользователи получают систему, не удовлетворяющую их потребностям. Модели (как функциональные, так и информационные) автоматизируемого объекта могут устареть одновременно с их утверждением. Для преодоления перечисленных проблем была предложена спиральная модель ЖЦ [10] (рис. 1.3), делающая упор на начальные этапы ЖЦ: анализ и проектирование. На этих этапах реализуемость технических решений проверяется путем создания прототипов. Каждый виток спирали соответствует созданию фрагмента или версии ПО, на нем уточняются цели и характеристики проекта, определяется его качество и планируются работы следующего витка спирали. Таким образом углубляются и последовательно конкретизируются детали проекта и в результате выбирается обоснованный вариант, который доводится до реализации. Разработка итерациями отражает объективно существующий спиральный цикл создания системы. Неполное завершение работ на каждом этапе позволяет переходить на следующий этап, не дожидаясь полного завершения работы на текущем. При итеративном способе разработки недостающую работу можно будет выполнить на следующей итерации. Главная же задача - как можно быстрее показать пользователям системы работоспособный продукт, тем самым активизируя процесс уточнения и дополнения требований. Основная проблема спирального цикла - определение момента перехода на следующий этап. Для ее решения необходимо ввести временные ограничения на каждый из этапов жизненного цикла. Переход осуществляется в соответствии с планом, даже если не вся запланированная работа закончена. План составляется на основе статистических данных, полученных в предыдущих проектах, и личного опыта разработчиков. <img src="image101" alt="image" /> <span><em>Рис 1.3. Спиральная модель ЖЦ</em></span></p>
<p><span>****</span></p>
<p><span><strong>24. Глобальные и локальные модели освещения в компьютерной графике. Модель Фонга.</strong></span></p>
<p>Реалистичное освещение сцены смоделировать сложно, каждый луч света в реальности многократно отражается и преломляется, число этих отражений не ограничено. А в 3D рендеринге число отражений сильно зависит от расчетных возможностей, любой расчет сцены является упрощенной физической моделью, а получаемое в итоге изображение лишь приближено к реалистичности. Алгоритмы освещения можно разделить на две модели: прямое или локальное освещение и глобальное освещение (direct или local illumination и global illumination). Локальная модель освещения использует расчет прямой освещенности, свет от источников света до первого пересечения света с непрозрачной поверхностью, взаимодействие объектов между собой не учитывается. Хотя такая модель пытается компенсировать это добавлением фонового или равномерного (ambient) освещения, но это самая простая аппроксимация, сильно упрощенное освещение от всех непрямых лучей источников света, которое задает цвет и интенсивность освещения объектов в отсутствии прямых источников света. Той же трассировкой лучей рассчитывается освещенность поверхностей только прямыми лучами от источников света и любая поверхность, для того, чтобы быть видимой, должна быть напрямую освещена источником света. Этого недостаточно для достижения фотореалистичных результатов, кроме прямого освещения нужно учитывать и вторичное освещение отраженными от других поверхностей лучами. В реальном мире лучи света отражаются от поверхностей несколько раз, пока не затухнут совсем. Солнечный свет, проходящий через окно, освещает всю комнату целиком, хотя лучи не могут напрямую достигать всех поверхностей. <span class="math">\(\times\)</span>ем ярче источник света, тем большее количество раз он будет отражаться. Цвет отражающей поверхности также влияет на цвет отраженного света, например, красная стена вызовет красное пятно на соседнем объекте белого цвета. Вот наглядная разница, расчет без учета вторичного освещения и с учетом такового: <img src="image102" alt="image" /> В глобальной модели освещения, global illumination, рассчитывается освещение с учетом влияния объектов друг на друга, учитываются многократные отражения и преломления лучей света от поверхностей объектов, каустика (caustics) и подповерхностное рассеивание (subsurface scattering). Эта модель позволяет получить более реалистичную картинку, но усложняет процесс, требуя заметно больше ресурсов. Существует несколько алгоритмов global illumination, мы вкратце рассмотрим radiosity (расчет непрямого освещения) и photon mapping (расчет глобального освещения на основе карт фотонов, предрассчитанных при помощи трассировки). Есть и упрощенные методы по симуляции непрямого освещения, такие, как изменение общей яркости сцены в зависимости от количества и яркости источников света в ней или использование большого количества точечных источников света, расставленных по сцене для имитации отраженного света, но все же это далеко от настоящего алгоритма GI. Алгоритм radiosity это процесс расчета вторичных отражений лучей света от одних поверхностей к другим, а также, от окружающей среды к объектам. Лучи от источников света трассируются до тех пор, пока сила их не снизится ниже определенного уровня или лучи достигнут определенного числа отражений. Это распространенная техника GI, вычисления обычно выполняются перед визуализацией, а результаты расчета можно использовать для рендеринга в реальном времени. Основные идеи radiosity основаны на физике теплового переноса. Поверхности объектов разбиваются на небольшие участки, называемые патчами, и принимается, что отраженный свет рассеивается равномерно во все стороны. Вместо расчета каждого луча для источников света, используется техника усреднения, разделяющая источники света на патчи, основываясь на уровнях энергии, которые они выдают. Эта энергия распределяется между патчами поверхностей пропорционально. Еще один метод расчета глобальной освещенности предложен Henrik Wann Jensen, это метод фотонных карт photon mapping. Использование фотонных карт - это другой алгоритм расчета глобального освещения, основанный на трассировке лучей и используемый для имитации взаимодействия лучей света с объектами сцены. Алгоритмом рассчитываются вторичные отражения лучей, преломление света через прозрачные поверхности, рассеянные отражения. Этот метод состоит в расчете освещенности точек поверхности в два прохода. В первом выполняется прямая трассировка лучей света с вторичными отражениями, это предварительный процесс, выполняемый перед основным рендерингом. В этом методе рассчитывается энергия фотонов, идущих от источника света к объектам сцены. Когда фотоны достигают поверхности, точка пересечения, направление и энергия фотона сохраняются в кэш, называемый фотонной картой. Фотонные карты могут сохраняться на диске для последующего использования, чтобы не просчитывать их каждый кадр. Отражения фотонов просчитываются до тех пор, пока работа не останавливается после определенного количества отражений или при достижении определенной энергии. Во втором проходе рендеринга выполняется расчет освещения пикселей сцены прямыми лучами, с учетом данных, сохраненных в фотонных картах, энергия фотонов добавляется к энергии прямого освещения. Расчеты global illumination, использующие большое количество вторичных отражений, занимают гораздо больше времени, чем расчеты прямого освещения. Существуют техники для аппаратного расчета радиосити в реальном времени, которые используют возможности программируемых видеочипов последних поколений, но пока что сцены, для которых рассчитывается глобальное освещение в реальном времени, должны быть достаточно простыми и в алгоритмах делается множество упрощений. Но вот что давно используют - так это статическое предпросчитанное глобальное освещение, что приемлемо для сцен без изменения положения источников света и больших объектов, сильно влияющих на освещение. Ведь расчет глобального освещения не зависит от положения наблюдателя и если в сцене не изменяется положение таких объектов сцены и параметров источников освещения, то можно использовать заранее просчитанные значения освещенности. Это используют во многих играх, сохраняя данные GI расчетов в виде лайтмапов (lightmaps). Существуют и приемлемые алгоритмы для имитации глобального освещения в динамике. Например, есть такой простой метод для использования в приложениях реального времени, для расчета непрямого освещения объекта в сцене: упрощенный рендеринг всех объектов с пониженной детализацией (за исключением того, для которого считают освещение), в кубическую карту низкого разрешения (ее также можно использовать для отображения динамических отражений на поверхности объекта), затем фильтрация этой текстуры (несколько проходов blur фильтра), и применение для освещения этого объекта данных из рассчитанной текстуры в качестве дополнения к прямому освещению. В случаях, когда динамический расчет слишком тяжел, можно обойтись статическими radiosity картами. Пример из игры MotoGP 2, на котором хорошо видно благотворное влияние даже такой простой имитации GI: <img src="image103" alt="image" /> Напоследок еще один пример direct illumination против global illumination рендеринга, чтобы развеять оставшиеся сомнения о полезности вторичного освещения (источник света один, ambient освещение отсутствует): <img src="image104" alt="image" />   <img src="image105" alt="image" /></p>
<p><span><em>Формула освещенности Фонга</em></span> Рассмотрим, как модель Фонга вписывается в общий случай. Вспомним, формула Фонга определяет количество света, отраженного в сторону наблюдателя следующим образом: <img src="image106" alt="image" /> где</p>
<p>L – направление на источник света;</p>
<p>V – направление на наблюдателя</p>
<p>N – нормаль к поверхности;</p>
<p>R – направление отражения.</p>
<p><span><em>k<span class="math">\({}_{d}\)</span></em></span> и <span><em>k<span class="math">\({}_{s}\)</span></em></span> – т.н. диффузный и зеркальный коэффициенты, используетюся для управления вкладом диффузного и зеркального отражения ;</p>
<p><span><em>n</em></span> – коэффициент для изменения ширины зеркального блика Модель Фонга – локальная, т.е. она не учитывает вторичного освещения. Поэтому часто в нее включают коэффициент, отвечающий за <span><em>фоновое (</em></span>ambient) освещение для аппроксимации вторичного освещения. Без ограничений общности, мы не будем рассматривать этот коэффициент. Обозначим выражение в скобках через <span><em>Refl</em></span>(<span><strong>L</strong></span>,<span><strong>V</strong></span>), получим: <img src="image107" alt="image" /> <span><strong>L</strong></span> и <span><strong>V</strong></span> соответствуют входящему направлению <span><em>w<span class="math">\({}_{i}\)</span></em></span> и, соответственно, исходящему направлению <span><em>w<span class="math">\({}_{o }\)</span></em></span>в терминологии ДФОС. Перепишем выражение следующим образом: <img src="image108" alt="image" /> <img src="image109" alt="image" /> <img src="image110" alt="image" /> <img src="image111" alt="image" /> Это выражение имеет вид подынтегральной функции в общей формуле освещения для точечного источника света. Если рассматривать первый множитель как ДФОС, тогда модель освещения Фонга становится частным случаем общей модели освещения. <img src="image112" alt="image" /> <img src="image113" alt="image" /> Необходимо сделать несколько замечаний</p>
<p>Хотя модель Фонга очень удобна для вычислений и ее вычисление реализовано в современной аппаратуре, на практике ей соответствует очень узкий класс материалов.</p>
<p>Несмотря на то, что эта модель широко распространена, она не является физически корректной. В частности, для модели Фонга не выполняется закон сохранения энергии.</p>
<p><span><em>Аппроксимация света на модели Фонга</em></span> Существует несколько алгоритмов закраски сложных поверхностей. Методы закраски Гуро и Фонга являются наиболее популярными. При этом метод Фонга требует больших вычислительных затрат, однако он позволяет разрешить многие проблемы метода Гуро.</p>
<p><span><strong>Модель Фонга</strong></span> I<span class="math">\({}_{s}\)</span> = I<span class="math">\({}_{l}\)</span> * w (q, l) * cos<span class="math">\({}^{n}\)</span>a, гдеI<span class="math">\({}_{s}\)</span> — интенсивность света, попадающего в глаз наблюдателя,I<span class="math">\({}_{l}\)</span> — интенсивность падающего луча,w — коэффициент отражения, который находится из кривой отражения и зависит от угла падения q и длины волны l,cos<span class="math">\({}^{n}\)</span>a — характеристика материала поверхности,a — угол, образованный лучами отражения и наблюдения,n — узость освещающего луча.</p>
<p><span><strong>Общая модель закраски</strong></span> На <span><strong>рис. 25.1</strong></span> мы видим тело, как бы составленное из граней. По формулам из предыдущей лекции можно рассчитать освещенность для каждой точки этого тела. Но наблюдателю будут видны явно выраженные стыки поверхностей, поэтому для вуалирования переходов освещенности между этими поверхностями и проводят аппроксимацию (то есть сглаживание). <img src="image114" alt="image" /></p>
<p><span><strong>Закраска фигуры по Фонгу. Вуалирование граней</strong></span> При закраске Фонга аппроксимация кривизны поверхности производится сначала в вершинах многоугольников — путем аппроксимации нормали в вершине. После этого билинейной интерполяцией вычисляется нормаль в каждом пикселе. На <span><strong>рис. 25.2</strong></span> (а также на <span><strong>рис. 25.3</strong></span>) изображены четыре плоскости, спроецированные на экран монитора. Горизонтальная штрих-линия представляет собой горизонтальный ряд пикселов, который строится лучом ЭЛТ. <img src="image115" alt="image" /> Рассмотрим метод Фонга, суть которого состоит в апроксимации нормалей, на примере.</p>
<p>Пусть нам известны уравнения плоскостей для трех многоугольников, и сходятся они в одной вершине. Три плоскости собираются в вершине V. Усредняем нормаль в ней:n<span class="math">\({}_{v}\)</span> = (a<span class="math">\({}_{1}\)</span> + a<span class="math">\({}_{2}\)</span> + a<span class="math">\({}_{3}\)</span>)i + (b<span class="math">\({}_{1}\)</span> + b<span class="math">\({}_{2}\)</span> + b<span class="math">\({}_{3}\)</span>)j + (c<span class="math">\({}_{1}\)</span> + c<span class="math">\({}_{2}\)</span> + c<span class="math">\({}_{3}\)</span>)kP<span class="math">\({}_{0}\)</span>: z - 1 = 0;P<span class="math">\({}_{1}\)</span>: -y + z - 2 = 0;P<span class="math">\({}_{2}\)</span>: -x + z - 2 = 0.n<span class="math">\({}_{v}\)</span> = -i - j + 3k — усредненная нормаль в точке <span><em>n</em></span> (используется для вычисления интенсивности пиксела).n= ((-1)<span class="math">\({}^{2}\)</span> + (-1)<span class="math">\({}^{2}\)</span> + 3<span class="math">\({}^{2}\)</span>)<span class="math">\({}^{0.5}\)</span> = 11<span class="math">\({}^{0.5}\)</span> — абсолютная величина нормали.е = n<span class="math">\({}_{v}\)</span> / n= -0.3i - 0.3j + 0.9k — единичная (нормированная) нормаль.</p>
<p>Вычисляем нормаль в каждом пикселе строки. Для закраски необходимы векторы нормали в точках A, B и C. Аппроксимируем их усреднением нормалей к окружающим плоскостям. Для того, чтобы изобразить объект методом построчного сканирования, нужно в соответствии с моделью освещения рассчитывать интенсивность каждого пиксела вдоль сканирующей строки. Сначала определяется интенсивность вершин многоугольника (A, B и C), а затем с помощью интерполяции вычисляется интенсивность каждого пиксела на сканирующей строке. <img src="image116" alt="image" /> Нормаль в точке Q находится линейной интерполяцией между А и В:n<span class="math">\({}_{Q}\)</span> = U * n<span class="math">\({}_{A}\)</span> + (1 - U) * n<span class="math">\({}_{B}\)</span>; 0 <span class="math">\(&lt;\)</span>= U <span class="math">\(&lt;\)</span>= 1; U = AQ/AB. Нормаль в точке R находится линейной интерполяцией между B и C:n<span class="math">\({}_{R}\)</span> = w * n<span class="math">\({}_{B}\)</span> + (1 - w) * n<span class="math">\({}_{C}\)</span>; w = BR/BC. Нормаль в точке P находится линейной интерполяцией между Q и R:n<span class="math">\({}_{P}\)</span> = t * n<span class="math">\({}_{Q}\)</span> + (1 - t) * n<span class="math">\({}_{R}\)</span>; 0 <span class="math">\(&lt;\)</span>= t <span class="math">\(&lt;\)</span>= 1; t = QP/QR.</p>
<p>В соответствии с принятым в компьютерной графике подходом, расчет освещенности распадается на две основные задачи. Первая – определить способ расчета освещенности в произвольной точке трехмерного пространства, решается при помощи построения обобщенной математической модели освещенности (Illuminating model). Вторая задача –применение Illuminating model для компьютерных расчетов освещенности трехмерных объектов с конкретной геометрией и свойствами поверхности, решается при помощи так называемой модели затенения (Shading model).Моделей освещенности к настоящему моменту разработано несколько. Самая первая, и самая простая – локальная модель освещенности. Эта модель не рассматривает процессы светового взаимодействия объектов сцены между собой, а только расчет освещенности самих объектов. Вторая, глобальная модель освещенности – Global Illuminations, рассматривает трехмерную сцену как единую систему и пытается описывать освещение с учетом взаимного влияния объектов. В рамках этой модели рассматриваются такие вопросы, как многократное отражение и преломление света (ray tracing), рассеянное освещение (radiosity), caustic и subsurface scattering (photon mapping) и другие. Начнем с самой простой модели освещенности, тем более что она и по сей день является главным способом расчета в рендерах scan-line типа (например, scan-line рендер 3ds max или mental ray).В рамках локальной модели освещения рассматривается свет только от явных точечных источников света трех типов – omni, spot и directional, а само взаимодействие ограничивается только <span><em>однократным</em></span> отражением света от <span><em>непрозрачной</em></span> поверхности. Изображение формируется в результате отражения падающего на поверхность объектов света, интенсивность и цвет которого и необходимо рассчитать.В самом общем случае, в свете требования фотореалистичности, эта модель должна также учитывать и неявное ambient-освещение. Ambient-освещение, или его еще называют фоновым (background), – это окружающее объект освещение от удаленных источников, чье положение и характеристики не известны. Необходимость учета ambient-освещения, пусть и очень грубо, обусловлена тем, что его вклад может быть достаточно велик – до 50% от общей освещенности. В Local Illumination считают, что фоновое освещение задает цвет (и его интенсивность) объекта в отсутствии явных источников света или в тени. Не несет никакой информации об объекте, кроме значения простого цвета, равномерно заливающего контур объекта.Интенсивность такого освещения постоянна и равномерно распределена во всем пространстве, расчет его отражения поверхностью выполняется по формуле: <img src="image130" alt="image" /> <span><em>где </em></span><img src="image132" alt="image" /><span><em>– интенсивность отраженного ambient освещения, </em></span><img src="image133" alt="image" /><span><em>– коэффициент, характеризующий отражающие свойства поверхности для ambient-освещения (его значение находится в пределах от 0 до 1), </em></span><img src="image134" alt="image" /><span><em>– исходная интенсивность ambient-света, падающего на поверхность.</em></span> <img src="image137" alt="image" /> <span><em>Увидеть этот тип освещения в “чистом виде” в 3ds max можно либо включив в настройках источника света свойство ambient only, либо изменив цвет Ambient Light панели Environment c черного (черный означает отсутствие окружающего освещения, принят по умолчанию) на более светлый и отключив diffuse/specular/ambient освещение в настройках источника света . В обычной ситуации, если цвет Ambient light в Environment отличен от черного (0, 0, 0 в RGB), свойство материалов Ambient color начинает оказывать влияние на цвет объекта – то есть max считает, что в сцене присутствует фоновое освещение, и начинает его просчитывать для поверхностей.</em></span> <img src="image141" alt="image" /> <span><em>Объектам назначены материалы, абсолютно одинаковые, за исключением значения ambient color. При отключенном фоновом освещении они и выглядят одинаково.</em></span> <img src="image145" alt="image" /> <span><em>Включение фонового освещения в Environment проявляет различие в ambient характеристиках этих материалов.</em></span><span class="math">\(\times\)</span>асть света от прямых источников зеркально отражается поверхностью, а остальной свет диффузно рассеивается во всех направлениях. Кроме чисто зеркального отражения, которое имеют идеально отполированные поверхности, различают так называемое glossiness или распределенное зеркальное отражение – отражение в некотором створе углов, а не на один единственный угол. Такое рассеяние света обусловлено микрорельефом (“шероховатостью”) поверхности, то есть поверхность реальных объектов не является идеально гладкой, а состоит из большого количества микровыступов и впадин, которые зеркально отражают падающий свет под разными углами. Результатом glossy-отражения является specular highlight – яркий световой блик, имеющий размер в зависимости от степени шероховатости поверхности. <img src="image151" alt="image" /> <span><em>Диффузное рассеяние. Свет отражается равномерно под всеми углами.</em></span> <img src="image155" alt="image" /> <span><em>Зеркальное отражение под одним идеальным углом и glossy отражение в створе углов, обусловленное шероховатостью поверхности.</em></span>Интенсивность рассеянного света зависит от угла падающего на поверхность света по закону Ламберта (Lambert): <img src="image161" alt="image" /> <span><em>где </em></span><img src="image163" alt="image" /><span><em>– интенсивность падающего на поверхность света, </em></span><img src="image164" alt="image" /><span><em>– коэффициент, характеризующий рассеивающие свойства поверхности (его значение изменяется в пределах от 0 до 1), </em></span><img src="image165" alt="image" /><span><em>– угол между направлением на источник света и нормалью поверхности.</em></span> <img src="image168" alt="image" /> Другими словами, поверхность будет освещена больше, если свет падает на нее перпендикулярно <img src="image170" alt="image" />, и меньше, если свет падает под любым другим углом, поскольку в этом случае увеличивается освещаемая площадь. <img src="image173" alt="image" /> Диффузно рассеянный свет является главным источником визуальной информации о геометрии трехмерных объектов. <img src="image177" alt="image" /> <span><em>В 3ds max диффузное отражение света можно увидеть, отключив Specular в свойствах источников света. Второй способ достичь того же результата – установить черный цвет для Specular в свойствах материала и Ambient light панели Environment. Полностью отключить диффузное отражение света для поверхности можно назначив черный цвет свойству материала Diffuse.</em></span>Как мы уже обсуждали, свет отражается зеркально в некотором створе углов, и для большинства реальных материалов мы всегда видим зеркальную подсветку в форме светового пятна, а не в форме яркой точки. Поэтому, для расчета интенсивности зеркально отраженного света используется формула, предложенная Фонгом: <img src="image183" alt="image" /> <span><em>где </em></span><img src="image185" alt="image" /><span><em>– интенсивность зеркально отраженного света, </em></span><img src="image186" alt="image" /><span><em>– интенсивность источника света, </em></span><img src="image187" alt="image" /><span><em>– коэффициент, характеризующий свойства зеркального отражения поверхности, </em></span><img src="image188" alt="image" /><span><em>– угол между направлением идеального отражения и направлением на наблюдателя, степень </em></span><span><strong><span><em>n</em></span></strong></span><span><em>определяет размер пятна светового блика – чем больше </em></span><span><strong><span><em>n</em></span></strong></span><span><em>, тем меньше световой блик, и тем ближе отражающие свойства поверхности к свойствам идеального зеркала.</em></span> <img src="image191" alt="image" /><img src="image194" alt="image" /> Формула Фонга – пример компьютерной фикции, поскольку она не имеет физического смысла. Ее используют просто потому, что она дает хорошие практические результаты. <img src="image198" alt="image" /> Зеркальную подсветку в 3ds max можно увидеть, установив черный цвет Diffuse color материала и Ambient light панели Environment, либо включив только Specular в свойствах источников света. Для создания идеальной зеркально отражающей поверхности в свойствах материала необходимо полностью отключить диффузное отражение и ambient-цвет. <img src="image202" alt="image" /> В 3ds max коэффициенту <img src="image204" alt="image" />соответствует параметр Specular Level, <span><strong>n</strong></span> – параметр Glossiness группы настроек материала Specular Highlights: <img src="image207" alt="image" /> Наконец, чтобы различать объекты, находящиеся на разных расстояниях от камеры, используется функция затухания интенсивности света с расстоянием: <img src="image211" alt="image" /> В компьютерной графике используется модифицированная формула, более приемлемая на практике: <img src="image215" alt="image" /> Таким образом, локальная модель освещенности предполагает расчет отраженной фоновой освещенности, диффузного и зеркального отражения от прямых источников: <img src="image219" alt="image" /><img src="image222" alt="image" /><img src="image223" alt="image" /><img src="image224" alt="image" /><img src="image225" alt="image" /><img src="image226" alt="image" /><img src="image227" alt="image" /><img src="image228" alt="image" /> Эта формула для расчета освещенности по одному каналу для одного источника света. Полная освещенность должна рассчитываться по всем трем основным каналам (RGB) и для всех источников освещения в трехмерной сцене и затем суммироваться. Эта модель получила название модели освещенности Фонга (не путать с моделью затенения Фонга, об этом ниже), по имени автора ее разработавшего. Является основной моделью в скан-лайн рендерах.Как видите, локальная модель освещенности довольно проста. Проста настолько, что обсуждать ее достоинства и недостатки бессмысленно, она дает неплохие практические результаты – на том и остановимся.</p>

</div>

<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({

  skipStartupTypeset: false,

  lazytex2jax: {
    displayMath: [['$$','$$'], ['\\[','\\]']],
    inlineMath: [['\\(','\\)']],
  },

 }); 
</script>


<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>


</body>
</html>
